<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>PhD-Report-Template</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    img {
    max-width: 50%;  /* Ensures image doesn't exceed its container's width */
    height: auto;     /* Maintains the image's aspect ratio */
    margin: 0 auto;   /* Optional: Centers the image if it is smaller than its container */
    display: block;   /* Optional: Ensures the image is treated as a block element */
}

  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<div class="titlepage">
<p><span class="smallcaps">University of Stirling</span><br />
<span class="smallcaps">Faculty of Natural Sciences</span><br />
<span class="smallcaps">Division of Computing Science and
Mathematics</span><br />
</p>
<hr />
<p><br />
<span> <strong>Domain-Specific Optimisations for Image Processing
Algorithms on Heterogeneous Architectures</strong></span><br />
</p>
<hr />
<p><br />
</p>
<div class="center">
<p><span class="smallcaps">Teymoor Rasheed Ali</span></p>
</div>
<div class="center">
<p><strong>Thesis submitted in fulfilment of the requirements for<br />
PhD in Computing Science<br />
29/12/2023<br />
</strong></p>
</div>
<p><img src="Images/unilogo.png" style="height:20mm" alt="image" /></p>
</div>
<h1 class="unnumbered" id="abstract">Abstract</h1>
<p>As real-time embedded vision systems become more ubiquitous, the
demand for better energy efficiency, runtime, and accuracy have become
vital metrics in evaluating overall performance. These requirements have
led to innovative computing architectures, leveraging heterogeneity that
combine various accelerators into a single processing fabric. These new
architectures lead to new challenges in understanding the most efficient
way to partition and optimise algorithms on the most suitable
accelerator.</p>
<p>In this thesis, domain-specific optimisation techniques are applied
to enhance performance and resource efficiency for image processing
algorithms on heterogeneous hardware. Domain-specific optimisations are
preferred for being hardware agnostic and their ability to cater to a
wider range of image processing pipelines within the domain. First, a
literature analysis is conducted on image processing implementations on
heterogeneous hardware, high-level synthesis tools, optimisation
strategies, and frameworks. The first objective is to develop
macro-micro benchmarks for image processing algorithms to determine the
suitability of these algorithms on hardware accelerators. The profiling
led to the development of a comprehensive benchmarking framework,
Heterogeneous Architecture Benchmarking on Unified Resources (HArBoUR).
The framework decomposes each algorithm into its fundamental properties
that would affect overall performance. A collection of representative
image processing algorithms from various operation domains
(<em>e.g.</em>, Filters, Morphological, Geometric, Arithmetic, CNNs,
Feature Extraction ) and full pipelines (<em>e.g.</em>, edge detection,
feature extraction, convolutional neural network) are used as examples
to understand the compute efficiency of on three hardware platforms
(CPU, GPU, FPGA).</p>
<p>The results show that parallelism and memory access patterns
influence hardware performance. GPUs excel for algorithms with large
data-size parallel operations and regular memory access patterns. FPGAs
better suit lower parallel factor and data-sized operations. In
addition, optimising for irregular memory access patterns and complex
computations remains challenging on both FPGA and GPU architectures.
However, FPGAs offer high performance relative to their resource and
clock speed, but their specialised architecture requires careful
implementation for optimal results. In the case of feature extraction
algorithms, GPU acceleration is preferable for high matrix
operation-intensive stages due to faster execution times. At the same
time, FPGAs are more suitable for lower arithmetic stages due to
comparable performance and energy consumption profiles. Edge detection
and CNN pipelines demonstrate GPUs faster performance but at a
significantly higher energy consumption than FPGAs. FPGAs exhibit lower
latency than GPUs, considering initialisation and memory transfer times.
CPUs perform comparably to both hardware in low-complexity and
data-dependant algorithms. In CNN pipelines, FPGAs compute particular
layers faster but generally have slower total inference times than GPUs.
Nonetheless, FPGAs offer flexibility with bit-widths and operation-fused
custom kernels.</p>
<p>Domain-specific optimisations are applied to algorithms such as SIFT
feature extraction, filter operations, and CNN pipelines to understand
the runtime, energy, and accuracy. Techniques such as downsampling,
datatype conversion, and convolution kernel size reduction are
investigated to enhance performance. These optimisations notably improve
computation time across different processing architectures, with the
SIFT algorithm implementation surpassing state-of-the-art FPGA
implementations and achieving comparable runtime to GPUs at low power.
However, these optimisations led to a 5-20% image accuracy loss across
all algorithms.</p>
<p>Finally, the research outcomes described above are applied to two
constructed heterogeneous architectures aimed at two domains, low-power
(LP) and high-power (HP) systems. Partitioning strategies are explored
for mapping CNN layers and operation stages of feature extraction
algorithms onto heterogeneous architectures. The results demonstrate
that layer-based partitioning methods outperform their fasted
homogeneous accelerator counterparts regarding energy efficiency and
execution time, suggesting a promising approach for efficient deployment
on heterogeneous architectures.</p>
<h1 class="unnumbered" id="attestation">Attestation</h1>
<p>I understand the nature of plagiarism, and I am aware of the
University’s policy on this.</p>
<p>I certify that this dissertation reports original work by me during
my PhD except for the following:</p>
<p>Chapter 4: The results and text are taken from my own ’A Benchmarking
Framework for Embedded Imaging’ paper.</p>
<p>Chapter 5: The results and text are from my own ’Domain-Specific
Optimisations for Real-time Image Processing on FPGAs’ Journal
paper.</p>
<p>Chapter 6: The results and text are from my own ’Energy Aware CNN
Deployment on Heterogeneous Architectures’ paper.</p>
<p><strong>Signature: Teymoor Rasheed Ali</strong> <em></em>
<strong>29/12/2023</strong></p>
<h1 class="unnumbered" id="acknowledgements">Acknowledgements</h1>
<p>I would like to thank my advisers, Dr. Deepayan Bhowmik and Dr.
Robert Nicol, who have been instrumental in shaping my research
path.</p>
<p>This work was supported by STMicroelectronics, Imaging Division and
the University of Stirling, Faculty of Natural Sciences. I express my
gratitude to all the colleagues and members within these institutions
who have provided me with valuable feedback and discussions on my work.
In addition, thanks for allowing me to contribute on many projects that
are used by millions of people across the world.</p>
<p>I would also like to thank my fellow university lab colleagues, Amir
M. and Alexander C., for the countless discussions and late night chess
games. Furthermore, thanks to Calum T., and Howard C. within the ST
office for the technical discussions. Thanks to my friends, I have met
along the way during my research: Karen F., Dr. Hannuy C., Dr. Ray W.
and many more.</p>
<p>Finally, I would like to thank my parents who have enabled and
supported me to pursue a PhD.</p>
<h1 class="unnumbered" id="list-of-symbols-and-acronyms">List of Symbols
and Acronyms</h1>
<p><span id="chap:symbols" data-label="chap:symbols"></span></p>
<h2 class="unnumbered" id="acronyms">Acronyms</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Acronym</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ASIC</td>
<td style="text-align: left;">Application Specific Integrated
Circuit</td>
</tr>
<tr>
<td style="text-align: left;">APU</td>
<td style="text-align: left;">Application Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Convolution Neural Network</td>
</tr>
<tr>
<td style="text-align: left;">CPU</td>
<td style="text-align: left;">Central Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">TPU</td>
<td style="text-align: left;">Tensor Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">NPU</td>
<td style="text-align: left;">Neural Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">DNN</td>
<td style="text-align: left;">Deep Neural Network</td>
</tr>
<tr>
<td style="text-align: left;">DSL</td>
<td style="text-align: left;">Domain-Specific Language</td>
</tr>
<tr>
<td style="text-align: left;">FFT</td>
<td style="text-align: left;">Fast Fourier Transform</td>
</tr>
<tr>
<td style="text-align: left;">FLOP</td>
<td style="text-align: left;">Floating Point Operation</td>
</tr>
<tr>
<td style="text-align: left;">FPS</td>
<td style="text-align: left;">Frames Per Second</td>
</tr>
<tr>
<td style="text-align: left;">FPGA</td>
<td style="text-align: left;">Field-Programmable Gate Array</td>
</tr>
<tr>
<td style="text-align: left;">GPU</td>
<td style="text-align: left;">Graphics Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">HDL</td>
<td style="text-align: left;">Hardware Descriptor Language</td>
</tr>
<tr>
<td style="text-align: left;">HLS</td>
<td style="text-align: left;">High-Level Synthesis</td>
</tr>
<tr>
<td style="text-align: left;">IP</td>
<td style="text-align: left;">Intellectual Property</td>
</tr>
<tr>
<td style="text-align: left;">MSE</td>
<td style="text-align: left;">Mean Square Error</td>
</tr>
<tr>
<td style="text-align: left;">NPU</td>
<td style="text-align: left;">Neural Processing Unit</td>
</tr>
<tr>
<td style="text-align: left;">PCIe</td>
<td style="text-align: left;">Peripheral Component Interconnect
Express</td>
</tr>
<tr>
<td style="text-align: left;">ReLU</td>
<td style="text-align: left;">Rectified Linear Unit</td>
</tr>
<tr>
<td style="text-align: left;">ResNet</td>
<td style="text-align: left;">Residual Network</td>
</tr>
<tr>
<td style="text-align: left;">RMSE</td>
<td style="text-align: left;">Root Mean Square Error</td>
</tr>
<tr>
<td style="text-align: left;">RTL</td>
<td style="text-align: left;">Register-Transfer Level</td>
</tr>
<tr>
<td style="text-align: left;">SIFT</td>
<td style="text-align: left;">Scale-Invariant Feature Transform</td>
</tr>
<tr>
<td style="text-align: left;">SSD</td>
<td style="text-align: left;">Solid State Drive</td>
</tr>
<tr>
<td style="text-align: left;">SSIM</td>
<td style="text-align: left;">Structural Similarity Measure</td>
</tr>
<tr>
<td style="text-align: left;">VHDL</td>
<td style="text-align: left;">VHSIC Hardware Description Language</td>
</tr>
<tr>
<td style="text-align: left;">VPU</td>
<td style="text-align: left;">Vision Processing Unit</td>
</tr>
</tbody>
</table>
<h1 class="unnumbered" id="statement-of-originality">Statement of
Originality</h1>
<p><span id="chap:soo" data-label="chap:soo"></span> The research
conducted within the scope of this thesis produced the following novel
and unique contributions towards domain-specific optimisation techniques
for image processing algorithms on heterogeneous architectures:</p>
<p>State of the art analysis of literature found within the
heterogeneous computing and domain-specific optimisation research
domain.</p>
<p>A framework that studies features of image processing algorithms to
identify characteristics. These features help partition complex
algorithms in determining optimal target accelerators within
heterogeneous architectures.</p>
<p>The approach adopts a systemic and multi-layer strategy that offers
trade-offs between accuracy within the imaging sub-domains
<em>e.g.</em>, <em>CNNs</em> and <em>feature extraction.</em>
Specifically, <em>HArBoUR</em> enables support in constructing end to
end vision systems while providing expected results and guidance.</p>
<p>Domain knowledge-guided hardware evaluation of computational tasks
allows imaging algorithms to be mapped onto hardware platforms more
efficiently than a heuristic based approach.</p>
<p>Benchmark of representative image processing algorithms and pipelines
on various hardware platforms and measure their <em>energy
consumption</em> and <em>execution time</em> performance. The results
are evaluated to gain insight into why certain processing accelerators
perform better or worse based on the characteristics of the imaging
algorithm.</p>
<p>Proposition of four domain-specific optimisation strategies for image
processing and analysing their impact on performance, power and
accuracy;</p>
<p>Validation of the proposed optimisations on widely used
representative image processing algorithms and CNN architectures
(MobilenetV2 &amp; ResNet50) through profiling various components in
identifying the common features and properties that have the potential
for optimisations.</p>
<p>Proposal of an efficient deployment of a CNN that is computationally
faster and consumes less energy.</p>
<p>Novel partitioning methods on a heterogeneous architecture by
studying the features of CNNs to identify characteristics found in each
layer which are used to determine a suitable accelerator.</p>
<p>Two heterogeneous platforms which consist of two configurations are
developed, one high-performance and the other, power-optimised embedded
system.</p>
<p>Benchmarking and evaluating runtime, energy, and inference of popular
convolution neural networks on a wide range of processing architectures
and heterogeneous systems.</p>
<h1 id="chap:intro">Introduction</h1>
<p>The emergence of heterogeneous processor technology has enabled
real-time embedded vision systems to become ubiquitous in many
applications, such as robotics<span class="citation"
data-cites="ZhaMenPra23"></span>, autonomous vehicles<span
class="citation" data-cites="KaiHonAma18"></span>, and satellites<span
class="citation" data-cites="PapTzioKal22"></span>. Real-time image
processing is inherently resource-intensive due to the complex
algorithms that demand significant computational power and memory
bandwidth. As such, optimising the performance of image processing
systems requires a delicate balance between hardware capabilities,
software efficiency, and algorithmic innovation to ensure timely and
responsive processing. Traditionally, imaging tasks implemented on
homogeneous architectures were limited in their adaptability in handling
diverse sets of operations. On the contrary, the advent of heterogeneous
architectures offers a flexible computing environment that combines
multiple accelerators such as CPUs, GPUs, and FPGAs, offering a choice
for executing tasks according to their computational requirements.</p>
<p>Integrating such accelerators together poses significant challenges
within design and implementation. These challenges are evident in the
complexities of scheduling tasks on different hardware units, managing
synchronisation, memory coherence, and addressing interconnect
requirements. Additionally, the absence of standardised models for
heterogeneous systems impacts the programming environment, making it
challenging for developers to create cohesive applications. Lastly,
performance evaluation becomes a multifaceted task, requiring a
comprehensive understanding of the interactions between processing units
and their contributions to overall system performance.</p>
<p>However, the primary challenge lies in determining the most effective
approach for algorithm partitioning on heterogeneous architectures.
Given that each processing architecture executes specific algorithms
more efficiently than the other<span class="citation"
data-cites="7577314 QasDenVis19"></span>. In addition, navigating an
environment with various tool-sets and libraries further compounds the
challenge, requiring developers to carefully select and integrate the
appropriate tools that align with each processor’s properties.
Consequently, partitioned algorithms require further hardware and
algorithmic optimisations to extract maximum performance. Typically,
domain-specific optimisation techniques are often overlooked limiting
the full realisation of performance potential and efficiency gains.</p>
<p>Within the scope of the thesis, the aim is to demonstrate that
leveraging heterogeneous architectures for image processing algorithms
will increase performance in terms of both runtime and energy
consumption. Consequently, this work introduces domain-specific
optimisation techniques to further improve application efficiency.</p>
<h2 id="motivation">Motivation</h2>
<p>The history of the microprocessor can be traced back to 1959 when
Fair-child Semiconductors made a significant breakthrough by creating
the first integrated circuit. This invention revolutionised the field of
electronics by laying the foundation for integrating multiple
transistors and other components into a single silicon chip. In the
early 1970s, Intel Corporation introduced the first commercially
available microprocessor. The Intel 4004<span class="citation"
data-cites="Asp97"></span>, released in 1971, was a 4-bit processor
capable of performing basic arithmetic and logical operations, with a
clock speed of 740 kHz, it represented a significant leap in computing
power compared to previous electronic circuits. The 4004 was primarily
designed for calculators and other small-scale applications but soon
found use in a wide range of devices. Many manufacturers began to
contribute and innovate within the microprocessor space. In 1974, Intel
released the 8080<span class="citation" data-cites="Maz07"></span>, an
8-bit microprocessor that became highly influential.</p>
<p>Continuing through the 1970s and 1980s, microprocessors advanced
rapi-dly, with increasing processing power, efficiency and improved
architecture capabilities. The introduction of 16-bit processors, such
as the Intel 8086 and Motorola 68000, marked another significant
milestone, enabling more complex applications and operating systems. In
addition, ARM introduced a new architecture design which used a reduced
instruction set paradigm to streamline the execution of instructions.
This paved the way for the modern era of computing, with the rise of
personal computers and the increasing integration of microprocessors
into various devices and industries. In subsequent decades,
microprocessors continued to evolve, with advancements in clock speeds,
transistor densities, and architectural designs. The transition from
32-bit to 64-bit architectures expanded the memory addressing
capabilities and enabled more demanding applications. Multi-core
processors emerged in the early 2000s<span class="citation"
data-cites="IntelCores"></span>, revolutionising computing by enabling
parallel processing and significantly improving performance and
efficiency.</p>
<figure id="fig:Transistor">
<img src="Images/transistor_chart.png" />
<figcaption>Cost, Transistor Count &amp; Gate-length Technology
Timeline<span class="citation" data-cites="Wafer"></span>.</figcaption>
</figure>
<p>At around the same time, as CPU processors continued to evolve, two
additional specialised architectures emerged to address specific
computational needs: GPUs and FPGAs. GPUs were initially designed to
handle the complex computations required for rendering high-quality
graphics in video games and multimedia applications. However, their
parallel processing capabilities and ability to handle large amounts of
data made them well-suited for other computationally intensive tasks,
such as scientific simulations. On the other hand, FPGAs offer a
different approach to computing. Unlike CPUs and GPUs, which are based
on fixed instruction sets, FPGAs provide programmable logic that allows
users to configure the hardware functionality to suit specific tasks.
This flexibility enables FPGAs to be highly optimised for specific
applications, such as digital signal processing, data encoding, and
real-time processing. FPGAs are particularly valuable in scenarios that
require low latency and high throughput, as they can be tailored to
perform specific operations with exceptional efficiency.</p>
<p>However, in the past decade, processor architecture designs had begun
to coalesce, which resulted in a convergence of approaches and a common
set of design principles among different CPU manufacturers. As a result,
the X86 and ARM instruction sets are the only remaining architectures
used in the majority of the systems available. This shift was driven by
the realisation that the exponential performance gains seen in previous
years were becoming increasingly difficult to achieve due to physical
limitations and power constraints, reflected in Fig. <a
href="#fig:Transistor" data-reference-type="ref"
data-reference="fig:Transistor">1.1</a>.</p>
<p>The recent emergence of deep learning has reignited the pursuit of
specialised computing units, which has fragmented the ecosystem.
Developers have started exploring the potential of domain-specific
accelerators such as TPUs or NPUs to meet specific computational needs.
As a result, the processor landscape has become increasingly diverse
again, with different manufacturers pursuing their unique architectural
approaches. The growing set of domain-specific accelerators has driven
designers to adopt newer and innovative approaches involving
heterogeneity. A chiplet-based approach has emerged as a promising
paradigm by disaggregating specialised processing units and integrating
them into a cohesive interconnected circuit. Each chiplet serves a
specific function, leveraging modularity and specialisation to enhance
performance, scalability, and customisation. In addition, new packaging
methods are utilised to integrate chiplets together, ranging from
2.5D-IC silicon interposers to 3D stacking. Nevertheless, with the
deployment of diverse and heterogeneous architectures, a crucial
challenge arises in the form of designing algorithms capable of
effectively harnessing the capabilities offered by these novel
architectural frameworks. This necessitates the development of
algorithmic approaches that can optimise performance, exploit
parallelism, and efficiently use the unique features and resources
provided by these heterogeneous systems.</p>
<figure id="fig:fabrication">
<img src="Images/image.png" />
<figcaption>Wafer Fabrication Process Steps to Develop
Microprocessors.</figcaption>
</figure>
<p>Wafer fabrication, involves a series of steps to transform a silicon
wafer into an integrated circuit shown in Fig. <a
href="#fig:fabrication" data-reference-type="ref"
data-reference="fig:fabrication">1.2</a>, including wafer preparation,
photolithography, etching, layer deposition, and testing for
functionality and quality. The pursuit of smaller transistor sizes,
driven by demands for enhanced memory capacity and processing
capabilities, has led to heavy investment in novel lithography
technologies. However, the doubling of transistor densities every two
years, as predicted by Moore’s Law, has started to deviate due to
technological limitations and economic costs. Shrinking transistors face
challenges from the limitations of lithography wavelengths and the
increasing complexity of manufacturing processes, leading to lower
yields and higher costs. The production of larger silicon wafers has
been debated, with the industry transitioning from small diameters in
the 1960s to 300mm wafers as the standard by the early 1990s. While
larger wafers offer cost and yield benefits, transitioning requires
equipment redesign and cost-effectiveness considerations.</p>
<p>In summary, recent years have brought about major changes in the
semiconductor industry, driven by the demand from resource intensive
algorithms such as image processing and higher wafer fabrication cost.
As a result, heterogeneous architectures serve as a potential to
increase system performance further. However, understanding how to
efficiently partition algorithms on each accelerator and identifying
domain-specific optimisation trade-offs remain key challenges in
maximising the potential of these architectures.</p>
<h2 id="research-objectives">Research Objectives</h2>
<p>This thesis aims to conduct research on partitioning and optimising
image processing algorithms on heterogeneous architectures to unlock the
full energy and runtime performance. This research encompasses a wide
range of multidisciplinary domains (<em>e.g.</em>, hardware
(CPU/GPU/FPGA), compilers, schedulers, optimisations and programming
languages). Therefore, the focus is refined to three primary objectives
in this thesis, which are listed in detail below:</p>
<p>Understanding the properties of image processing algorithms and
hardware to determine the suitability in order to map operations to the
most efficient hardware to increase performance. In addition, exploring
optimised tool-sets and libraries in terms of programmability and
performance. The goal of this objective is to develop a comprehensive
micro/macro bench-marking framework which distils algorithms into their
principle operations and gives heuristics towards mapping the operations
to correct architecture. Additionally, providing various metrics to
evaluate and compare each accelerator. This work enables the
partitioning of algorithms on heterogeneous architectures, as realised
in later chapters</p>
<p>Investigating domains-specific optimisation techniques which leads to
better performance on hardware by exploiting inherent characteristics
and structures in the image domain. These optimisations are applied in
various combinations to determine the trade-offs in runtime, energy and
accuracy metrics. The outcomes of this research enable understanding the
efficiency of various hardware-agnostic optimisation methods found
within the image processing domain.</p>
<p>Development of a comprehensive heterogeneous platform capable of
executing image processing operations across all processing units while
efficiently scheduling data for optimal performance. This includes
designing and developing two complete heterogeneous platforms for high
and low-power applications. Furthermore, using novel layer-wise/stage
partitioning techniques on convolutional neural networks and feature
extraction algorithms to execute on the most suitable accelerator within
the heterogeneous platform. The goal of the objective is to uncover the
advantages of heterogeneous architectures in image processing and
document their performance gains over single-device solutions.</p>
<h2 id="thesis-outline">Thesis Outline</h2>
<p>The rest of this thesis is organised as follows:</p>
<p><strong>Chapter 2</strong> presents a technical background on the
devices, tools and software deployed in end to end imaging pipelines.
This encompasses types of imaging sensors, interfaces, hardware
architectures for image processing, high-level synthesis tools and
Domain Specific Languages, followed by general discussions of their
advantages and drawbacks within the image processing domain.</p>
<p><strong>Chapter 3</strong> critically discusses the state-of-the-art
in current literature on optimisations and architectures, which includes
HLS/DSL tools, micro/macro benchmarking frameworks and methodologies.
Furthermore, an analysis of heterogeneous hardware and their performance
in image and domain-specific optimisations.</p>
<p><strong>Chapter 4</strong> presents a novel framework methodology
<em>HArBoUR</em>, for heterogeneous architectures which deconstructs
image processing pipelines into their fundamental operations and
evaluates their performance on hardware platforms, including CPUs, GPUs,
and FPGAs. The methodology extends its evaluation to include various
hardware based performance metrics, enabling a finer-grained analysis of
each architecture’s capabilities.</p>
<p><strong>Chapter 5</strong> presents the proposition of
domain-specific optimisations for various imaging and deep-learning
algorithms. Each optimisation strategy is applied individually and in
combination, and their effectiveness is validated using runtime,
accuracy and energy consumption metrics.</p>
<p><strong>Chapter 6</strong> proposes two algorithm types and their
implementations on heterogeneous architectures, two convolution neural
networks and one feature extraction algorithm. The accuracy, energy
consumption and runtimes are recorded and compared to their discrete
counterparts.</p>
<p><strong>Chapter 7</strong> concludes this thesis by summarising the
research outcomes, i.e., analysis, proposed benchmarking framework and
optimisation strategies on heterogeneous algorithms. Novel contributions
are highlighted here along with suggestions on new ideas for future
research in this domain.</p>
<h2 id="publications">Publications</h2>
<h3 class="unnumbered" id="journals">Journals</h3>
<p><strong>Ali, T.</strong>, Bhowmik, D. &amp; Nicol, R. Domain-Specific
Optimisations for Image Processing on FPGAs. Journal of Signal Process
Systems (2023). <a href="https://doi.org/10.1007/s11265-023-01888-2"
class="uri">https://doi.org/10.1007/s11265-023-01888-2</a></p>
<h3 class="unnumbered" id="reports">Reports</h3>
<p>M, Bane, O, Brown, <strong>T, Ali</strong>, D, Bhowmik, J, Quinn, D,
Stansby. ENERGETIC (ENergy aware hEteRoGenEous compuTIng at sCale). <a
href="https://doi.org/10.23634/MMU.00631226"
class="uri">https://doi.org/10.23634/MMU.00631226</a></p>
<h3 class="unnumbered" id="under-preparation">Under Preparation</h3>
<p><strong>Ali, T.</strong>, Bhowmik, D. &amp; Nicol, R. A Benchmarking
Framework for Imaging Algorithms on Heterogeneous Architectures.</p>
<div class="flushleft">
<p><strong>Ali, T.</strong>, Bhowmik, D. &amp; Nicol, R. Energy Aware
CNN Deployment on Heterogeneous Architectures.</p>
</div>
<h1 id="background">Background</h1>
<p>In this chapter, the following sections review central components
that make up the image processing pipeline. The components are divided
into four categories: 1) Image Sensor Type and Characterisation 2)
Interface Technologies 3) Hardware Processing Architectures 4) Software
Tool-sets. The first category discusses the most common image sensor
designs and various noises sources. The second category observes the
data transfer performance of each interfaces between the sensor and
processing hardware. The third category explores the components of
hardware architectures used to execute algorithms. The final category
delves into the tools and libraries employed for the ease of
implementation.</p>
<h2 id="chap:Background">Image Processing Pipeline</h2>
<div class="figure*">
<p><img src="Images/vision_pipeline.png" alt="image" /></p>
</div>
<p>Vision applications fundamentally contain a sequence of operations
that form a pipeline shown in Fig. <a href="#fig:VisionPipeline"
data-reference-type="ref"
data-reference="fig:VisionPipeline">[fig:VisionPipeline]</a>. Firstly,
the image sensor captures photons reflected off objects using micro-lens
to refract the light into a matrix of wells containing circuits called
pixels and the charge produced from the photodiode is converted to a
voltage. Once the analogue signal from the image sensor is converted
into a digital format, the image data goes through various pixel and
frame operations to correct any defects found from the introduction of
noise. Furthermore, a full-colour image is reconstructed from the raw
frame using a demosaicing algorithm, which may differ depending on the
filter pattern <em>e.g.</em>, <span>Bayer, X-Trans or EXR</span>.
Optionally, the colour image can be compressed into a JPEG format to
reduce file size for transmission. The image may contain helpful
features that define particular objects, such as shape, colour or
texture information. Feature extraction algorithms help identify these
characteristics and compile the features into a vector. Finally, a
feature vector or image is inputted into a classification algorithm such
as a convolution neural network to determine a label or ’class’. The
sequence of operations within the pipeline can be reordered or removed
to fulfil particular design requirements.</p>
<p>The imaging pipeline comprises various hardware and software
components that enable the efficient implementation and execution of
image processing algorithms. This chapter presents a complete overview
of each component and its limitations. These components include imaging
sensors, processing architectures, interface protocols, vision libraries
and other tool-sets used to develop a heterogeneous system.</p>
<h2 id="imaging-sensor">Imaging Sensor</h2>
<figure id="fig:CMOSCROSS">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a) Back-Illuminated</td>
<td style="text-align: center;">(b) Front-Illuminated</td>
</tr>
</tbody>
</table>
<figcaption>Cross-Section of CCD and CMOS silicon, revealing internal
components fundamental to converting light into a signal.</figcaption>
</figure>
<p>Image sensors are essential components in modern digital imaging
devices, such as digital cameras, smartphones, and surveillance systems.
These sensors play a crucial role in capturing and converting light into
electrical signals, which are then processed to form digital images.
Image sensors work on the principle of detecting and measuring light
intensity to create a representation of the scene being captured. The
most commonly used image sensing technologies within vision systems are
charge-coupled device (CCD)<span class="citation"
data-cites="Smi09"></span>, and CMOS image sensor(CIS)<span
class="citation" data-cites="Fos97"></span>. CCD technology was
developed first and optimised over time for imaging applications, which
allowed it to gain a significant market share compared to the newly
developed CIS technology, which suffered in image quality due to higher
noise. Therefore, CIS sensors were only used in applications where lower
cost was the driving factor over image quality. However, over the years,
significant advances in silicon size, power consumption, process
technology and the reduced fabrication cost of CIS technology resulted
in surpassing CCD in market volume. CIS technology can now be found in
many applications, from smartphones to medical imaging. Current research
on CIS technology focuses on image quality by improving spatial,
intensity, spectral and temporal characteristics <span class="citation"
data-cites="Gou16"></span>.</p>
<p>Modern image sensors comprise several layers shown in Fig. <a
href="#fig:CMOSCROSS" data-reference-type="ref"
data-reference="fig:CMOSCROSS">2.1</a> that integrate together to
capture and process light. At the topmost layer, microlenses focus
incoming light onto the pixel array below, enhancing light sensitivity
and overall image quality. Beneath the microlenses lies the pixel array,
with each pixel containing a photodiode responsible for converting
photons into electric charge. A Bayer pattern colour filter<span
class="citation" data-cites="BayerPatent"></span>, located on top of the
pixel array, captures colour information by using red, green, and blue
colour filters arranged in a specific pattern. Interpolating algorithms
reconstruct the full-colour image from the captured colour data. Wiring
and interconnects within the sensor facilitate the efficient transfer of
electrical signals from each pixel to the readout circuitry, minimising
signal degradation and cross-talk. The silicon substrate forms the
foundation for all components, enabling efficient light conversion by
the photodiodes and hosting the CMOS circuits for signal processing and
readout.</p>
<div class="figure*">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;">(b)</td>
</tr>
</tbody>
</table>
</div>
<p>The <em>CCD</em> architecture operates on the principle of
transferring charge thro-ugh a sequential shift register. This shift
register is a critical component within the CCD chip, responsible for
transporting the accumulated charge from each pixel to the output node
for further processing. The photons of light strike the pixels of the
CCD sensor, which absorbs the incident light, generating an electrical
charge proportional to the intensity of the light. The charge in each
pixel is horizontally transferred to neighbouring pixels along the shift
register. This process, known as "horizontal transfer" in the row
direction, uses potential wells to transport charge from one well to the
next. After the horizontal transfer, the charge is vertically shifted
down the columns. Manipulating voltages in the vertical shift registers
moves the charge from one row to the next, guiding it towards the output
node. The output node stores the accumulated charge and is connected to
an analogue-to-digital converter (ADC) to convert the analogue charge
into a digital signal for further processing and storage.</p>
<p>In a <em>CMOS</em> image sensor, the conversion of light into voltage
involves several technical steps. Each pixel in the sensor consists of a
photodiode, which acts as a light-sensitive capacitor. When incident
photons strike the photodiode, it generates electron-hole pairs, and
these charge carriers are stored as electric charge in the capacitor.
The accumulated charge in each pixel’s capacitor is then transferred to
an associated charge-to-voltage conversion circuit, commonly known as
the readout circuit. This circuit typically includes a source follower
amplifier or a trans-impedance amplifier. The charge is converted into a
corresponding analogue voltage signal, proportional to the intensity of
the incident light on the pixel. The output voltage from each pixel is
then sent to the image sensor’s output circuitry for further signal
conditioning and processing. This circuitry may include analogue signal
processing components such as analogue filters or amplifiers to enhance
the image quality and reduce noise.</p>
<div class="figure*">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;">(b)</td>
</tr>
</tbody>
</table>
</div>
<p>In machine vision, the key performance metrics are latency and noise.
The differences arise between CMOS and CCD imagers in their signal
conversion processes, transitioning from signal charge to an analogue
signal and finally to a digital one. In CMOS area and line scan imagers,
a highly parallel front-end design enables low bandwidth for each
amplifier. Consequently, when the signal encounters the data path
bottleneck, typically at the interface between the imager and off-chip
circuitry, CMOS data firmly resides in the digital domain. Conversely,
high-speed CCDs possess numerous parallel fast output channels, albeit
not as massively parallel as high-speed CMOS imagers. As a result, each
CCD amplifier requires higher bandwidth, leading to increased noise
levels. Therefore, high-speed CMOS imagers exhibit the potential for
considerably lower noise compared to high-speed CCDs.</p>
<p>In recent years, semiconductor manufacturers have moved onto stacking
imaging sensors depicted in Fig. <a href="#fig:3DStacking"
data-reference-type="ref"
data-reference="fig:3DStacking">[fig:3DStacking]</a> to reduce the
latency between readout to processing, which was previously developed in
the memory domain to increase data storage.</p>
<h3 id="image-sensor-characterisation">Image Sensor
Characterisation</h3>
<figure id="fig:NoiseyImage">
<img src="Images/FixedPatternNoise.png" />
<figcaption>The figure illustrates the presence of characteristic fixed
noise patterns, often resulting from sensor imperfections or calibration
issues, alongside temporal noise, which can manifest as random
variations in pixel values over multiple frames.</figcaption>
</figure>
<p>Image sensor characterisation is a process that assesses the
performance and capabilities of imaging sensors. The goal is to
understand the sensor’s behaviour and limitations to ensure optimal
image quality and accurate representation of the captured scene. Noise
introduced in sensors come from various sources such as thermal noise,
read noise, and photon shot noise, which can degrade image quality, as
observed in <a href="#fig:NoiseyImage" data-reference-type="ref"
data-reference="fig:NoiseyImage">2.2</a>. Characterisation involves
measuring and analysing these noise components to determine their impact
on image fidelity. Noise can be separated into two categories:</p>
<p><strong>Pattern Noise:</strong></p>
<p>This term describes noise patterns that remain constant or fixed over
time and across multiple frames or exposures. Fixed pattern noise
includes phenomena like Fixed Pattern Noise (FPN), Pixel Non-Uniformity
(PRNU), and other systematic and deterministic noise sources.</p>
<p><strong>Random Noise:</strong></p>
<p>The random noise relates to noise that varies over time or across
different exposures. It includes sources of noise that exhibit
randomness and unpredictability from frame to frame, such as Photon Shot
Noise, Readout Noise, Amplifier Noise, and Jitter Noise.</p>
<p>Signal-to-noise ratio (SNR) is a standard metric used to quantify the
signal quality captured by the sensor relative to the noise in the
image. Dynamic range is another parameter that refers to the sensor’s
ability to capture and distinguish details in a scene’s bright and dark
regions. A wide dynamic range is essential for preserving details in
high contrast scenes without overexposing or underexposing certain
areas. Sensitivity and linearity are additional metrics assessed during
the characterisation process. Sensitivity determines how well the sensor
responds to incoming light, while linearity examines how the sensor’s
output corresponds to the actual incident light levels.</p>
<h2 id="interface-technologies">Interface Technologies</h2>
<p>Vision systems typically rely on input from cameras or other video
sources, generating a continuous stream of image frames. Designing
algorithms for embedded vision systems requires a detailed understanding
of performance and interfacing technologies. The subsequent sections
provide an overview of various characteristics related to each
technology.</p>
<h3 id="camera-link">Camera Link</h3>
<figure id="fig:CameraLink">
<img src="Images/CameraLink.png" style="width:70.0%" />
<figcaption>Camera Link interface, showing the integration of Low
Voltage Differential Signalling (LVDS) technology for noise
immunity.</figcaption>
</figure>
<p>Camera Link<span class="citation" data-cites="CameraLink"></span> is
a parallel communication protocol that extends the Channel Link
technology and standardises the interface between cameras and frame
grabbers. Channel Link provides a one-way transmission of 28 data
signals and an associated clock over five LVDS pairs. Among these pairs,
one is designated for the clock, while the 28 data signals are
multiplexed across the remaining four pairs exhibited in Fig. <a
href="#fig:CameraLink" data-reference-type="ref"
data-reference="fig:CameraLink">2.3</a>, involving a 7:1 serialisation
of the input data. A single Camera Link connection allocates 24 bits for
pixel data (three 8-bit pixels or two 12-bit pixels) and reserves 4 bits
for frame, line, and pixel data valid signals. The pixel clock operates
at a maximum rate of 85 MHz. Additionally, four LVDS pairs facilitate
general-purpose camera control from the frame grabber to the camera,
with the specifics defined by the camera manufacturer. Furthermore, two
LVDS pairs are designated for asynchronous serial communication between
the camera and frame grabber, supporting a minimum baud rate of 9600 for
relatively low-speed serial communication.</p>
<p>For higher bandwidth requirements, the medium configuration includes
an additional Channel Link connection, granting an extra 24 bits of
pixel data. The full configuration further extends the capacity by
incorporating a third Channel Link, resulting in a total of 64 bits of
pixel data transmission capability. The versatile nature of Camera Link,
with its various configurations, makes it a widely adopted interface
standard for high-performance camera systems, particularly in
applications demanding real-time image capture and processing.</p>
<h3 id="peripheral-component-interface-express-pcie">Peripheral
Component Interface Express (PCIe)</h3>
<figure id="fig:PCIe">
<img src="Images/PCIe.png" style="width:60.0%" />
<figcaption>The PCIe Architecture consists of Root Complex, PCIe
Endpoint Devices, and Memory Subsystem. The Root Complex orchestrates
data flow, while PCIe Endpoint Devices serve as endpoints for data
transactions.</figcaption>
</figure>
<p>The Peripheral Component Interface Express (PCIe)<span
class="citation" data-cites="PCIe"></span> shown in Fig. <a
href="#fig:PCIe" data-reference-type="ref"
data-reference="fig:PCIe">2.4</a>, is an open standard serial bus
interface protocol designed in the early 1990s to provide a high-speed
interconnect between devices such as Ethernet controllers,
expansion/capture cards, storage and graphics processing units. The
protocol defined a set of registers within each device known as
configuration space, allowing software to view memory and IO resources.
In addition, the exposure of peripheral data enables software to assign
an address to each device without conflict with other systems. Table <a
href="#tab:PCIeSummary" data-reference-type="ref"
data-reference="tab:PCIeSummary">[tab:PCIeSummary]</a> summarises each
version of the PCIe specification ratified in the past and future.</p>
<figure id="fig:PCIeDualSimplexLink">
<img src="Images/PCIELink.png" style="width:90.0%" />
<figcaption>The PCIe Communication Data Link between two
Devices</figcaption>
</figure>
<p>The PCIe architecture consists of a root complex that connects the
CPU and memory subsystem to the PCI Express switch fabric composed of
one or more PCIe/PCI endpoints. The dual‐simplex connections between
endpoints are bidirectional, as shown in Fig. <a
href="#fig:PCIeDualSimplexLink" data-reference-type="ref"
data-reference="fig:PCIeDualSimplexLink">2.5</a>, which allows data to
be transmitted and received simultaneously. The term for this path
between the devices is a Link and is made up of one or more transmit and
receive pairs. One such pair is called a Lane, and the spec allows a
Link to be made up of 1, 2, 4, 8, 12, 16, or 32 Lanes. The number of
lanes is called the Link Width and is represented as x1, x2, x4, x8,
x16, and x32. The trade‐off regarding the number of lanes to be used in
a given design is that having more lanes increases the Link’s bandwidth
but at the cost of space requirement and power consumption.</p>
<h3 id="ethernet">Ethernet</h3>
<p>Ethernet technology<span class="citation"
data-cites="Ethernet"></span> is based on the Carrier Sense Multiple
Access with Collision Detection (CSMA/CD) access method. It operates at
the physical layer (Layer 1) and the data link layer (Layer 2) of the
OSI model. The physical layer handles the transmission and reception of
raw data over the physical medium, while the data link layer is
responsible for framing, addressing, and error detection.</p>
<p>One of the main advantages of Ethernet is its flexibility and
scalability. It can support various data rates, ranging from 10 Mbps for
older versions (e.g., 10BASE-T) to 1 Gbps (Gigabit Ethernet) and beyond
for modern implementations. This adaptability allows Ethernet to cater
to a wide range of applications, from simple office networks to
high-speed data centres and multimedia streaming.</p>
<p>When using Ethernet with FPGAs, designers face the challenge of
implementing the higher layers of the OSI model, namely the network
layer (Layer 3) and transport layer (Layer 4). These layers are
responsible for IP addressing, routing, and end-to-end communication.
FPGA designs must include logic to handle IP addressing, packet
forwarding, and any higher-level protocols required for data exchange.
This complexity can add overhead to the FPGA design and require careful
optimisation to ensure efficient data processing.</p>
<p>In FPGA-based systems, the communication between the FPGA and the
Ethernet physical layer typically involves a Media Access Control (MAC)
core, which is responsible for generating and interpreting Ethernet
frames. The MAC core interfaces with the external Ethernet PHY chip,
which handles the conversion between the MAC-level signals and the
actual physical signals transmitted over the Ethernet cable. In
CPU-based systems, handling Ethernet involves the integration of a
Network Interface Controller (NIC) or Ethernet controller. The NIC is a
hardware component that interfaces the CPU with the Ethernet medium. It
manages low-level operations, such as frame reception and transmission,
packet encapsulation and decapsulation, and error checking. The NIC
communicates with the CPU through driver software that implements
higher-level network protocols.</p>
<p>The CPU’s involvement in Ethernet communication extends beyond the
data link layer. It handles the network layer protocols (Layer 3), such
as Internet Protocol (IP), which involves tasks like IP address
assignment, routing, and packet forwarding. Additionally, the CPU
manages transport layer protocols (Layer 4), such as Transmission
Control Protocol (TCP) and User Datagram Protocol (UDP), responsible for
end-to-end communication and data flow control.</p>
<h4 id="gige-vision">GigE Vision</h4>
<figure id="fig:GigEVision">
<img src="Images/GigEVision.png" />
<figcaption>A Structure of the Data Frame, Including Payload Data,
Header Information, and Ethernet Protocol Stack.</figcaption>
</figure>
<p>GigE Vision is a standard developed in 2006 by the Automated Imaging
Association<span class="citation" data-cites="GigE"></span>, which
extends gigabit Ethernet to transport video data and control information
to the camera efficiently. This standard benefits from the widespread
availability of low-cost standard cables and connectors, allowing data
transfer rates of up to 100 MPixels per second over distances of up to
100 meters.</p>
<p>GigE Vision comprises four essential elements. The control protocol
facilitates camera control and configuration communication, while the
stream protocol governs the transfer of image data from the camera to
the host system, both running over UDP. A device discovery mechanism
identifies connected GigE Vision devices and acquires their internet
addresses. GigE Vision utilises Gigabit Ethernet (1000BASE-T) for data
transmission, enabling a maximum data rate of 1 Gbps for real-time
transfer of large image and video data in industrial applications. It
employs packet-based communication displayed in Fig. <a
href="#fig:GigEVision" data-reference-type="ref"
data-reference="fig:GigEVision">2.6</a>, dividing images into smaller
packets for efficient data transfer, ensuring reliable transmission and
minimal data loss. Moreover, many GigE Vision cameras support Power over
Ethernet (PoE), receiving power through the Ethernet cable, reducing
installation overhead. GigE Vision supports both asynchronous and
synchronous triggers for precise image capture control. Asynchronous
triggers allow continuous image capture at a specified frame rate, while
synchronous triggers enable coordinated capture based on external events
for synchronised operation with other devices. Additionally, GigE Vision
cameras can be easily configured and accessed using the GigE Vision
Control Protocol (GVCP), providing efficient camera parameter
adjustments and image data retrieval. Overall, GigE Vision is a
versatile and efficient interface for industrial imaging applications,
offering seamless data transmission and easy camera control.</p>
<p>In many embedded vision applications, it is more practical to
integrate the FPGA system within the camera itself, allowing for image
processing before transmitting results to a host system using GigE
Vision. To achieve real-time operation, a dedicated device driver is
used on the host system. This driver bypasses the standard TCP/IP
protocol stack for the video stream and employs Direct Memory Access
(DMA) transfers to transfer data to the application directly. By
avoiding CPU overhead during video data handling, real-time performance
can be achieved effectively. This optimised data transfer scheme ensures
smooth and efficient communication between the camera and the host
system in GigE Vision applications.</p>
<h3 id="universal-serial-bus-usb">Universal Serial Bus (USB)</h3>
<p>USB has emerged as a widely used interface for connecting peripheral
devices to personal computers. Over the years, USB technology has
evolved significantly, supporting increasing link speeds from the
initial 1.5 Mb/s and 12 Mb/s to the current 20 Gb/s in the double lane
configuration of USB 3.2 Gen 2. As a result, USB has proven to be a
viable and versatile interface between FPGAs and SoCs (System-on-Chips)
in various applications.</p>
<p>USB operates in a master-slave architecture, where there can be only
one host or master controller within a USB network, and the host
controller initiates all communication. The communication protocol of
USB is structured into four layers: the application and system software
interacts with the USB pipe at the topmost layer, while the protocol
layer handles packet management. USB packets come in several types, such
as Link Management Packets, Transaction Packets, Data Packets, and
Isochronous Timestamp Packets. These packets serve to exchange control
and status information between the host and the connected devices.</p>
<p>The Data Packet, which carries user data along with a 16-byte header,
is essential for transferring information between the host and the
device. On the other hand, the other packet types primarily facilitate
control and status exchanges. Any data transfer requires initiation by a
Transaction Packet before actual data transmission occurs. To enable
FPGA access to the USB bus, an external PHY (Physical Layer) chip is
necessary. This chip often provides a first-in-first-out (FIFO)
interface, which the FPGA can connect to through regular I/O ports. User
logic is then required to implement the control logic and interface with
the application. While this FIFO interface might limit throughput in
certain scenarios, it does not pose any bottleneck for applications like
video streaming.</p>
<h3 id="mobile-industry-processor-interface-mipi">Mobile Industry
Processor Interface (MIPI)</h3>
<figure id="fig:MIPI">
<img src="Images/MIPI.png" style="width:70.0%" />
<figcaption>C-PHY and D-PHY with two lanes each. C-PHY makes it possible
to reach more than double the bandwidth per lane than
D-PHY.</figcaption>
</figure>
<p>MIPI<span class="citation" data-cites="mipi"></span> is a serial
interface standard developed in 2003 for interconnecting components in
mobile devices. MIPI comes in various versions, and one of the widely
used versions in mobile camera interfaces is MIPI CSI-2 (Camera Serial
Interface 2). The interface can consist of one or more data lanes, each
capable of transmitting a stream of image data. A separate clock lane
synchronises the data transmission, ensuring accurate data reception.
MIPI CSI-2 supports various data types, including RAW image data and
metadata, allowing it to accommodate different image sensor formats and
data requirements. Furthermore, the concept of virtual channels enables
the multiplexing of multiple data types over the same physical data
lanes.</p>
<p>MIPI CSI-2 utilises low-voltage differential signalling to transmit
image data from the camera sensor to the application processor. C-PHY
and D-PHY are two different physical layer specifications, and their
usage depends on the specific requirements of the devices shown in
Fig. <a href="#fig:MIPI" data-reference-type="ref"
data-reference="fig:MIPI">2.7</a>. D-PHY provides higher data rates and
is capable of reaching extremely high speeds, making it suitable for
applications that require substantial data throughput. D-PHY supports
multiple data lanes (typically 1 to 4 lanes), and it is commonly used in
devices with high-resolution imaging requirements, such as high-end
smartphones and cameras. On the other hand, C-PHY, or Combo PHY, is a
combination of MIPI C-PHY and MIPI D-PHY technologies. It offers a more
power-efficient solution than D-PHY, making it ideal for power-sensitive
mobile devices. C-PHY leverages both a low-power, single-ended
signalling mode and a high-speed, differential signalling mode,
providing a balance between data transfer rates and power consumption.
It uses fewer wires compared to D-PHY, simplifying the physical design
of mobile devices and potentially reducing costs.</p>
<p>MIPI CSI-2 comes with certain drawbacks that may impact its
applicability. Firstly, its physical image data transfer (D-PHY) is
limited to shorter cable lengths, typically not exceeding 20 cm, which
can be restrictive for certain industrial applications. Additionally,
the lack of a standardised plug for MIPI CSI-2 means that sensor/camera
modules must be individually and proprietary connected. Moreover, the
absence of a standardised driver and software stack requires custom
adjustments for each sensor or camera module to work with the CSI-2
driver of a specific System-on-Chip (SoC) through a proprietary I²C
driver as a Video4Linux sub-device.</p>
<h3 id="fpga-mezzanine-card-fmc">FPGA Mezzanine Card (FMC)</h3>
<figure id="fig:FMC">
<img src="Images/FMCPincount.png" style="width:70.0%" />
<figcaption>FMC Low Pin and High Pin Count Sockets.</figcaption>
</figure>
<p>The FMC interface is a high-speed, versatile standard for connecting
external modules to FPGAs (Field-Programmable Gate Arrays). The FMC
standard encompasses two form factors: single-width and double-width.
Single-width supports one connector, while double-width caters to
applications needing more bandwidth, front panel space, or larger PCB
areas and supports up to two connectors, offering designers flexibility
for optimising space and I/O requirements. Two connector types, Low Pin
Count (LPC) with 160 pins and High Pin Count (HPC) with 400 pins,
displayed in Fig. <a href="#fig:FMC" data-reference-type="ref"
data-reference="fig:FMC">2.8</a>. Both support single-ended and
differential signalling up to 2 Gb/s, with signalling to an FPGA’s
serial connector at up to 10 Gb/s. LPC offers 68 user-defined
single-ended signals or 34 differential pairs, along with clocks, a JTAG
interface, and optional I2C support for base Intelligent Platform
Management Interface (IPMI) commands. HPC provides 160 single-ended
signals (or 80 differential pairs), ten serial transceiver pairs, and
additional clocks. HPC and LPC connectors use the same mechanical
connector, differing only in populated signals, enabling compatibility
between them.</p>
<h3 id="summary">Summary</h3>
<p>Table <a href="#tab:Interfaces" data-reference-type="ref"
data-reference="tab:Interfaces">[tab:Interfaces]</a> provides a summary
of common image sensor interfaces utilised in various imaging
applications. These interfaces offer diverse specifications in terms of
bandwidth, maximum cable length, frame rate, bit depth, and power
consumption, catering to specific imaging needs and requirements. USB4,
Thunderbolt and USB offers the highest bandwidth at 40 Gbps while
CoaXPress and GigE variants supports the longest cable length at 100
meters which is ideal for distant camera setups. USB provides the
highest bit depth options, ensuring better colour precision. MIPI CSI-2
stands out as the most power-efficient interface, consuming only 1.2 W,
which is ideal for mobile applications, while CoaXPress requires the
most power at 24 W. Although, USB4 can supply up to 240W to cameras or
other devices. The only two parallel interfaces are FMC and
Cameralink.</p>
<h2 id="hardware-architectures">Hardware Architectures</h2>
<p>In recent years, the demand for flexible, energy-efficient and higher
performance processors has continuously grown. This has pushed designers
to develop novel processing architectures to facilitate requirements.
This section introduces popular processing hardware used within vision
applications.</p>
<h3 id="multi-core-central-processing-unit-cpu">Multi-Core Central
Processing Unit (CPU)</h3>
<figure id="fig:CPU">
<img src="Images/CPU.png" style="width:70.0%" />
<figcaption>The CPU architecture consists of multiple cores, which
contain components such as registers, caches, ALU and
interconnects.</figcaption>
</figure>
<p>The CPU observed in Fig. <a href="#fig:CPU" data-reference-type="ref"
data-reference="fig:CPU">2.9</a> is an integrated circuit responsible
for executing instructions and performing arithmetic, timing, logic and
I/O operations. The CPU architecture involves the design and
organisation of various components to optimise performance, power
efficiency, and instruction execution. The main components are
registers, arithmetic logic units (ALUs), control units, cache memory,
and instruction pipelines. Registers are small, high-speed storage units
within the CPU used for temporarily holding data and intermediate
results during computation. ALUs are responsible for performing
arithmetic and logic operations, such as addition, subtraction, NOT and
OR. The control unit manages the flow of instructions and data within
the CPU, fetching instructions from memory, decoding them, and
coordinating their execution. CPU cache memory is used to store
frequently accessed data, reducing the time taken to retrieve data from
main memory.</p>
<p>Reduced Instruction (RISC) and Complex Instruction Set Computer
(CISC) are two CPU microarchitecture approaches. RISC architectures
prioritise simplicity and efficiency by employing a smaller set of basic
instructions. This streamlined design typically leads to faster and more
predictable execution, making RISC processors well-suited for
power-constrained devices and applications where speed is critical. In
contrast, CISC architectures, exemplified by x86, feature a diverse and
extensive set of complex instructions designed to reduce the number of
instructions required to perform tasks. While this complexity can
provide convenience for programmers, it often results in more intricate
hardware, potentially impacting performance and energy efficiency.</p>
<p>Significant research is put into improving the execution speed of
instruction pipelines. The pipeline breaks down the execution of
instructions into multiple stages, allowing different instructions to be
processed simultaneously. Each stage of the pipeline handles a specific
task, such as instruction fetch, decode, execute, and write back. This
pipelining process increases the CPU’s instruction throughput and
overall performance. CPU architecture also includes features like branch
prediction, speculative execution, and out-of-order execution. Branch
prediction predicts the outcome of conditional branches to keep the
pipeline filled with useful instructions. Speculative execution allows
the CPU to execute instructions before it is confirmed that they are
needed, further improving performance. Out-of-order execution enables
the CPU to execute instructions in a different order to optimise
resource utilisation.</p>
<p>In the past decade, single-core processors have now been outpaced by
the shift to multi-core designs. Traditionally, speedup was achieved by
increasing the processor’s clock speed and decreasing the transistor
size to pack more into the silicon area. However, the power density
required grew at a faster rate than the frequency which entailed power
problems exacerbated by complex designs attempting to extract extra
performance from the instruction stream. This led to designs that were
complex, unmanageable, and power-hungry. However, chip designers
introduced multiple cores onto a single die and leveraged parallel
programming to continue pushing for more performance. The primary
advantage to multi-core systems is the raw performance increase from
extending the number of processing cores rather than clock frequency,
which translates into slower growth in power consumption. This can be a
significant factor in embedded devices that operate on a power budget,
such as mobile devices.</p>
<p>General-purpose multi-cores are becoming necessary in real-time
digital signal processing. One general-purpose core would control
various signals and watchdog functions for many special-purpose ASICS as
part of a system-on-chip. This is primarily due to the variety of
applications and functions required. Nevertheless, multi-Core processors
give rise to new problems and challenges. As more processing cores are
integrated into a single chip, power and temperature are the primary
concerns that can increase exponentially with more cores. Memory and
cache coherence is another challenge due to the distributed L1 caches
and, in some cases, L2 caches which need to be coordinated.</p>
<h3 id="graphics-processing-unit-gpu">Graphics Processing Unit
(GPU)</h3>
<div class="figure*">
<p><img src="Images/GPU.png" alt="image" /></p>
</div>
<p>The GPU is a specialised hardware architecture initially used for
graphics rendering. However, GPUs have undergone significant power and
cost advancements, which have captured the attention of both industry
and academia. Designers have been exploring the potential of GPUs to
accelerate large-scale computational workloads.</p>
<p>The architecture of GPUs is designed with a focus on throughput
optimisation, allowing for efficient parallel computation of numerous
operations. Fig. <a href="#fig:GPU" data-reference-type="ref"
data-reference="fig:GPU">[fig:GPU]</a> illustrates the high-level GPU
architecture. The GPU comprises multiple Streaming Multiprocessors (SMs)
that function independently, and these SMs are organised into multiple
Processor Clusters (PCs). Each SM incorporates a layer-1 (L1) cache with
each core. Typically, each SM possesses its dedicated layer-1 cache, and
multiple SMs share a layer-2 cache before accessing data from the global
GDDR-5 memory. Newer GPU models integrate tensor cores, which
efficiently compute matrices calculations, enhancing their performance
in deep learning tasks.</p>
<p>The GPU architecture, initially tailored for 3D graphics rendering,
involves a streamlined pipeline with distinct stages. It commences with
vertex processing, transforming 3D geometric data, followed by primitive
assembly to group vertices into primitives. Rasterisation then
translates these into screen pixels or fragments, and fragment
processing adds attributes like colours and textures. Finally, the pixel
output stage writes processed fragments to the frame buffer, resulting
in the rendered image on the screen. The highly parallel nature of the
graphics pipeline in GPUs makes them exceptionally well-suited for image
processing tasks. Image processing often involves manipulating and
analysing large amounts of pixel data concurrently, making it a
naturally parallelisable task. Leveraging the parallel processing
capabilities, image processing algorithms can be accelerated by
providing higher frames per second performance for tasks such as image
filtering, edge detection, and object recognition. Additionally, GPU
optimised memory hierarchy ensures faster access and storage of larger
images, kernels and intermediate data.</p>
<p>There remain drawbacks for GPUs, primarily if they are intended to be
used as general-purpose machines. Firstly, the limitations of
adaptability and context switching make them less suitable for
general-purpose computing tasks. Simple calculations which do not
utilise the parallelism are inhibited by lower clock speeds.
Communication between the CPU and GPU can introduce bottlenecks and
decrease the GPU throughput, especially when waiting for results from
the CPU. Memory capacity and bandwidth would also affect GPU
performance; for example, an image processing application must wait for
the image data to be transferred from the main memory, further delaying
the runtime. Lastly, GPUs cannot operate independently without support
from a CPU, which contributes to more power consumption from idling.</p>
<h3 id="field-programmable-gate-array-fpga">Field-Programmable Gate
Array (FPGA)</h3>
<div class="figure*">
<p><img src="Images/FPGA.png" style="width:70.0%" alt="image" /></p>
</div>
<p>Field-Programmable Gate Arrays are versatile integrated circuits
which offer direct hardware programmability for diverse applications.
They have gained prominence due to their reconfigurability, making them
highly advantageous compared to fixed processing architectures such as
ASICs. These features enable shorter time-to-market by allowing
prototyping and late-stage design modifications. The FPGA architecture,
as depicted in Fig. <a href="#fig:FPGA" data-reference-type="ref"
data-reference="fig:FPGA">[fig:FPGA]</a>, comprises a matrix of
configurable logic blocks (CLBs) containing a combination of look-up
tables (LUTs), shift registers (SRs), and multiplexers (MUXs). These
components are interconnected through programmable high-bandwidth
pathways and are surrounded by I/O ports.</p>
<p>The fine-grained nature of FPGAs empowers designers to exploit both
spatial and temporal parallelism in their designs, resulting in enhanced
performance. In image processing applications, algorithms can be
tailored to operate on individual pixels or groups of pixels in
parallel. Temporal parallelism can be achieved using techniques like
pipelining, where separate processors work on successive stages of data,
allowing concurrent processing and better throughput. Spatial
parallelism, however, involves partitioning the image frame and
processing each segment independently using separate processors.</p>
<p>FPGAs allow seamless integration of I/O, such as image sensors,
enabling pixel data to be streamed directly into processing units
without latency. Data can be routed efficiently to other embedded
processors without external memory access. Block RAMs (BRAMs) within the
FPGA enable exploiting data locality in vision kernels by keeping
critical data on-chip. However, the main limitation in image processing
applications often stems from external memory (E.g. DDR4 RAM) read/write
operations, which can impact overall performance.</p>
<p>Advanced extensible interface (AXI) is a standard protocol for
efficient communication between IP blocks within an FPGA design. It
follows the Advanced Microcontroller Bus Architecture (ARM AMBA)
specification, ensuring compatibility with ARM-based processors and
systems-on-chip (SoCs). The AXI protocol supports separate read and
write channels, enabling simultaneous data transactions in both
directions. It also features burst transfers, allowing multiple data
transfers within a single transaction to enhance data throughput.</p>
<p>Despite their advantages, FPGA development requires expertise in
hardware descriptor languages (HDL), such as VHDL/Verilog. This steep
learning curve can be a challenge for new developers accustomed
high-level languages and instruction based architectures. In comparison
to ASICs, the support functions and additional reconfigurable logic and
power consumption overhead, making power efficiency considerations
important during the design phase. FPGAs typically have limited on-chip
memory compared to GPUs, which can have limitations for applications
that require large memory spaces. Overall, FPGAs offer a powerful
platform for image processing tasks, but their effective use requires
careful consideration of design constraints and optimisation
strategies.</p>
<h3
id="application-specific-integrated-circuits-asics">Application-Specific
Integrated Circuits (ASICs)</h3>
<p>ASICs are a specialised type of Very Large Scale Integration (VLSI)
technology where integrated circuits are designed specifically for a
particular application domain. This involves custom designing at the
transistor level to optimise the circuit for performance and silicon
area. There are several advantages of opting for an ASIC implementation
over other general-purpose accelerators. The custom designed nature of
ASIC logic allows designers to create tightly integrated applications,
resulting in better performance, reduced power consumption, and
minimised silicon usage. ASICs come with intrinsic trade-offs listed
below:</p>
<p><strong>Fixed Design</strong>: ASICs are designed for specific
applications and lack flexibility compared to general-purpose
processors. Once fabricated, it is challenging and costly to make
modifications or upgrades to their functionality.</p>
<p><strong>High Design Cost</strong>: Designing and prototyping involves
significant expertise and time, leading to higher initial development
costs.</p>
<p><strong>Long Development Timeline</strong>: Creating a custom ASIC
requires extensive expertise and significant time to design, verify, and
manufacture.</p>
<p>Despite these drawbacks, the per-chip manufacturing cost becomes
significantly lower during mass production, rendering ASICs more
economically viable for high-volume production. The following sections
discuss the various types of ASICS targeting specific workloads:</p>
<h4 id="vision-processing-units-vpus">Vision Processing Units
(VPUs)</h4>
<figure id="fig:VPU">
<img src="Images/VPU.png" style="width:10cm" />
<figcaption>VPU Architecture consists of an array of processing elements
with horizontal and vertical buffers for efficient image
processing.</figcaption>
</figure>
<p>VPUs are a class of ASIC designed to alleviate the heavy processing
load on the central processor by accelerating workload-specific tasks.
VPUs shown in Fig. <a href="#fig:VPU" data-reference-type="ref"
data-reference="fig:VPU">2.10</a> have a distinct hardware design that
focuses on accelerating specific types of computations, such as deep
learning inference, video encoding/decoding, and image processing. They
often incorporate dedicated execution units, tensor cores, or
specialised instructions to accelerate these tasks efficiently.</p>
<p>VPUs employ hardware architectures and software frameworks tailored
to exploit parallelism and optimise performance for these tasks. GPUs,
while also capable of accelerating AI workloads, are designed to handle
a wide range of general-purpose graphics and compute tasks, making them
more versatile but potentially less optimised for specific
workloads.</p>
<p>VPUs also prioritise energy efficiency, aiming to deliver better
performance per watt over other accelerators. They employ techniques
like low-power execution units, reduced precision compute, and power
management features to minimise energy consumption. GPUs, on the other
hand, focus more on delivering absolute performance, often consuming
more power in exchange for higher computational capabilities. In
addition, VPUs often have specialised APIs or libraries that target
specific applications or frameworks, enabling efficient execution of AI
models or video codecs. However, the programming ecosystem for VPUs is
limited in comparison to general-purpose architectures.</p>
<h4 id="neural-processing-units-npus">Neural Processing Units
(NPUs)</h4>
<p>NPUs initially emerged in embedded devices as efficient AI inference
accelerators specifically designed to manage the computational demands
of machine learning workloads. The initial NPU architecture integrated
high-density MAC arrays such as 2D GEMM or 3D systolic arrays since the
majority of the computations are found within convolutional layers,
which involve significant matrix multiplications. As CNNs continued to
become increasingly complex with higher depth and many layers
configurations, NPU has now optimised the MAC array structures to ensure
enhanced modularity and scalability. Furthermore, newer features such
as:</p>
<p>Fused operations</p>
<p>Sparsity acceleration</p>
<p>Unified High Bandwidth Memory</p>
<p>Multi-level array partitioning</p>
<p>Mixed Precision Support</p>
<p>NPUs have expanded their capabilities for other neural network
architectures. This includes RNN/LSTM structures, targeting for audio
and natural language processing, and transformers.</p>
<h4 id="neuromorphic-hardware">Neuromorphic Hardware</h4>
<p>Neuromorphic architectures are a type of hardware developed to mimic
the structure and function of the human brain’s neural networks. These
architectures aim to replicate the principles of neural function in
their operation, seeking inspiration from biological systems. By
incorporating concepts such as weighted connections, activation
thresholds, short and long-term potentiation, and inhibition,
neuromorphic architectures aim to perform distributed computation in a
way that resembles how the human brain processes information.</p>
<p>The key objective of neuromorphic architectures is to achieve
efficient and parallel processing of data by leveraging the inherent
capabilities of neural networks. These architectures often involve the
use of spiking neural networks, where information is transmitted through
spikes or pulses, similar to how neurons communicate in the brain. This
approach allows for event-driven and energy-efficient computation,
making neuromorphic architectures suitable for various tasks, including
sensory data processing, pattern recognition, and complex
decision-making. Despite their promising advantages, they face
challenges, including complexity in design and implementation, limited
applicability to specific tasks, scalability issues, lack of
standardisation, and difficulty in implementing learning and adaptation
mechanisms. Balancing energy efficiency and performance is another
challenge, and commercial availability remains limited.</p>
<h4 id="asic-summary">ASIC Summary</h4>
<p>Table <a href="#tab:ASIC_specs" data-reference-type="ref"
data-reference="tab:ASIC_specs">[tab:ASIC_specs]</a> offers a concise
overview of various ASICS. These ASICs serve diverse purposes, from
machine learning acceleration to edge computing and AI inference.
Notable entries include the Intel Movidius Myriad X, known for its use
in edge devices, and the Google TPU, a powerful tensor processing unit
designed for machine learning tasks. The ARM Ethos-U55 and Huawei Kirin
ASICs are optimised for IoT devices and smartphones, all while operating
at low power consumption. Graphcore’s IPU, on the other hand, stands out
with its high power requirements, tailored for AI workloads in data
centres. Lastly, the Intel Neural Compute Stick focuses on applications
such as machine translation and natural language processing.</p>
<h3 id="heterogeneous-architectures">Heterogeneous Architectures</h3>
<figure id="fig:Heterogeneous">
<img src="Images/Heterogenous.png" style="width:11cm" />
<figcaption>Concept Heterogeneous Architecture which integrate multiple
specialised processing units onto a interconnected silicon chip.
</figcaption>
</figure>
<p>Heterogeneous architectures have recently gained significant
attention and mainstream appeal in various application domains. These
architectures integrate different types of accelerators, including CPUs,
GPUs, NPUs, and FPGAs, into a single compute fabric, observed in Fig. <a
href="#fig:Heterogeneous" data-reference-type="ref"
data-reference="fig:Heterogeneous">2.11</a>. Currently, commercial
heterogeneous chips only contain a combination of CPU-GPU-NPU<span
class="citation" data-cites="Intelhet"></span>. The primary objective of
heterogeneous architectures is to accelerate complex tasks by allocating
specific operations to the most suitable specialised cores that can
process them efficiently.</p>
<p>One of the key challenges in utilising heterogeneous systems lies in
algorithm design. Designing algorithms that can effectively leverage the
capabilities of different accelerators is crucial. It requires careful
consideration of the characteristics and strengths of each accelerator,
as well as the partitioning and mapping of computational tasks to the
appropriate cores. Algorithm designers need to analyse the computational
requirements, data dependencies, and parallelism inherent in the
application to optimise the workload distribution across different
cores.</p>
<p>Partitioning and mapping refer to the process of breaking down the
computational tasks and mapping them onto the available cores. It
involves considering the data dependencies, communication overhead, and
resource utilisation to ensure efficient execution. Additionally,
scheduling tasks across different cores, managing synchronisation
between them, and optimising interconnect requirements are critical
aspects of achieving optimal performance in heterogeneous
architectures.</p>
<p>The programming environment for heterogeneous architectures can be
complex and diverse. Each accelerator may have its own programming
model, APIs, and language extensions, making it challenging to develop
applications that can fully exploit the capabilities of all
accelerators. Furthermore, the availability of libraries and software
tools may vary across different compute elements due to differences in
instruction set architectures. This can lead to binary incompatibility
and limit the portability of applications across different accelerators.
Evaluating the performance of heterogeneous architectures requires
comprehensive performance evaluation techniques. Benchmarks and
performance metrics need to consider the characteristics of the
application, workload distribution, and communication patterns to
provide an accurate assessment of the system’s capabilities.</p>
<h3 id="summary-1">Summary</h3>
<p>The table <a href="#tab:HardwareSummary" data-reference-type="ref"
data-reference="tab:HardwareSummary">[tab:HardwareSummary]</a> provides
a concise overview of various hardware architectures used in compute
operations. CPUs and GPUs offer general-purpose flexibility, supporting
temporal and spatial computations with medium and high latency,
respectively, while following an instruction-based execution paradigm.
FPGAs, though generally flexible, are better suited for spatial
computations, with limited practicality for temporal tasks due to
overhead and effectiveness constraints. They employ a dataflow execution
paradigm. In contrast, ASICs are fixed-function hardware designed for
specific spatial computations, offering low latency and following a
dataflow execution paradigm.</p>
<h3 id="software-ecosystem">Software Ecosystem</h3>
<p>This section explores the software domain employed for targeting
hardware architectures and software interfaces. Optimised libraries such
as OpenCV, High-Level Synthesis, and Domain-Specific Languages assume a
role in bridging the gap between hardware and software application
development.</p>
<h4 id="high-level-synthesis-hls">High-Level Synthesis (HLS)</h4>
<p>High-level synthesis (HLS) is a tool that enables hardware designers
to use a high-level programming language, such as Python, C or C++, to
create hardware designs. This is in contrast to traditional hardware
design methods, which involve manually writing hardware description
languages (HDLs) such as VHDL or Verilog. HLS tools take in the
high-level source code and automatically generate the corresponding HDL
code. This can greatly simplify the design process, making it more
accessible to non-hardware design experts. This means that designers can
focus on the functionality of the design and not worry about low-level
implementation details. HLS tools also perform optimisation to improve
the performance and resource utilisation of the generated hardware. This
can result in more efficient designs that use fewer resources and run
faster.</p>
<p>Another benefit of HLS is that it allows for faster design iteration.
As the design can be expressed in a high-level programming language, it
can be easily modified and re-synthesised to see the effects of the
changes. This can greatly speed up the design process and allow for
faster time-to-market. In addition, FPGAs are often selected for systems
where time to market is critical in order to avoid lengthy chip design
and manufacturing cycles. The designer may accept the increased
performance, power, or cost in order to reduce design time. Modern HLS
tools put this trade-off into the hands of the designer; with more
effort, the quality of the result is comparable to handwritten RTL
(register transfer language). ASICs have high manufacturing costs, so
there is a lot of pressure for designers to achieve success on the first
attempt. Design iterations can quickly and inexpensively be done without
huge manufacturing costs.</p>
<p>However, these tools come with a set of drawbacks. For instance, the
initial learning curve can be steep, particularly for those new to
hardware design, as they require a solid understanding of both
high-level programming and hardware optimisation techniques. While HLS
tools automate the allocation of hardware resources based on the
provided code, they may not always yield the most efficient designs for
complex projects compared to manual, fine-tuned hardware descriptions.
One of the key challenges in using HLS tools is accurately predicting
the performance of the generated hardware. Factors such as memory access
patterns, data dependencies, and the overall architecture can
significantly impact performance, making it challenging to estimate how
the synthesised hardware will behave. Moreover, debugging HLS-generated
designs can be complex. Traditional software debugging methods are often
insufficient, as hardware-related issues might not manifest in the same
way as in software. This can prolong development cycles and hinder the
identification of issues.</p>
<h4 id="domain-specific-languages-dsl">Domain-Specific Languages
(DSL)</h4>
<p>Domain-specific languages (DSLs) are programming languages designed
to address specific problem domains rather than being general-purpose
languages. DSLs offer higher-level abstractions and syntax tailored to a
particular application area, allowing users to express domain-specific
concepts more concisely and intuitively. Unlike general-purpose
languages, DSLs enable non-experts to work effectively within a specific
domain, as they are more focused on the domain’s requirements and
semantics. DSLs come in two main types: external DSLs, which are
standalone languages distinct from the host language (<em>e.g.</em>, Cal
Actor Language<span class="citation" data-cites="Eker"></span>), and
internal DSLs, which are embedded within a general-purpose language
using its syntax and tools (<em>e.g.</em>, Halide <span class="citation"
data-cites="10.1145/2491956.2462176"></span>). The use of DSLs can lead
to improved productivity, reduced error rates, and better code
maintainability in specific application areas.</p>
<h4 id="libraries-frameworks">Libraries &amp; Frameworks</h4>
<p>Optimised libraries such as OpenCV<span class="citation"
data-cites="opencv_library"></span> are essential tools used to develop
vision and deep-learning applications. These libraries offer a
comprehensive collection of pre-built algorithms and functions for a
wide range of image-related tasks. Their significance lies in the
substantial time and resource savings they provide, enabling developers
to utilise tried-and-tested algorithms, thus reducing development
efforts and benefiting from community-driven improvements. Moreover,
optimised libraries ensure cross platform compatibility, supporting
various programming languages and platforms. They are continually
updated to harness advancements in hardware and software, making them
key for efficient and adaptable image processing.</p>
<p>Deep learning frameworks such as Pytorch<span class="citation"
data-cites="Pytorch"></span> offer abstraction and simplification,
allowing developers to focus on high-level tasks. Frameworks encompass a
comprehensive suite of support programs, compilers, code librar-ies,
toolsets, and application programming interfaces that provide a cohesive
environment that streamlines the development of systems. Therefore,
frameworks facilitate rapid prototyping and integration with other
tools.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In conclusion, this section provides an in-depth overview of the
imaging pipe-line and its fundamental components, establishing the
groundwork for the subsequent chapters. It encompasses typical
operations present in each pipeline stage, which will used as
implementation examples. Furthermore, the section delves into diverse
hardware platforms such as CPUs, GPUs, VPUs, and FPGAs, each offering
distinct attributes that can accelerate algorithms. To leverage these
hardware capabilities, a range of tools and methodologies are
introduced, which include high-level synthesis. In the next chapter, the
state-of-the-art study on heterogeneous architectures and optimisation
strategies related to image processing are discussed.</p>
<h1 id="chap:sota">State-of-the-Art</h1>
<p>This chapter surveys the literature relevant to the research
conducted in this thesis. The work covered in this section spans a wide
range of topics, including image processing, CNNs, hardware,
algorithmic, and domain-specific optimisation approaches. Additionally,
the chapter reviews proposed heterogeneous platforms and partitioning
methods. A critical analysis of recent research publications is
performed, and potential areas for exploration are discussed throughout
the section.</p>
<h2 id="hardware-targeting-image-processing">Hardware Targeting Image
Processing</h2>
<p>This section introduces imaging algorithms implemented on various
architecture configurations found within the literature. Heterogeneous
architectures, which integrate diverse computing elements like CPUs,
GPUs, FPGAs, and specialised accelerators, have emerged as a pivotal
paradigm in modern computing systems, aiming to achieve higher
performance and energy efficiency. These architectures cater to the
diverse computational needs such as parallelisation or pipelining for
tasks involving deep learning to signal processing. In addition to the
literature on supporting algorithms that are tailored to exploit the
unique capabilities of these heterogeneous components. Furthermore,
various optimisation methods are explored for each hardware.</p>
<h3 id="multi-core-cpu-architectures">Multi-Core CPU Architectures</h3>
<p>While accelerators with numerous cores such as GPUS, have
traditionally outperformed CPUs in image processing due to core count,
the recent introduction of many-core CPUs boasting thousands of cores
has become more competitive in runtime performance. Furthermore,
considering the initialisation and memory latency required for GPUs,
CPUs may complete kernels within that timeframe <span class="citation"
data-cites="GreKim11 YukRusTor19 Wszola_2019"></span>.</p>
<p>Many-core co-processors, relying on simple hardware, place
substantial demands on software programmers, while their use of in-order
cores struggles to tolerate long memory latencies. In addressing these
challenges, work has been done to explore decoupled access/execute (DAE)
mechanisms for tensor processing. One software-based method is to use
naïve and systolic DAE, complemented by a lightweight hardware access
accelerator to enhance area-normalised throughput. This method has shown
<span class="math inline">\(2-6\times\)</span> performance improvement
on a 2000-core CPU heterogeneous system compared to an 18-core
out-of-order CPU baseline<span class="citation"
data-cites="ChPanZha22"></span>. Executing fundamental image processing
operations, such as Winograd-based convolution, on many-core CPUs (Intel
Xeon Phi), has shown comparable performance for 2D ConvNets.
Additionally, it has demonstrated <span
class="math inline">\(3\times-8\times\)</span> times better runtime
performance for 3D ConvNets compared to the best GPU
implementations<span class="citation"
data-cites="JiaAlekDur18"></span>.</p>
<h3 id="cpu-gpu-architectures">CPU-GPU Architectures</h3>
<p>The CPU-GPU architecture is a widely adopted approach to implementing
of complex image processing algorithms. The architecture leverages many
simple processing cores, which are efficient in executing parallelised
tasks. The CPU is typically responsible for orchestrating the high-level
control flow and task management allocation to the GPU. Many works
developing image processing algorithms on GPUs<span class="citation"
data-cites="DanDomAnd08 YuWeiDav19 ParkSingLee11"></span> have exhibited
a <span class="math inline">\(10\sim20\)</span>x speedup in runtime
compared to single CPU implementations. In real-time imaging, works such
as optical flow<span class="citation" data-cites="ChaNelBren08"></span>
and edge-corner detection<span class="citation"
data-cites="PosRicMah14"></span> were evaluated for their algorithmic
performance on GPUs and FPGAs. The results observed show that GPUs
slightly outperform FPGAs by utilising large amounts of data parallelism
and hiding latency. Dynamic thread scheduling on the GPU hides memory
latency by swapping threads and making memory requests with others, as
long as there are enough threads to keep the process continuous. In
addition, easy programmability of GPUs supports software debug
iterations which involve fast edit/compile/execute cycles compared to
the much more time consuming FPGA<span class="citation"
data-cites="CheShuLi08"></span>.</p>
<h3 id="cpu-fpga-architectures">CPU-FPGA Architectures</h3>
<figure id="fig:AlgoChar">
<img src="Images/Microblaze.png" />
<figcaption>Generic Soft Processor Architecture on Programmable Logic.
</figcaption>
</figure>
<h4 id="fpga">FPGA:</h4>
<p>FPGAs have been utilised for image processing in order to leverage
their unique architectural characteristics, such as parallelism,
reconfigurability, and low latency. These features enable FPGAs to excel
in tasks that demand real-time analysis of image data and require lower
power consumption<span class="citation"
data-cites="TakTsuMar08"></span>.</p>
<p>One major drawback of using FPGAs for image processing is the need to
primarily use fixed-point arithmetic. While FPGAs can handle
floating-point arithmetic, it often demands too many resources,
especially for parallel processing. Vision research typically relies on
floating-point algorithms, and adapting them to fixed-point requires a
detailed analysis to determine necessary precision at each stage and to
work within the FPGA’s resource limits<span class="citation"
data-cites="Mac05"></span>. When compared directly to ASIC devices,
disregarding cost and design timelines, FPGA implementations are
generally less efficient due to the configuration circuitry overhead,
which includes I/O and the required SRAM cells to store the current
design. This results in larger device sizes and higher power
consumption. ASIC design processes also enable circuitry optimisation
for faster clock speeds than those achievable on FPGAs<span
class="citation" data-cites="BauDanRoss07"></span>.</p>
<h4 id="cpu-fpga">CPU-FPGA:</h4>
<p>Historically, these two components operated independently, each
catering to its own application domains. However, in recent years,
manufacturers have recognised the complementary strengths of CPUs and
FPGAs. This has led to the development of integrated systems, which can
be split into two categories, which are soft or hard processors. A soft
processor is realised using the programmable logic resources of an FPGA.
It’s essentially a processor described in a hardware description
language, such as VHDL or Verilog, which is then synthesised and mapped
onto the FPGA’s logic blocks. This design offers flexibility, allowing
designers to modify the architecture, add custom instructions, or adjust
interfaces as needed, with Xilinx MicroBlaze<span class="citation"
data-cites="AMD_2023"></span> and Intel Nios V<span class="citation"
data-cites="Intel_2023"></span> being notable examples. In contrast, a
hard processor is a physical processor core embedded directly into the
FPGA silicon which is optimised and hard-wired for better performance
and efficiency. The ARM Cortex cores found in newer Xilinx’s Zynq
FPGAs<span class="citation" data-cites="AMDSoftProcess"></span> are
typically connected to the programmable logic elements through an AXI
(Advanced eXtensible Interface) protocol for efficient data transfer and
communication.</p>
<p>Initially, soft CPUs were utilised for pre-processing, task
scheduling, and resource management. However, collaborative execution,
where tasks are computed by both accelerators, have emerged as a
prominent approach for increasing application performance, as
demonstrated in the literature <span class="citation"
data-cites="HuaChEL19 RajDarSum23 YiaRos05"></span>. In image
processing, soft processors have been shown to be more energy efficient
and have comparable runtimes than their counterpart discrete processors
for low-high complexity algorithms, which is shown in the works <span
class="citation" data-cites="SidAmmin19 CheCha10 HonOlePol14"></span>.
The performance gains extend into the deep learning domain such as CNNs
are presented in literature <span class="citation"
data-cites="MelCapDeri28 ZhaPra17 zenpras20 MossNurSim17"></span>.</p>
<p>In summary, hard processors typically outperform soft processors in
both speed and resource utilisation due to their independence from FPGA
fabric speed and separate chip placement, resulting in enhanced clock
speeds and efficient data path designs. Soft processors excel in power
efficiency and adaptability, catering to scenarios prioritising
energy-conscious designs and dynamic modifications during rapid
prototyping and development stages. The architectural distinctions align
each processor type with specific application requirements within
FPGA-based computing landscapes.</p>
<h3 id="cpu-gpu-fpga-architectures">CPU-GPU-FPGA Architectures</h3>
<p>FPGAs offer the advantage of direct hardware mapping for efficient
implementation of CNNs<span class="citation"
data-cites="NguNguKim19"></span>, but they are often constrained by
limited on-chip resources<span class="citation"
data-cites="ShawSai19"></span>. The complexity and size of
state-of-the-art CNNs often exceed the available logic and memory
resources on a single FPGA chip. To mitigate this limitation, a
heterogeneous approach can be employed where different layers of the CNN
are mapped onto both FPGA and GPU platforms. This leverages the FPGA’s
efficiency for specific layers while utilising the GPU’s computational
power for more complex layers, thereby creating a balanced and optimised
system.</p>
<p>Recent work into partitioning and executing algorithms onto
heterogeneous CPU-GPU-FPGA architectures has been explored in the
literature, collected in Table <a href="#CPUGPUFPGA"
data-reference-type="ref" data-reference="CPUGPUFPGA">[CPUGPUFPGA]</a>.
The platforms category records the combination of accelerators that
compose the heterogeneous platform in which the algorithm has been
distributed across. The results for energy gain and runtime speedups are
derived from comparing the algorithm executed on a single GPU.
Partitioning strategy refers to the level of detail at which operations
are divided on a heterogeneous platform. In a coarse-grained
implementation, entire algorithms or large functional blocks are
distributed across different processors within the system. Conversely, a
fine-grained implementation maps individual components or layers of an
algorithm to specific processors, allowing for more targeted
optimisation and resource utilisation. Across all studies, a range of
<span class="math inline">\(1\sim4\times\)</span> speedup and <span
class="math inline">\(1\sim2.3\times\)</span> energy improvement is
observed from various partitioning techniques. The key areas identified
from all works are that the limiting factors for performance are
communication latency, resource availability, coarse partitioning
strategies and limited optimisations. In all works, CNN algorithms were
implemented partially (<em>e.g.</em>, Convolution Layer Only) or did not
pass data to other accelerators, therefore not utilising true
heterogeneity.</p>
<h2 id="asic-architecture">ASIC Architecture</h2>
<p>ASICs are highly efficient because they are purpose-built and don’t
require additional support hardware. They integrate all necessary
components on a single chip, minimising external dependencies and
reducing overall system complexity, making them ideal for streamlined
and dedicated image processing tasks<span class="citation"
data-cites="RivPenMolo18 kyrPapEli19"></span>. VPUs have been shown to
achieve similar performance to reference CPUs, GPUs and FPGAs.
Additionally, benchmarking of NPUs within mobile platforms has shown to
be better in runtime than desktop CPUs and comparable to GPUs while
consuming less energy<span class="citation"
data-cites="IgnTimKul19"></span>.</p>
<h2 id="image-processing-optimisations">Image Processing
Optimisations</h2>
<p>Optimisations are necessary for improving overall system performance,
There are three primary categories. First, Hardware optimisations which
include optimising memory architectures, computation engine and
integrating additional accelerators. Algorithmic optimisations focus on
improving the computational procedures, ensuring efficient solving
strategies. Lastly, domain-specific optimisations leverage domain
knowledge and characteristics inherent to image processing which aim to
improve performance, accuracy, and computational efficiency. This
section explores optimisation techniques tailored for image processing
and CNN algorithms across various hardware accelerators, primarily
focused on FPGAs.</p>
<h3 class="unnumbered" id="hardware-optimisations">Hardware
Optimisations</h3>
<p>In image processing, memory usage primarily contributes to overall
energy consumption and runtime, especially when algorithms require
complete frames to be stored in memory<span class="citation"
data-cites="FanZhanYu17"></span>. However, accelerators such as FPGAs
have resource limitations, making efficient utilisation critical for
meeting performance, size, and power constraints<span class="citation"
data-cites="HajBenWal18"></span>. Hardware-based memory optimisations
can be classified into on-chip and off-chip categories:</p>
<p>On-chip: Involves optimising the use of fast but limited on-chip
memory resources like Block RAM in FPGAs or L1/L2 caches in CPUs and
GPUs.</p>
<p>Off-chip: focuses on optimising the use of larger but slower off-chip
memory like DDR RAM.</p>
<p><strong>Line buffers</strong> are a memory optimisation technique
used in convolution-based algorithms by minimising redundant memory
access. The first few lines of the image or signal are loaded into the
line buffer, marking the only time these lines are fetched from the main
memory. As the convolution operation progresses through the image or
signal, the lines already in the buffer are reused to calculate multiple
output pixels, thereby eliminating the need to fetch the same lines from
the main memory again. When moving to the next set of lines, the buffer
shifts, discarding the oldest line and fetching a new one to ensure that
the lines immediately needed for the convolution are always available.
This data reuse and line shifting minimises the number of times the
slower main memory has to be accessed. Line buffers have been explored
throughout literature <span class="citation"
data-cites="SonLeeKo14 FanZhaYan17 ZhaXiaHu07 AsaMaeYam09"></span>.
Ping-pong buffers employ a dual-buffering scheme, where two or more
buffers alternate roles in a synchronised manner. This approach allows
one buffer to be filled with new data while the other is being
processed, thereby increasing the throughput by speeding up the
read/write process <span class="citation"
data-cites="JiaXiaZha14 BaiZhaHua18 liuzoudan19"></span>.</p>
<figure id="fig:pipelining">
<img src="Images/Pipelining.png" />
<figcaption>Hardware Pipelining: concurrent processing of multiple
stages in a computational task, enhancing throughput and reducing
latency.</figcaption>
</figure>
<p><strong>Pipelining</strong> is a technique used to increase the
throughput by partitioning complex operations into discrete, independent
stages implemented within logic elements like LUTs and flip-flops. Each
stage performs a specific operation and is clocked separately, allowing
for concurrent execution of multiple data elements across stages shown
in Fig. <a href="#fig:pipelining" data-reference-type="ref"
data-reference="fig:pipelining">3.2</a>. In the works of, Jiang <em>et
al.</em><span class="citation" data-cites="JiaXiaZha14"></span> and
Bai <em>et al.</em><span class="citation"
data-cites="BaiZhaHua18"></span>, significantly improved throughput in
their designs, the data generated by each operation was transferred to
the next operation without storage, reducing resource consumption and
off-chip latency. Additionally, It is important to ensure stage
independence for maximum parallelism and to balance resource utilisation
to avoid bottlenecks.</p>
<p><strong>Look-up tables</strong> (LUTs) are an effective optimisation
technique to increase efficiency<span class="citation"
data-cites="RyuNisTos09 MesvAI01"></span>. LUTs pre-compute and store
the results of frequently used operations, allowing for rapid retrieval
and eliminating the need for redundant calculations. In addition, for
more complex expressions, such as square roots or multiplying and
dividing by an arbitrary number, look-up tables (LUT) and raster based
incremental methods can offer improved performance.</p>
<p><strong>Memory architecture</strong> can significantly impact both
performance and energy efficiency, especially when dividing on-chip
memory into smaller blocks to allow parallel access and reduce latency.
However, the choice of parallelism influences the required memory
organisation and, consequently, the total energy consumption, which is
explored in literature<span class="citation"
data-cites="KadLakDav16 KadLak15"></span>. Following on previous works,
Tessier <em>et al.</em><span class="citation"
data-cites="TessBetzNet07"></span> showed on-chip power reduction
through converting user-defined memory specifications to on-chip FPGA
memory block resources. FPGAs often have fixed-size memory that may not
align well with the task at hand, leading to energy overhead.
Partitioning techniques are therefore required to efficiently manage the
storage and processing needs of image data. In the work, Garcia <em>et
al.</em><span class="citation" data-cites="GarBhoSte19"></span>, showed
that effectively partitioning image frames into BRAMs in order to
maximise utilisation (ie, minimise the number of required on-chip
memories) can reduce power consumption without affecting the
performance. Various off-chip caching systems have been developed to
mitigate the latency overheads, such as a three-level memory access
architecture proposed by Zhang <em>et al.</em><span class="citation"
data-cites="ZhaWeiChe19"></span>. This architecture includes off-chip
memory, on-chip buffers, and local memories. Nonetheless, the system
entails significant waiting times for valid signals between Block RAMs
(BRAMs) and off-chip memory, introducing delays.</p>
<p><strong>Approximate computing</strong> techniques can significantly
improve computational throughput and energy efficiency in image
processing tasks when implemented on FPGAs<span class="citation"
data-cites="Mit16"></span>. These methods trade off a small degree of
accuracy for performance gains. Two primary strategies are generally
used: the first leverages approximate arithmetic for reduced-precision
calculations, while the second aims to decrease the total number of
operations without substantially affecting output quality. These
approaches can be integrated into the learning or optimisation stages to
balance both accuracy and computational demands effectively. One study
has shown using lower-bit precision like INT8 and INT4 significantly
speeds up neural network inference on various architectures. For
example, INT8 inference led to up to 5.02× speedup on GPUs, and INT4
added another 50-60% speed gain. Mix-precision further improved
ResNet50’s speed by 2% without accuracy loss. These benefits extend to
non-GPU platforms, achieving up to 2.35× speedup <span class="citation"
data-cites="AmiSehzhe21"></span>.</p>
<h4 class="unnumbered" id="cnn-hardware-optimisations">CNN Hardware
Optimisations</h4>
<p>CNNs have now become a popular method of feature extraction and
classification. Therefore, this section explores hardware-based
optimisation techniques that improve performance. Optimising CNNs on
hardware accelerators requires careful algorithm-to-hardware mapping and
resource management. The convolutional and fully connected layers are
typically the most resource-intensive in terms of both computational
logic and memory footprint. Specifically, the storage of high-precision
weights and biases for these layers can consume substantial portions of
on-chip memory, while the multiply accumulate (MAC) operations required
for convolutions and activation’s demand significant computational
resources as discussed by Laith <em>et al.</em><span class="citation"
data-cites="LaiJinAmj21"></span>.</p>
<p>Multiple techniques address these challenges. Firstly, pruning is a
compression technique that reduces the model’s complexity<span
class="citation" data-cites="Ree93"></span>. These methods identify and
remove weights and neurons that contribute minimally to the model’s
predictive performance, usually based on certain statistical or
empirical thresholds. Pruning lessens the memory footprint, reducing the
storage required for high-precision weights and biases. At its simplest
level, pruning removes the smallest weights, setting them to zero as
demonstrated by Song <em>et al.</em><span class="citation"
data-cites="han2016deep"></span>. When optimised for energy consumption,
pruning techniques that target the least energy-consuming weights
achieved a <span class="math inline">\(1.74\times\)</span> gain in
efficiency compared to traditional approaches <span class="citation"
data-cites="yang2017designing"></span>. In both methods, the pruned
network is fine-tuned to maintain the classification accuracy. Multiple
studies demonstrate that pruning eliminates <span
class="math inline">\(53\%\)</span> to <span
class="math inline">\(85\%\)</span> of weights in a CNNs convolutional
and fully connected layers while losing around <span
class="math inline">\(0.5\sim1\%\)</span> accuracy <span
class="citation" data-cites="NIPS2015_ae0eb3ee HeZhaSun17"></span>.
Table <a href="#tab:hardware_optimisations" data-reference-type="ref"
data-reference="tab:hardware_optimisations">[tab:hardware_optimisations]</a>
summarises optimisations techniques found in hardware.</p>
<h3 class="unnumbered"
id="domain-specific-optimisations">Domain-Specific Optimisations</h3>
<p>Domain-specific optimisations within the imaging domain are methods
tailored to increase the performance of applications. These
optimisations leverage the unique characteristics of image processing.
Such optimisations often involve exploiting properties like spatial
locality, symmetry, and redundancy present in images. In literature,
there has been very little research on platform agnostic domain-specific
optimisations of imaging algorithms on FPGAs. Domain-specific tools and
optimisations, particularly in areas such as compilers <span
class="citation"
data-cites="RaagBarCon13 TanChoRez11 ChrMehUdayBon21"></span>, have been
explored but not yet reached maturity.</p>
<p>In the field of image processing, domain-specific optimisations aim
to significantly reduce computational load while maintaining consistent
accuracy. Examples of such optimisations include down-sampling <span
class="citation" data-cites="LinDon06"></span>, approximation<span
class="citation" data-cites="SharZha16"></span>, data-type
conversion <span class="citation" data-cites="YonLiGuo01"></span>,
kernel size adjustments <span class="citation"
data-cites="NikMaiLon17"></span>, bit-width modification <span
class="citation" data-cites="WanLouQui18"></span>, and the complete
removal of certain operations. Although hardware acceleration techniques
for algorithms on CPUs, GPUs, and FPGAs have been extensively
researched <span class="citation"
data-cites="WanWenYan15 SteFraStu14 RisBlaWan13"></span>, these studies
generally focus only on target algorithms. In contrast, there has been
limited work on exploring the performance and accuracy trade-offs of
domain-specific optimisations of imaging algorithms specifically for
FPGAs.</p>
<p><strong>Downsampling</strong> is a popular method used to reduce the
amount of data in an image by selectively removing samples. This
involves reducing the resolution of an image by eliminating pixels,
usually through averaging or taking the value of a representative pixel
in a local neighbourhood. The aim is to decrease computational
complexity and storage requirements, making it easier to process and
analyse the data. However, downsampling comes with the trade-off of
losing some level of detail, which may be critical for certain
applications. It is essential to choose an appropriate downsampling
factor and method to balance computational efficiency with the
preservation of important features in the data.</p>
<p><strong>Fast Fourier Transform</strong> is an algorithm to compute
the Discrete Fourier Transform (DFT) and its inverse in a more efficient
manner. It capitalises on the properties of symmetry and periodicity in
the Fourier domain to reduce the number of arithmetic operations.
Instead of directly convolving spatial or time-domain signals, FFT first
transforms both the input signal and the kernel into the frequency
domain. Here, the convolution operation transforms into a simpler
element-wise multiplication. After this multiplication, an inverse FFT
(IFFT) is applied to bring the data back to the spatial or time domain.
The FFT algorithm reduces the computational complexity from <span
class="math inline">\(O(n^2)\)</span> for direct convolution to <span
class="math inline">\(O(n \log n)\)</span>, making it highly efficient,
especially for larger kernels. The use of FFTs in image processing is
found in many works <span class="citation"
data-cites="RioDuh92 FiaCad06 ZhaCheSon16"></span>. However, FFT is
hardware-intensive due to its high memory bandwidth requirements and
arithmetic complexity, which can lead to increased power
consumption.</p>
<p>Additional work by Qiao <em>et al.</em> <span class="citation"
data-cites="QiaReiOli19"></span> proposed a minimum cut technique to
search fusible kernels recursively to improve data locality. Rawat
<em>et al.</em> <span class="citation" data-cites="RawPraVad"></span>
proposed multiple tiling strategies that improved shared memory and
register resources. However, such papers propose constrained
domain-specific optimisation strategies that exclusively target CPU and
GPU hardware. In related work, Reiche <em>et al.</em> <span
class="citation" data-cites="ReiKonMar15"></span> proposed domain
knowledge to optimise image processing accelerators using high-level
abstraction tools such as domain-specific languages (DSL) and reusable
IP-cores. Additional optimisation techniques commonly used in
general-purpose computing, such as loop unrolling, fission, and fusion,
do not map effectively onto FPGA architectures due to the distinct
operational paradigms and resource constraints inherent to FPGA design.
Consequently, there is a need for the development of
accelerator-agnostic and domain-specific optimisation strategies that
can be universally applied across diverse computational platforms,
including CPUs, GPUs, and FPGAs, for a more cohesive and efficient
heterogeneous design.</p>
<h3 class="unnumbered" id="algorithmic-optimisations">Algorithmic
Optimisations</h3>
<p>Algorithmic optimisations refer to techniques employed to exploit
mathematical properties or patterns in the data being processed.
Strategies may include the use of more efficient data structures,
dynamic programming, divide and conquer techniques, and algorithmic
transformations. Convolution operations are used in many image
processing algorithms which typically account for the majority of
computation time. Various algorithmic convolution optimisation
strategies are discussed below:</p>
<p>The <em>Strassen</em><span class="citation"
data-cites="STRASSEN1969"></span> algorithm optimises matrix
multiplication through recursive partitioning. Given two <span
class="math inline">\(n \times n\)</span> matrices, <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span>, it divides each into four submatrices
and recursively computes seven intermediate products (<span
class="math inline">\(M_1\)</span> to <span
class="math inline">\(M_7\)</span>). These products are combined to
yield the final matrix using additions and subtractions. The algorithm’s
time complexity of <span class="math inline">\(O(n^{\log_2{7}})\)</span>
improves upon the <span class="math inline">\(O(n^3)\)</span> complexity
of naive multiplication, particularly advantageous for larger matrices.
However, its practicality diminishes for smaller matrices due to
increased constant factors and memory requirements associated with
additional operations. The algorithm has shown to be effective in
reducing the computational complexity without losing accuracy in CNN
algorithms<span class="citation" data-cites="ZhaWanWan18"></span>.</p>
<p>The <em>Winograd</em><span class="citation"
data-cites="winograd1980arithmetic"></span> filter algorithm utilises
minimal filtering algorithms to perform convolutions, particularly
advantageous for small kernel sizes <span class="math inline">\(K \leq
3\)</span>. It transforms the convolution operation into a set of
polynomial multiplications in a transformed domain. The idea is to
decompose the convolution into smaller, overlapping tiles and then apply
the Winograd transformation to each tile separately. This results in a
significant reduction in the number of multiplicative operations, which
are computationally more expensive than additive operations. Numerous
works in literature implementing and comparing Winograd performance
<span class="citation" data-cites="Lavin2015FastAF YepKo20"></span>. In
comparison to FFT-based methods which also reduce the number of
multiplications by transforming the convolution into a point-wise
multiplication in the frequency domain. However, these methods introduce
the overhead of complex-to-real transformations and are more
computationally intensive for small kernel sizes due to the increased
number of additions and the need for padding.</p>
<p>Specific image processing algorithms often require sorting pixels
(e.g., median filtering). These algorithms can benefit from parallel
sorting network algorithm optimisations. Sorting networks consist of a
predefined sequence of compare-and-swap operations, often organised in a
pipeline or tree-like structure, enabling simultaneous execution. In the
case of median filtering, sorting networks such as Batcher’s Odd-Even
Mergesort<span class="citation" data-cites="Bat68"></span> can be
implemented to sort the values in the input window in parallel, thereby
reducing time complexity<span class="citation"
data-cites="KimKimSun15"></span>.</p>
<p>In CNNs, algorithmic optimisations are commonly used to reduce
runtime for both convolutional and fully connected (FC) layers. General
Matrix Multiply (<code>GEMM</code>) is a key method for implementing
these layers, as indicated in <span class="citation"
data-cites="KimNamJun17 CheDiJai16"></span>. In the FC layer,
<code>GEMM</code> proves effective for batch processing feature maps
(FMs), organised as a <span class="math inline">\(CHW \times B\)</span>
matrix. In which <span class="math inline">\(C\)</span> represents the
number of channels, <span class="math inline">\(H\)</span> for height,
<span class="math inline">\(W\)</span> for width, and <span
class="math inline">\(B\)</span> for the batch size. This approach
optimises computational throughput and memory bandwidth by loading
weights just once per batch. Given that FC layers house the majority of
CNN weights, <code>GEMM</code> significantly enhances computational
speed, especially with increasing sparsity in the FC weight matrix.</p>
<h2 id="high-level-synthesis">High-Level Synthesis</h2>
<p>High-level synthesis (HLS) is a potential solution to increase the
productivity of real-time image processing development on FPGAs. In
order to close the performance gap between the manual and HLS-based FPGA
designs, various code optimisations that exploit FPGA architecture for
potential speedups are made available in today’s HLS tools. At present,
there are various high-level synthesis compilers that are being
developed commercially and in academia, shown in table <a
href="#tab:HLS" data-reference-type="ref"
data-reference="tab:HLS">[tab:HLS]</a>.</p>
<p>Efficient code optimisation by HLS compilers is vital in real-time
image processing applications, where the goal is to minimise execution
time and resource utilisation <span class="citation"
data-cites="SolJinSen19"></span>. Furthermore, the quality of generated
Register Transfer Level (RTL) descriptions in High-Level Synthesis (HLS)
is found to be influenced by the high-level language used, prompting a
need for optimised approaches <span class="citation"
data-cites="ConLiuPra12"></span>. Notably, comparative research
underscores significant performance gaps between HLS-based designs and
manually crafted counterparts for intricate applications <span
class="citation" data-cites="JasMuhYi11 RupLiaLi11 LiaRupLi12"></span>.
Noteworthy disparities of up to 40 times in performance have been
documented, particularly evident in demanding tasks like high-definition
stereo matching.</p>
<p>Several contemporary avenues in HLS compiler optimisation merit
exploration. In the work <span class="citation"
data-cites="HuaLiaCan13"></span>, investigates the impact of compiler
optimisations on hardware generated by HLS tools, highlighting the
significance of both the optimisation strategies and their sequential
application order in enhancing the RTL output quality. In addition, a
subsequent study <span class="citation"
data-cites="ChaYanBen17"></span>, refines the understanding of HLS-based
real-time image processing design optimisations. Applying a sequence of
optimisation techniques, this approach showcases comparable performance
when benchmarked against alternative methodologies and industry-standard
HLS tools. The optimisations applied in both works include:</p>
<p><strong>Function In-lining:</strong> Incorporating functions directly
into the code to eliminate function call overhead and improve overall
performance.</p>
<p><strong>Loop Manipulation:</strong> Adjusting loop structures to
enhance computational efficiency and reduce processing time.</p>
<p><strong>Symbolic Expression Manipulation:</strong> Utilising symbolic
expressions to manipulate mathematical representations for improved
computational speed and precision.</p>
<p><strong>Loop Unrolling:</strong> Expanding loops by replicating their
bodies to reduce loop-control overhead and maximise parallelism.</p>
<p><strong>Array Transformation:</strong> Applying various techniques to
optimise arrays, the two commonly applied techniques are listed:</p>
<p><strong>Array Partitioning:</strong> Dividing arrays into smaller,
more manageable partitions to enhance data locality and optimise
parallel processing.</p>
<p><strong>Array Reshaping:</strong> Modifying the shape of arrays to
better align with computation requirements, improving overall efficiency
in data processing.</p>
<p>The advantages of HLS tools observed by Wakabayashi <em>et
al.</em><span class="citation" data-cites="Kaz04"></span>, on elevating
abstraction levels highlight how expressing designs in higher-level
languages like C and C++ can significantly reduce code complexity,
making them better at managing complex designs more effectively.</p>
<h3 class="unnumbered"
id="domain-specific-languages-dsl-1">Domain-Specific Languages
(DSL)</h3>
<p>A domain-specific language (DSL) is a specialised programming
language for a particular domain, such as image processing. The
following paragraphs look into some recent developments of DSLs within
image processing. In contrast to C/C++ with HLS tools, DSLs provide
clearer syntax, rigorous semantic checks and possible compiler domain
optimisations for improved generated code. A summary of available DSLs
is found in Table <a href="#tab:DSL" data-reference-type="ref"
data-reference="tab:DSL">[tab:DSL]</a>.</p>
<p>Richard, Membarth <em>et al.</em><span class="citation"
data-cites="MemReiHan16"></span> proposed a new DSL and source-to-source
compiler for image processing called ’Hipacc’. They show that domain
knowledge can be captured to generate tailored implementations for
C-based HLS from a common high-level DSL description targeting FPGAs and
GPUs. The image processing algorithms that were generated in
VHDL/Verilog code from the DSL are evaluated by comparing them with
hand-written register transfer level (RTL) implementations. The results
show that the HLS still has deficiencies in contrast to the RTL but
enables rapid design space exploration. The Hipacc framework does not
generate the hardware descriptor language but relies on Xilinx’s HLS
tools for generated HDL optimisations.</p>
<p>In the work by Jocelyn, Serot <em>et al.</em><span class="citation"
data-cites="SerBerAhm11"></span> presented CAPH, a DSL suited to
implementing stream-processing based applications on FPGA. CAPH relies
upon the actor/dataflow model of computation and the tool suite also
contains a reference interpreter and a compiler producing both SystemC
and VHDL code. CAPH was evaluated by implementing a simple real-time
motion detection on an FPGA platform. This was done to validate the
overall methodology and to identify key issues. The results established
three research directions to improve CAPH. The first is assessing the
tools on larger and more complex applications and comparing them with
hand-crafted RTL in terms of resource usage and runtime. The second
research direction is improving the compiler and optimising the
generated VHDL code. Third, applying static analysis techniques to actor
behaviours to statically estimate the size of FIFO channels.</p>
<p>Another DSL for FPGAs was proposed by Robert, Stewart <em>et
al.</em><span class="citation" data-cites="SteDunMic18"></span> called
RIPL. The aim is to increase throughput by maximising clock frequency
and minimising resource usage to fit complex algorithms onto FPGAs. RIPL
introduces an algorithmic skeleton to express image processing
algorithms which are then exploited to generate deep pipelines of highly
parallel and memory-efficient image processing components. The data-flow
graph generated is expressed in CAL actor language and is compiled into
Verilog. The DSL was used to implement image watermarking and
multi-dimensional subband decomposition algorithms.</p>
<h2 id="benchmarking">Benchmarking</h2>
<p>Benchmarking is a relatively established concept in computing,
serving as a crucial tool to gauge the performance of various systems.
Identifying the most suitable hardware platform becomes imperative,
especially when aiming for efficiency and performance. Yet, the
challenge lies in determining this without investing significant time
and understanding into implementations. Thus, benchmarking measures
performance and aids in making informed decisions about hardware
compatibility for complex algorithms.</p>
<p>Numerous benchmarking studies have been conducted on a variety of
accelerators, including FPGA <span class="citation"
data-cites="GauAltPin16"></span>, GPU <span class="citation"
data-cites="AllHorAgar08"></span>, TPU <span class="citation"
data-cites="JouYouPat18"></span>, and NPU <span class="citation"
data-cites="qi2023vpuem"></span>. These studies assess performance using
specific metrics and facilitate comparisons between different hardware
platforms <span class="citation" data-cites="QasMurDen19"></span>.
Additionally, recent interest in the industry has begun to develop
suites such as MLPerf <span class="citation"
data-cites="RedJanChe2020"></span> and DataPerf <span class="citation"
data-cites="mazumder2023dataperf"></span> to establish a standardised ML
benchmarking and evaluation to allow comparison of inference/training
chips or models.</p>
<p>Early work in heterogeneous benchmarking was the introduction of the
Rodinia suite in 2009 <span class="citation"
data-cites="CheBoyMic09"></span>. Rodinia comprises applications and
kernels that embody the behaviours of the Berkeley dwarfs. These are a
taxonomy of 13 computational patterns widely used in various scientific
domains. The suite also addresses communication, synchronisation, and
power consumption issues. However, Rodinia does not leverage newer
features, such as advanced heterogeneous programming constructs,
half/mixed precision, tensor computations, and libraries that enhance
communication between architectures. Instead, Rodinia focuses on more
abstract algorithms rather than micro-benchmarks that target specific
components.</p>
<p>Scalable Heterogeneous Computing (SHOC) <span class="citation"
data-cites="DanMarMcC10"></span> developed in 2010 as another benchmark
suite targeting heterogeneous systems. The suite primarily focused on
scientific computing workloads, including common kernels such as matrix
multiply, fast Fourier transform, and Stencil computation. The benchmark
is divided into two testing methods: The stress tests use
computationally demanding kernels to identify OpenCL devices with bad
memory, insuﬃcient cooling, or other device component problems. The
other tests measure many aspects of system performance on several
synthetic kernels as well as common parallel operations and algorithms.
SHOC supports various versions of benchmarking, from serial to testing
inter-communication between architectures. Every application in the SHOC
suite operates within a cohesive framework that allows users to define
specific testing parameters, including the desired number of iterations.
The framework can also capture intricate metrics, such as floating-point
operations per second (FLOPS). The drawback to SHOC is that it focuses
on basic parallel algorithms, thus missing the nuance of real-world
applications; just like Rodinia, it has not been updated to test modern
algorithms and cannot scale to larger problem sizes.</p>
<p>In recent work, Mirovia <span class="citation"
data-cites="Hu2019MiroviaAB"></span> builds upon both Rodinia and SHOC,
designed to leverage the newer evolving architectures. While also
representing a diverse set of application domains. This includes a
particular focus on deep neural networks. Mirovia aims to characterise
modern heterogeneous systems better. The benchmark suite falls short in
the range of hardware it can target, being limited to Compute Unified
Device Architecture (CUDA) enabled GPU only. Other work focuses on a
single domain area; <em>QuTiBench</em> <span class="citation"
data-cites="BloHalLis"></span> is a multi-tiered framework for neural
networks which introduces optimisation strategies such as quantisation,
which is essential for specific accelerators such as FPGAs. Only the
classification stage of the image-signal processing pipeline is tested
within the framework; therefore, determining the full performance scope
of a vision system is difficult. Reuther <em>et al.</em> <span
class="citation" data-cites="ReuAlbMich19"></span> proposed a survey and
benchmarked machine learning algorithms on commercial low-power ASICs
and a CPU. However, such papers propose benchmarks and frameworks for
specific algorithms or target singular architectures, focusing only on
execution time performance. In addition, power consumption and memory
transfer metrics are often missing in such benchmarks, which is a
driving factor for embedded systems with limited energy.</p>
<h2 id="evaluated-image-processing-algorithms">Evaluated Image
Processing Algorithms</h2>
<p>This section outlines the implementation details on hardware
(primarily FPGA) and the rationale behind the selection of various
algorithms evaluated in the subsequent chapters. All algorithms were
partly chosen due to their popular use in many image processing
pipelines and varying complexity. The CPU and GPU image processing
implementations of all algorithms are derived from OpenCV <span
class="citation" data-cites="opencv_library"></span>. The FPGA
implementations have been reviewed in literature to develop widely
adopted methods (Algorithmically the same as CPU &amp; GPU for fair
comparison), which, at best, are close to the most optimal design.</p>
<p><strong>RGB2Grey, Image Addition, Subtraction:</strong> These
operations serve as fundamental building blocks in image processing
pipelines. Converting images to grayscale simplifies processing tasks,
reduces memory usage, and enhances contrast for improved feature
detection. Grayscale images directly represent luminance, making them
useful for detecting subtle brightness variations. In addition, grey
images have widespread compatibility, require less storage space, and
can help reduce noise levels, resulting in clearer images for analysis.
Image addition can adjust brightness or contrast by adding or
subtracting constant values, while subtraction can isolate foreground
objects through background subtraction or detect changes in scenes over
time.</p>
<p>The FPGA colour conversion module declares parameters for the
dimensions of the image (m columns by n rows) and defines registers to
store the input colour image in BMP format and the resulting grayscale
image. Upon initialisation, the module reads the input colour image data
from a BMP file into memory. Then, it iterates over each pixel in the
image, extracting the red, green, and blue colour values and calculating
their sum. This sum is divided by 3 to obtain the grayscale value, which
is stored in a register. The image addition and subtraction module
functions by performing pixel-wise arithmetic operations between
corresponding pixels in two input images. The modules primarily use
registers and combinational logic to perform pixel-wise
addition/subtraction of two images.</p>
<p><strong>Resizing:</strong> Resizing operations are essential for
various image processing applications, including scaling images for
different display resolutions or aspect ratios. Many algorithms and CNN
architectures require images to be resized to reduce computation
complexity.</p>
<p>The <code>imageResize</code> module facilitates the resizing of input
image data by adjusting its width and depth based on specified scaling
factors. The resizing operation involves updating counters for tracking
column, row, and pixel positions within the image. As the module
receives valid input data and a ready signal, it increments these
counters accordingly. When the counters reach the desired scaling
factors for width and depth, the module resets them to zero, effectively
resizing the image. The output image data is synchronized with the clock
signal and becomes valid only when both the column and row counters are
zero, ensuring proper alignment with the resized image dimensions.</p>
<p><strong>Erode, Dilate:</strong> Morphological operations like erosion
and dilation are commonly used for tasks such as image segmentation and
feature extraction. The module <code>erodeDilate</code> operates on
grayscale images represented by 8-bit pixel values. A 3x3 buffer array
is utilised to store neighbouring pixel values for each input image
pixel. Upon initialisation or reset, the buffers and output values are
cleared. As new pixel values arrive with each clock cycle, the buffer
contents are shifted accordingly.</p>
<p>For erosion, the module computes the logical AND operation of all
pixels in the 3x3 neighbourhood, resulting in the minimum pixel value.
Conversely, dilation computes the logical OR operation, resulting in the
maximum pixel value. These operations are performed on the buffer
contents corresponding to the current pixel position. Finally, the
resulting eroded or dilated pixel value is output along with its
validity signal.</p>
<p><strong>Box Filter, Gaussian Filter:</strong> Filters like the box
filter and Gaussian filter are fundamental for image smoothing and noise
reduction.</p>
<p>The Verilog code comprises modules designed for linear filters. The
"line Buffer" module functions as a storage mechanism for incoming pixel
data, organising it into line buffers to facilitate subsequent
convolution operations. It efficiently manages the storage and shifting
of pixel data as needed. The "imageControl" module orchestrates the flow
of pixel data, determining when to initiate reading and writing
operations based on the availability of data and signalling when to
begin filtering. It tracks the total number of pixels processed to
ensure accurate filtering across the image. The "conv" module is
responsible for executing the convolution operation itself. It performs
element-wise multiplication of pixel values with corresponding kernel
coefficients and aggregates the results to generate the convolved pixel
output.</p>
<p><strong>Sobel Filter, Median Filter:</strong> The Sobel filter is
widely used for edge detection, while the median filter is effective for
noise removal. The Sobel operator consists of two 3x3 kernels: one for
detecting vertical edges and the other for horizontal edges. The module
takes nine input pixel values corresponding to the 3x3 neighbourhood
surrounding a central pixel. These input pixels are named according to
their relative positions: Within the module, two instances of the
<code>matrixmul</code> module compute the gradient components along the
x-axis (<code>gx</code>) and y-axis (<code>gy</code>) using the Sobel
kernels. The result of each multiplication operation is squared to
obtain the squared gradient magnitudes in the <code>gxsquared</code> and
<code>gysquared</code> wires. These squared magnitudes are then added
together to compute the overall squared gradient magnitude in the
<code>squaredsum</code> wire. The <code>sqrt</code> module calculates
the square root of the squared gradient magnitude.</p>
<p>The <code>median filter</code> module takes in pixel values (pixelin)
of image width and operates on a square filtering window of fixed size.
Within each processing cycle, the module updates the window with new
pixel values, sorts the window values to find the median value, and
outputs the median as the filtered pixel value (pixelout). The algorithm
maintains internal registers to store the window and the histogram-based
sorted window of pixel values. During reset, the internal registers are
initialised, and processing flags are reset.</p>
<p><strong>White Balance:</strong> White balance adjustment is essential
for achieving accurate colour representation in images captured under
different lighting conditions.</p>
<p><code>WhiteBalance</code> module is designed to perform white balance
adjustment on an input image by adjusting the red, green, and blue
colour channels. It takes in pixel values for the red, green, and blue
channels of the image.</p>
<p>The module maintains buffers to accumulate the pixel values for each
colour channel (<code>redsum</code>, <code>greensum</code>,
<code>bluesum</code>) and a register to count the number of pixels
processed (<code>pixelcount</code>). These registers store the
accumulated sums and count, respectively. On each clock cycle, the
module accumulates the pixel values and updates the count. Then, it
calculates the average pixel values for each colour channel by dividing
the accumulated sum by the pixel count. Finally, it applies the white
balance coefficients to adjust the colour channels accordingly.</p>
<p><strong>Linearization: &amp; Gamma Correction</strong> Linearization
and gamma correction are essential in image processing, ensuring
consistent pixel representation and adjusting brightness and contrast
for good visual images, making them ideal for bench-marking.</p>
<p>The <code>Linearization</code> module is designed to linearize the
pixel values of an input image, effectively scaling them to a range
between 0 and 1. The module takes an 8-bit pixel value as input and
outputs the corresponding linearized value. It employs simple arithmetic
logic to divide the input pixel value by 255, the maximum value in an
8-bit system, thereby scaling it to the desired range. The linearization
process occurs on each clock cycle, ensuring real-time processing of
image data.</p>
<p><code>GammaCorrection</code> module applies gamma correction to an
input pixel value using a real gamma value of 2.2. The module operates
synchronously with the clock signal and includes a reset input for
initialisation. Inside the module, it takes the input pixel value and
applies a power function with an integer approximation of the gamma
value. The function then converts the gamma-corrected integer value back
to the [0, 255] range to ensure compatibility with pixel
representations. The module continuously applies the gamma correction
function to the input pixel value on each clock cycle. The output pixel
value is updated accordingly. The input and output pixel values are
stored in registers.</p>
<p><strong>GEMM:</strong> GEMM algorithm serves as a base building block
for numerous image processing and deep learning operations due to their
algorithmic efficiency in performing matrix multiplications. The
algorithm is computed in many areas of ML, such as fully-connected
layers, recurrent layers such as recurrent neural networks, Long
short-term memory or Gated recurrent unit, and convolutional layers.
Benchmarking GEMM allows for assessing the computational performance and
scalability of hardware architectures across a wide range of image
processing and deep learning algorithms. The optimised FPGA GEMM
implementations used for evaluation are provided by Xilinx<span
class="citation" data-cites="AMDGEMM"></span> library.</p>
<p><strong>FFT (DFT):</strong> Fast Fourier Transform (FFT) are found in
various operations in imaging algorithms by enabling efficient frequency
domain analysis and manipulation of images for tasks such as filtering,
convolution, registration, texture analysis, edge detection,
compression, and super-resolution imaging. Xilinx provided FFT
IP-block<span class="citation" data-cites="AMDFFT"></span> is used in
the benchmarking. The module implements the Cooley-Tukey FFT algorithm
for computing both forward and inverse DFTs of sample sizes that are
powers of 2.</p>
<p><strong>STREAM:</strong> Memory bandwidth and latency are important
metrics because they directly impact the speed and efficiency of data
transfer between the processor and memory. Therefore, when benchmarking
image processing algorithms, measuring memory bandwidth and latency
provides insights into how efficiently the algorithms utilise memory
resources, helping assess their overall performance and scalability. The
implementation used for FPGAs are from HPCC FPGA benchmarking suite<span
class="citation" data-cites="hpcc_fpga"></span>.</p>
<p><strong>Demosaicing:</strong> Demosaicing algorithms are essential
for reconstructing colour images from Bayer-pattern sensor data which
are common filter used in vision systems. The algorithm is a good choice
to benchmark since most vision systems use Bayer filter. Xilinx provided
de-mosaicing IP-block<span class="citation"
data-cites="AMDDemosiac"></span> is used in the benchmarking. The
demosaicing algorithm used is a bilinear interpolation, where missing
colour values in a Bayer-filtered image are estimated by averaging
neighbouring pixel values.</p>
<p><strong>SIFT:</strong> Scale-Invariant Feature Transform (SIFT) is a
widely used technique for feature extraction in image processing
applications. The FPGA implementation is discussed in Section <a
href="#SIFTHardwareDesc" data-reference-type="ref"
data-reference="SIFTHardwareDesc">[SIFTHardwareDesc]</a>.</p>
<p><strong>CNN (Classification):</strong> Convolutional Neural Networks
(CNNs) have become significantly popular methods for image
classification, object detection/segmentation tasks. Xilinx Deep
Learning Processor Unit (DPU) is used to implement both optimised
ResNet-18 and MobilnetV2 architectures<span class="citation"
data-cites="AMDDPU"></span>.</p>
<h2 id="conclusion-1">Conclusion</h2>
<p>This chapter delves into the discussion and evaluation of diverse
heterogeneous architecture implementations, tools, and optimisation
strategies. The literature review emphasises that specific processing
architectures, such as GPUs, FPGAs, and VPUs, exhibit greater efficiency
in executing imaging algorithms than CPUs, owing to their architectural
properties (<em>e.g.</em>, SIMD, DSP Slice) and depending on algorithmic
features like parallelisation and data dependencies. Moreover, these
architectures to exploit their advantages leads to further performance
gains. Various optimisations have also been shown to enhance the
efficiency of image processing algorithms, encompassing techniques such
as algorithm replacement, hardware (memory management) and pipelining
schemes. However, the knowledge gap is evident in the lack of a
systematic approach or set of strategies for partitioning imaging
algorithms onto the appropriate hardware accelerators in a heterogeneous
platform, nor a comprehensive rationale for such decisions. In addition,
there are no end-to-end implementations of CNN and feature extraction
algorithms utilising CPU-GPU-FPGA architectures. The absence of
image-domain-guided optimisations and understanding of trade-offs
further complicates achieving optimal performance and efficiency. Hence,
within the scope of this thesis, a robust benchmarking framework that
guides algorithm partitioning along with domain-specific optimisation
strategies on heterogeneous platforms is proposed.</p>
<h1 id="Harbour">HArBoUR: Heterogeneous Architecture Benchmarking on
Unified Resources</h1>
<p>This chapter presents a description of <em>HArBoUR</em>, a
heterogeneous imaging framework used for guidance and implementation of
various image processing algorithms presented in later chapters. In
addition, the chapter contains benchmarks and evaluations of micro/macro
image processing algorithms commonly found in imaging pipelines of
vision systems. The algorithm suitability on a specific accelerator is
determined from the analysis of the results.</p>
<p><span id="chap:HFrwk" data-label="chap:HFrwk"></span></p>
<h2 id="introduction">Introduction</h2>
<p>The advances in multi-core processors and accelerators have enabled
real-time embedded imaging algorithms to become ubiquitous within many
vision application areas such as advanced driver assist systems (ADAS)
<span class="citation" data-cites="GeiFraCha18"></span>,
surveillance<span class="citation" data-cites="FabBerFra07"></span> and
satellites<span class="citation" data-cites="BruBruHin15"></span>. The
growing demand for image processing algorithms on systems with resource
and energy constraints requires architectures that perform tasks
efficiently. These hardware accelerators come with various architectures
ranging from CPUs, GPUs, and FPGAs. Traditionally, embedded imaging
designs often involve implementing image processing algorithms on
homogeneous architectures, which come with hardware limitations.
However, recent developments introduce heterogeneous architectures that
combine multiple specialised accelerators on a singular interconnected
chip<span class="citation" data-cites="Xilinx"></span>. These novel
architectures provide optimum design opportunities for embedded imaging
development. However, current developments in targeting heterogeneous
platforms are still primitive and require careful consideration of
various development languages, tool-sets and performance profiles to
fulfil energy and runtime constraints of applications. Furthermore,
certain accelerators have pre-written optimised vision libraries,
<em>e.g.</em>, OpenCV/CUDA (for CPU/ GPU) and xfOpenCV (for FPGAs).
However, the design and development of image processing algorithms in a
heterogeneous environment is still an arduous task. It requires in-depth
knowledge of multiple hardware accelerators, and each differing in
performance due to their underlying architectures. Additionally, FPGA
designs require knowledge of hardware descriptor languages (HDLs), which
have higher learning difficulty despite the existence of recent
high-level synthesis tools or domain-specific languages that abstract
away from the underlying hardware. This is due to a lack of
understanding and the existence of benchmarks for image processing
algorithms on different hardware. Therefore, partitioning complex image
processing algorithms onto each accelerator remains a difficult task for
application designers.</p>
<p>Benchmarking has played an integral part within the computing domain
for decades. Since the beginning of computing systems, there has been a
persistent need to evaluate and compare the performance of hardware
components. Initially, with the early day mainframe computers to the
modern era of microprocessors, GPUs, and custom ASICs, benchmarking has
provided a standardised measure to gauge the efficiency, speed, and
capabilities of hardware devices. Over the years, benchmarking tools and
suites have played a pivotal role in driving technological advancements,
guiding design decisions, and ensuring that hardware meets the
ever-evolving demands of software applications.</p>
<p>To address the emerging demand for high performance vision hardware,
there is a need for a suitable benchmarking framework that dissects the
imaging/vision algorithms in a disciplined way and benchmarks their
performances (both energy and execution time) on all available target
hardware (<em>e.g.</em>, CPU, GPU and FPGA). To address such a gap, this
chapter proposes a new framework providing a systematic way of
implementing imaging designs on specialised platforms and perform
benchmarks on representative vision algorithms while assessing execution
time, memory latency and energy consumption. System designers will use
the proposed framework to identify appropriate hardware for the target
application and unlock the potential of a true heterogeneous system. The
main contributions of this chapter are:</p>
<p>We propose a framework that studies features of image processing
algorithms to identify characteristics. These characteristics help
partition complex algorithms into the most optimal target accelerators
within heterogeneous architectures.</p>
<p>The approach adopts a systemic and multi-layer strategy that offers
trade-offs between runtime, energy and accuracy within the imaging
sub-domains <em>e.g.</em>, <em>CNNs</em> and <em>feature
extraction.</em> Specifically, <em>HArBoUR</em> enables support in
constructing end to end vision systems while providing expected results
and guidance.</p>
<p>Domain knowledge-guided hardware evaluation of computational tasks
allows imaging algorithms to be mapped onto hardware platforms more
efficiently than a heuristic based approach.</p>
<p>We benchmark representative image processing algorithms on various
hardware platforms and measure their <em>energy consumption</em> and
<em>execution time</em> performance. The results are evaluated to gain
insight into why certain processing accelerators perform better or worse
based on the characteristics of the imaging algorithm.</p>
<h2 id="sec:framework">Benchmarking Framework for Image Processing on
Hardware</h2>
<figure id="fig:AlgoChar">
<img src="Images/Heterogeneous Benchmark Framework.png" />
<figcaption>Benchmarking Framework for Image Processing Algorithms,
Highlighting Key Metrics and Properties</figcaption>
</figure>
<p>For efficient implementation on heterogeneous platforms, the
algorithm design will require partitioning any image processing
algorithm according to its suitability for individual components in the
pipeline on the target hardware. Therefore, a standard framework is
proposed containing a pool of image processing algorithms and their
characteristics in accordance with their hardware suitability. We
selected a range of low, medium and high-level algorithms from the image
processing hierarchical classification domain, providing wider coverage
of commonly used operations performed within a vision application
pipeline.</p>
<p>Various algorithmic and hardware characteristics that would impact
the performance are identified in the heterogeneous benchmark framework,
shown in Fig. <a href="#fig:AlgoChar" data-reference-type="ref"
data-reference="fig:AlgoChar">4.1</a>. The framework diagram offers a
clear overview of the image processing landscape. It maps out the
relationship between hardware properties, optimisations, algorithms,
metrics and memory access patterns. This concise visual guide aids
designers by offering insights into potential bottlenecks, suggesting
areas for innovation, and guiding the fine-tuning of algorithms on
heterogeneous platforms to achieve peak performance in imaging
tasks.</p>
<h3 id="processing-pipeline-operation-types">Processing Pipeline &amp;
Operation Types:</h3>
<p>Image processing algorithms are organised into three primary domains:
Pixel, Kernel, and Image. The <em>Pixel domain</em> focuses on
operations that manipulate or query individual pixel values. The
<em>Kernel domain</em> encompasses algorithms that utilise a small
matrix (the kernel) to modify an image. Lastly, the <em>Image
domain</em> deals with operations that consider the image as a whole,
where global features and patterns are essential for labelling.</p>
<h3 id="operator-group">Operator Group </h3>
<p>This label specifies the name of the algorithm. Algorithms may
perform a particular operation (<em>e.g.</em>, Image Arithmetic), but
depending on the stage within the image computation pipeline, the data
type of the pixel is defined differently and may contain additional
values for calibration, such as a pedestal. It is necessary to be
explicit when defining the algorithm within the framework. These image
processing algorithms can further be categorised into groups (Operation
Group) depending on the type of operation it performs.</p>
<h5 id="image-arithmetic-pre-processing">Image Arithmetic &amp;
Pre-Processing:</h5>
<p>Image arithmetic and pre-processing are foundational steps in image
processing pipelines, preparing images for subsequent analysis. These
algorithms predominantly execute primitive operations to transform an
input format into a desired one. They typically operate on individual
pixels using localised data, which minimises task dependencies. While
algorithms like multiplication, accumulation, squaring, magnitude
determination, and weighting are arithmetically simple, most
architectures can compute them with ease. Given their low initialisation
and latency requirements, architectures such as CPUs and FPGAs are
particularly well-suited for these tasks.</p>
<h5 id="geometric-transformation-image-analysis">Geometric
Transformation &amp; Image Analysis:</h5>
<p>Geometric transformations refer to operations that modify the spatial
arrangement of pixels in an image. These transformations can be applied
for various purposes, such as image registration, scaling, and
augmentation. Typically, these algorithms involve convolution and
interpolation operations, which can be linear or nonlinear.
Additionally, the choice of interpolation method, whether
nearest-neighbour, bilinear, or bicubic, can significantly impact both
the quality of the transformed image and the computational complexity of
the operation. Several operations are sequentially bound; forward
mapping directly calculates new pixel locations but can leave gaps in
the output. Its counterpart, backward mapping, determines source
contributors for each output pixel and often requires interpolation,
which can be sequential, especially with higher-order methods. Warping
with a displacement map, which dictates pixel movement, can also be
sequential if complex algorithms determine displacements. Resampling,
essential post-mapping, can become sequential with intricate
interpolation. Cumulative transformations, where multiple operations are
applied in sequence, and error corrections post-transformation, further
introduce sequential elements. For operations with inherent
sequentiality, such as certain geometric transformations, traditional
CPUs are often the most suitable due to their optimised instruction sets
for sequential tasks and complex branching. However, for tasks within
geometric transformations that can be parallelised, GPUs, FPGAs, and
TPUs can offer significant speedups</p>
<p>Image analysis algorithms label and understand various statistical
data about a pixel. These algorithms have many irregular memory access
patterns (mean, mode, min/max) and branching conditions that negatively
impact the performance of processing accelerators.</p>
<h5 id="image-filters-morphology">Image Filters &amp; Morphology:</h5>
<p>Image filter algorithms modify particular spatial frequencies. The
image is filtered either in the frequency or in the spatial domain.
Image filters are divided into two categories: linear and non-linear.
Linear image filters perform the convolution of an image using a
pre-computed kernel for efficiency. The data-independent multiply and
accumulate operations coupled with sequential data access of linear
filters map well onto GPUs and FPGAs. Contrarily, non-linear filters
have varied memory access patterns and have higher arithmetic intensity.
Additionally, certain algorithms with branching makes it arduous to
implement efficiently on a GPU and FPGA, which can exploit parallelism
in these operations. Non-linear filters consist of operations where the
output pixel value is determined based on some non-linear function of
the input pixel values in its neighbourhood. Examples of algorithms
include median, adaptive and bilateral filtering.</p>
<p>In morphological operations, an image is processed with a structuring
element, which is a small binary or grayscale mask. The structuring
element is moved over the entire image, and at each position, a
computation is performed based on the values of the image pixels that
overlap with the mask. Architectures with cache hierarchies, prevalent
in modern CPUs and GPUs, can exploit this pattern for enhanced cache
locality, especially when the structuring element’s dimensions are
compatible with cache sizes. In row-major order, horizontal traversal
optimises memory access, while vertical traversal can introduce
inefficiencies due to memory strides. Basic operations like dilation and
erosion have regular patterns, but advanced morphological algorithms can
cause irregular accesses. These irregularities, often from adaptive
structuring or conditional operations, challenge GPU performance through
warp divergence. Additionally, these algorithms may require repeated
pixel reads, especially with overlapping structuring elements, and
in-place operations risk read-write conflicts, which need careful
management to prevent race conditions.</p>
<h5 id="feature-extraction">Feature Extraction:</h5>
<p>Feature extraction algorithms, such as SIFT<span class="citation"
data-cites="Low99"></span>, SURF<span class="citation"
data-cites="Her06"></span>, and Oriented FAST and Rotated BRIEF
(ORB)<span class="citation" data-cites="ORB"></span>, are designed to
identify and describe local features in an image. These features are
often points or small image patches that are distinct and can be
reliably and robustly detected in various scales of the same scene. The
pixels extracted from an image are not stored adjacently in memory and
require expensive computational reads from non-adjacent memory addresses
that will impact the performance of all processing architectures.
Algorithms such as <code>ORB</code> examine a circle of pixels around
each candidate pixel. While each keypoint detection is independent and
can be parallelised, the algorithm involves conditional checks, which
can lead to divergent execution paths.</p>
<p>Regarding hardware suitability, CPUs have a layered hierarchy of
caches, encompassing L1, L2, and L3. This architecture is good at
offsetting the performance implications of non-sequential memory
accesses. Therefore, algorithms with random access patterns, akin to the
keypoint detection seen in SIFT or ORB, can leverage this hierarchical
structure. Nevertheless, despite their proficiency, CPUs will lag in
efficiency when confronted with parallel operations stages within the
algorithms. GPUs and FPGAs, on the other hand, are geared towards the
parallel processing tasks which are found during the convolution and
prefix sum stage. GPUs favour coalesced memory access, where adjacent
threads reading consecutive memory locations achieve faster, more
efficient data retrieval. Consequently, the random accesses, if
frequent, can lead to performance dips due to the resulting uncoalesced
memory transactions. However, TPUs are purpose-built for tensor
operations, forming the basis of deep learning methodologies.
Traditional feature extraction may not have direct advantages from TPUs
unless they’re integrated into a wider deep learning framework.</p>
<h4 id="data-primitive">Data Primitive:</h4>
<p>This characteristic specifies the type of data unit or collection of
pixels an algorithm operates on, encompassing attributes like type,
size, and representation. Depending on the level of the pipeline, a
pixel may refer to an individual or collection of bits of type
<code>word</code>, <code>uint8</code> or <code>uint12</code>. The
following are the various data primitives found within image
processing:</p>
<p><strong>Bit:</strong> Refers to individual bits in the binary
representation of the image data, encompassing pixel values, metadata,
file headers, and more, contingent on the file format.</p>
<p><strong>Element:</strong> Denotes a discrete scalar value, formed of
bits, quantifying pixel attributes, like colour intensity or
luminance.</p>
<p><strong>Pixel:</strong> Is a set of elements symbolising a point in
an image, with formats such as RGB, YUV, or Bayer encoding.</p>
<p><strong>Frame:</strong> Is a structured pixel collection visualised
in 2D or 3D, where the resolution indicates the total pixel count.</p>
<p><strong>Patch:</strong> Is a small frame subsection targeted by
algorithms like blurring; a <span
class="math inline">\(3\times3\)</span>, <span
class="math inline">\(5\times5\)</span> Kernel is a matrix sliding over
the image, its values multiplied with corresponding patch pixels, and
the results summed for a transformed image.</p>
<p><strong>Block:</strong> Pertains to a contiguous pixel group,
typically of fixed dimensions like <span
class="math inline">\(8\times8\)</span> or <span
class="math inline">\(16\times16\)</span>, serving as the atomic unit
for algorithms, such as JPEG compression.</p>
<p><strong>Blob:</strong> Is an image region defined by properties like
brightness, distinct from surrounding areas.</p>
<p><strong>Tensor:</strong> Is a multi-dimensional structure
encapsulating complex data; a 2D tensor represents greyscale images,
while a 3D tensor handles colour images, considering width, height, and
colour channels. In deep learning, tensors provide a concise
mathematical representation of the problem.</p>
<p><strong>Tile:</strong> Is a unique image portion, often rectangular,
acting as a processing or representation unit. Unlike overlapping
patches, tiles traditionally denote non-overlapping image regions,
ensuring each pixel’s unique tile membership. Tiling affects memory
access patterns and storage; for instance, accessing an image row might
require data fetching from multiple tiles if stored tile-by-tile.</p>
<p>Understanding data type precision is essential as it impacts accuracy
and hardware suitability. Algorithms requiring higher precision will use
floating-point datatype, which is better supported by the FP hard blocks
within CPU or GPU architectures, while FPGA solutions suit integer-based
calculations. Data primitive choice impacts memory, bandwidth, and
computational efficiency. Successful imaging pipeline design hinges on
aligning data primitive attributes with processing unit capabilities,
thereby optimising image processing workflow in terms of accuracy,
efficiency, and hardware compatibility. An optimal pipeline balances
various primitives for each operation while maintaining high
accuracy.</p>
<h4 id="access-patterns">Access Patterns:</h4>
<p>Image pixel locality in memory refers to how the spatial arrangement
of pixel data impacts the efficiency of image processing tasks. When
pixels are stored in memory, their arrangement influences data access
efficiency. Locality in memory means nearby pixels in the image are
stored adjacently, aiding faster data access. Various access patterns
are discussed below:</p>
<p><strong>Sequential Access:</strong> Involves accessing pixels one
after the other, typically in row-major or column-major order.</p>
<p><strong>Random Access:</strong> Retrieves pixels in a non-sequential
manner based on algorithmic requirements.</p>
<p><strong>Neighbourhood Access:</strong> Relates to the pixels
surrounding a specific pixel, often used in operations with kernels or
local filters.</p>
<p><strong>Block Access:</strong> Deals with a contiguous region of
pixels, common in block-based algorithms or compression methods.</p>
<p><strong>Strided Access:</strong> Refers to the method where pixels
are accessed at regular intervals or ’strides’.</p>
<p><strong>Pyramidal Access:</strong> Is associated with
multi-resolution representations, such as image pyramids.</p>
<p><strong>Scanline Access:</strong> Involves accessing entire rows or
columns of pixels simultaneously, often seen in raster operations.</p>
<p><strong>Tile-based Access:</strong> Focuses on square or rectangular
pixel tiles, crucial in tiled rendering or processing.</p>
<p>Efficient memory access is crucial in real-time imaging due to
computer memory hierarchies. Pixels stored close in memory can be loaded
into faster cache levels, reducing time spent waiting for data from
slower memory. In image processing, operations like convolution require
accessing nearby pixels. Locally stored pixels minimise cache misses and
improve computational performance. Techniques like tiling, memory
padding, and cache-aware algorithms enhance processing efficiency. By
aligning pixel data in memory with spatial arrangement and optimising
memory hierarchy, image processing algorithms can leverage hardware
effectively for faster performance.</p>
<h4 id="hardware-characteristics-edge-handling">Hardware Characteristics
&amp; Edge Handling:</h4>
<p>It is necessary to understand the capabilities and limitations of
each hardware architecture to obtain optimum accuracy, area and speed of
imaging algorithms. These depend on particular hardware properties such
as bit-width, clock rate, memory location, data type and data
dependency. Image processing algorithms perform poorly on memory systems
due to memory hierarchy latency bottlenecks and high cache miss rates.
Additionally, architectures containing many processing units require
careful division of tasks to avoid load imbalance.</p>
<p>Edge handling involves strategies when operations, such as filtering,
convolution and morphological transformations, are applied near the
boundaries of an image. Since these algorithms often require
neighbouring pixel values, challenges arise at the image edges where
full neighbourhoods are unavailable. Common edge handling techniques
include zero-padding (extending the image with zeros), replication
(duplicating the edge values), reflection (mirroring the adjacent
pixels), and circular (considering the image as a continuous loop).
Different edge handling techniques can lead to non-uniform or
non-sequential memory access patterns. In addition, the choice of method
can influence the resultant image, especially in terms of artefacts or
discontinuities at the boundaries. Proper edge handling is crucial to
ensure consistent and artefact-free processing results.</p>
<h4 id="optimisations-metrics">Optimisations &amp; metrics</h4>
<p>The optimisation attribute captures accelerator agnostic
optimisations for image processing algorithms. The attribute provides a
repository of optimisations that helps designers pick and tune
algorithms to find the optimal combination within their design space for
specific use cases. These optimisations focus on the inherent properties
of the algorithm, such as reducing computational complexity, improving
data access patterns, or refining logical structures. The primary
reasoning is their broad applicability and ensures a performance
baseline. The improvements realised are typically consistent across
various hardware architectures, from CPUs and GPUs to FPGAs and
ASICs.</p>
<p>The metric attribute standardises performance indicators from
benchmarking literature, facilitating an understanding of trade-offs.
Metrics such as runtime assess algorithmic execution speed, throughput
quantifies data processed over time, and energy per operation provides
insights into energy efficiency. For neural networks, accuracy measures
how often the model is correct, precision looks at how many of the
positive identifications were actually right, and the F1 score balances
precision against recall.</p>
<h3 id="sec:introframework">Heterogeneous Benchmarking Development
Flow</h3>
<p>Heterogeneous hardware addresses the growing complexity of modern
workloads by combining different processing units, such as CPUs, GPUs,
and other accelerators, within a single system. This approach optimises
performance and energy efficiency for specific tasks, leveraging the
strengths of each component. However, targeting these platforms remains
a significant challenge to address.</p>
<figure id="fig:FrameworkFlow">
<img src="Images/Bencmark Flow.png" />
<figcaption>Framework Pipeline for Heterogeneous Image Processing
</figcaption>
</figure>
<p>Therefore, To effectively exploit the power of heterogeneous
architectures, a robust development flow is crucial. Such a workflow not
only aids in pinpointing the optimal architecture but also streamlines
the entire development process. As depicted in Fig. <a
href="#fig:FrameworkFlow" data-reference-type="ref"
data-reference="fig:FrameworkFlow">4.2</a>, a comprehensive
heterogeneous development pipeline describes a systematic and
standardised approach for implementation. This structured flow ensures
that developers can seamlessly integrate various computational
resources, leverage specialised hardware capabilities, and achieve
optimal performance across multiple platforms.</p>
<p><strong>Characteristic Analysis:</strong> The first stage involves
identifying certain properties of an algorithm discussed in <a
href="#sec:framework" data-reference-type="ref"
data-reference="sec:framework">4.2</a> and building a model of data,
which helps find suitable architectures. Starting with workload
characterisation provides a comprehensive overview of the algorithm’s
computational and data demands, potentially giving insight into areas
where algorithms can be partitioned. Specific algorithms require higher
precision, which can impact the choice of the target architecture.
However, trading off accuracy for speed is a potential opportunity.
Memory access patterns significantly affect cache utilisation and memory
latency. It’s important to recognise an algorithm’s parallelism
potential while being aware of data dependencies. Moreover, optimising
memory access patterns to align with the cache hierarchy can reduce
latency and enhance memory throughput. Furthermore, adapting algorithms
to harness specific hardware features, such as GPU threads, FPGA
pipelines, or TPU matrix multiply units.</p>
<p><strong>Prototyping:</strong> This stage involves prototyping designs
to identify the initial performance of an architecture to establish a
baseline benchmark. Profiling code is done to identify performance
bottlenecks, which offers valuable insights into areas suitable for
performance enhancement across various architectures. Profiling aims to
uncover the ’hotspots,’ sections of code where execution time and
resource consumption are disproportionately high. In addition,
identifying task, data parallelism or pipelining opportunities which
benefit certain accelerators. It is essential to pinpoint potential
latency issues, both in I/O operations and within memory, which can
arise from slow data transfers or inefficient data handling. Identifying
loop structures is important for performance; branching within loops in
parallel or pipelined processors can negatively affect performance. This
is because branching can lead to divergence, where different execution
paths are taken simultaneously, causing processing cores to remain idle.
Loop unrolling is a common optimisation technique that can mitigate the
effects of branching by increasing the number of operations in each loop
iteration, reducing the loop’s overhead. However, if a loop cannot be
unrolled or tiled, it may be more efficient to execute the algorithm on
a higher clocked sequential core, which can handle branching.</p>
<p><strong>Implementation:</strong> After selecting the appropriate
architecture for an algorithm, the next step involves its
implementation. Depending on the chosen accelerator, this process may
entail simulating and synthesising designs and conducting thorough
verification. Finally, timing analysis involves evaluating the
propagation delays of signals through the circuit’s logic gates and
interconnects to ensure they meet the constraints set by the clock cycle
time. This helps in detecting and addressing potential timing
violations. General-purpose architectures will use compilation methods
to high-level code into machine-level instructions tailored for the
instruction driven accelerators.</p>
<p><strong>Evaluation &amp; Optimisation:</strong> Post-implementation,
performance tuning and optimisation techniques are applied to ensure the
algorithm runs efficiently, maximising the hardware’s potential.
Optimisations can be grouped into four categories: hardware, software,
domain-specific and algorithmic. Hardware optimisations involve
fine-tuning specific hardware configurations or datatypes such as
quantisation or bit-width adjustments. Software optimisations are
usually applied at the code level either manually or automatically by
compilers. These techniques can include inlining, dead code elimination,
and vectorization. Domain-specific is tailored for specific application
areas such as downsampling or separable filters. Lastly, algorithmic
focus on mathematical refinement to reduce complexity and use more
efficient data structures. It’s also necessary to validate the
implementation against reference data-sets to ensure functional
correctness. Throughout this process, continuous profiling helps
identify bottlenecks and areas for further optimisation.</p>
<h2 id="sec:benchmark">Benchmarking Methodology</h2>
<p>This section introduces two benchmarking strategies, micro and macro,
each offering distinct approaches to evaluate accelerator performance.
While micro-benchmarking focuses on assessing individual algorithms or
pipelines, macro-benchmarking provides an overall view by analysing
fundamental operations found in many algorithms within the ISP
pipeline.</p>
<h3 id="Benchmarking Algorithms">Micro Benchmarking Algorithms</h3>
<figure id="fig:edge-detect">
<img src="Images/Processed Images.png" />
<figcaption>Low to High Complexity Image Processing Algorithms in the
ISP Pipeline</figcaption>
</figure>
<p>Image processing pipelines contain many operations varying in
complexity. For a comprehensive set of results, many popular individual
ISP algorithms are chosen to be benchmarked, listed in Table <a
href="#tab:algorithms" data-reference-type="ref"
data-reference="tab:algorithms">[tab:algorithms]</a> and visually shown
in Fig. <a href="#fig:edge-detect" data-reference-type="ref"
data-reference="fig:edge-detect">4.3</a>. The algorithms,
<em>Addition</em>, <em>Subtraction</em>, <em>Erode</em>,
<em>Dilate</em>, <em>Box Filter</em>, <em>Gamma Correction</em>,
<em>Linearization</em>, and <em>Demosaicing</em> are chosen because they
represent foundational operations in image processing. These algorithms
exhibit diverse memory access patterns, computational intensities, and
parallelism levels. Their inclusion ensures a comprehensive evaluation
of an architecture’s capability to handle point-wise and neighbourhood
operations.</p>
<h4 id="complete-imaging-pipelines">Complete Imaging Pipelines</h4>
<figure id="fig:completepipelines">
<img src="Images/PopularPipeline.png" />
<figcaption>Exemplar Image Pipelines Benchmarked on each Architecture.
</figcaption>
</figure>
<p>Vision applications usually do not consist of one algorithm but
contain many pipelined together to form a complete system. In developing
the proposed framework, three exemplars were selected: 1) <em>Edge
Detection</em>, 2) <em>Feature Extraction (SIFT)</em> <span
class="citation" data-cites="Low99"></span> and 3) Classification,
representing low to high-level complexity shown in Fig. <a
href="#fig:completepipelines" data-reference-type="ref"
data-reference="fig:completepipelines">4.4</a>. They are partitioned
into nine sub-algorithms, namely, <em>RGB2Grey</em>, <em>Gaussian
Filter</em>, <em>Sobel Filter</em>, <em>Gaussian Pyramid</em>,
<em>Extrema Detection</em>, <em>Orientation Assignment</em>,
<em>Descriptor Generation</em>, <em>Resize</em>, and <em>CNN</em>. The
sub-algorithms are common building blocks of many other image processing
algorithms with varying complexity and therefore are good candidates for
benchmarking. For example, <em>Gaussian Pyramid</em> is useful for
analysis across different spatial scales and <em>Extrema Detection</em>
operations are often used in corner detection and image blending
algorithms.</p>
<p>The first pipeline is the edge detection pipeline, designed to
identify and emphasise edges within images. It starts with the
conversion of RGB colour information into greyscale, a method aimed at
reducing redundant processing. Following this, Gaussian filtering is
used to achieve image smoothing and noise reduction, essential for
accurate edge detection. The Sobel edge detection algorithm, serving as
the final stage within this pipeline, detects edges by highlighting
abrupt changes in pixel intensities.</p>
<p>The feature extraction pipeline captures important features present
within images. The first step in the pipeline involves the construction
of a Gaussian pyramid, accomplished by generating multiple versions of
the input image through Gaussian filtering and downsampling. This
pyramid plays a critical role in identifying features across varying
scales. Subsequently, extremum detection is executed, facilitating the
identification of keypoints or points of interest within the image.
These keypoints serve as reference points for subsequent analysis and
interpretation. Grayscale images is used as a input for their simplicity
in processing and their robustness to changes in illumination.</p>
<p>The classification pipeline can be found in many deep learning based
applications, including vision. It begins with the conversion of RGB to
greyscale and subsequently, the image resizing operation is performed to
standardise dimensions, ensuring compatibility with the CNN
architecture. The final stage involves the application of the CNN
algorithm, a state-of-the-art deep learning technique known for its
proficiency in tasks related to image classification, object detection,
and segmentation.</p>
<h3 id="macro-benchmarking-algorithms">Macro Benchmarking
Algorithms</h3>
<p>Many image processing algorithms share foundational operations, which
can be used to benchmark accelerators to gain better insight. This
section reviews a range of algorithms and their properties that make it
an ideal case study for evaluation.</p>
<h4
id="sustainable-memory-bandwidth-in-high-performance-computers">Sustainable
Memory Bandwidth in High Performance Computers</h4>
<p>Stream memory benchmark<span class="citation"
data-cites="Macc06"></span> (STREAM) is a widely used performance
evaluation tool for measuring memory bandwidth in computer systems. It
assesses the speed at which a system can read and write data to memory.
The benchmark primarily focuses on four memory access patterns: Copy,
Scale, Add, and Triad. In the Copy pattern, data is read from one memory
location and written to another. The Scale pattern involves reading
data, scaling it by a constant, and writing it to a different memory
location. The Add pattern reads two arrays, adds corresponding elements,
and writes the result to a third array. Finally, the Triad pattern
combines scaling and addition operations. The benchmark generates a set
of memory performance metrics, including the memory bandwidth,
calculated as the amount of data transferred per unit time, typically in
gigabytes per second (GB/s). The memory bandwidth (B) can be calculated
using the following equation: <span class="math display">\[B = \frac{N
\times S}{t}\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the number of data
elements accessed in the memory, <span class="math inline">\(S\)</span>
is the size of each data element in bytes, and <span
class="math inline">\(t\)</span> is the time taken to complete the
memory operation in seconds. This equation gives us the memory bandwidth
in bytes per second. Image processing is very memory-intensive due to
the large amounts of data associated with higher resolution images and
the need for frequent data access during processing. Each pixel requires
multiple bytes of storage, and when processing, these pixels often need
to be accessed multiple times, especially in operations like
convolution, filtering, or transformations. The STREAM benchmark becomes
invaluable in this context, as it provides insights into how efficiently
an architecture can handle the memory demands of image processing
tasks.</p>
<h4 id="fast-fourier-transform">Fast Fourier Transform</h4>
<p>Fast Fourier Transform (FFT) is an algorithm that finds extensive
applications in signal processing, image analysis, and various fields
where frequency domain analysis is essential. In image processing, FFT
is particularly valuable for transforming an image from its spatial
domain representation to its frequency domain representation. This
transformation enables the identification of various frequency
components present in an image, offering insights into patterns,
textures, and other intricate details that may not be as evident in the
spatial domain.</p>
<p>The FFT algorithm computes the Discrete Fourier Transform (DFT) of a
signal in an efficient manner, reducing the computational complexity
from <span class="math inline">\(O(n^2)\)</span> to <span
class="math inline">\(O(n \log (n))\)</span>, where <span
class="math inline">\(n\)</span> is the number of data points in the
signal. In the case of a 2D image, the FFT operation involves applying
the DFT algorithm separately to both the rows and columns of the image’s
pixel values. The 2D FFT of an image <span class="math inline">\(I(x,
y)\)</span> is expressed as:</p>
<p><span class="math display">\[F(u, v) = \sum_{x=0}^{N-1}
\sum_{y=0}^{M-1} I(x, y) e^{-j 2 \pi \left(\frac{u x}{N} + \frac{v
y}{M}\right)}\]</span></p>
<p>Here, <span class="math inline">\(F(u, v)\)</span> represents the
frequency components in the transformed image, N is the number of pixels
along the x-axis, <span class="math inline">\(M\)</span> is the number
of pixels along the y-axis, and <span class="math inline">\((u,
v)\)</span> are the spatial frequency coordinates in the frequency
domain.</p>
<p>The resulting 2D FFT representation provides valuable information
about the image’s frequency content. Low-frequency components
(corresponding to slow changes in intensity) are typically located near
the centre of the frequency domain representation. High-frequency
components (corresponding to rapid changes in intensity, edges, and
textures) tend to be found towards the corners. By analysing this
transformed image, practitioners can perform tasks like filtering,
denoising, compression, and other frequency-based manipulations to
enhance or extract specific features from the original image.</p>
<h4 id="convolution-matrix-multiply">Convolution (Matrix Multiply)</h4>
<p>The two most common methods for convolution are general matrix
multiply (GEMM) and direct convolution. GEMM-based convolution relies on
the <em>im2col</em> algorithm<span class="citation"
data-cites="CheKumPur06"></span>, which results in a large memory
footprint and reduced performance. Alternatively, direct convolution has
a lower memory footprint but the performance is reduced due to the
irregular memory access patterns. GEMM can be can be expressed through
Eq. (<a href="#eq:GEMM" data-reference-type="ref"
data-reference="eq:GEMM">[eq:GEMM]</a>):</p>
<p><span class="math display">\[\label{eq:GEMM}
C_{ij} = \sum_{k=1}^{K} A_{ik} \cdot B_{kj}\]</span></p>
<p>Here, <span class="math inline">\(C_{ij}\)</span> refers to the
element positioned at row <span class="math inline">\(i\)</span> and
column <span class="math inline">\(j\)</span> within the resultant
matrix <span class="math inline">\(C\)</span>, <span
class="math inline">\(A_{ik}\)</span> signifies the element situated at
row <span class="math inline">\(i\)</span> and column <span
class="math inline">\(k\)</span> in matrix <span
class="math inline">\(A\)</span>, and <span
class="math inline">\(B_{kj}\)</span> represents the element located at
row k and column <span class="math inline">\(j\)</span> in matrix <span
class="math inline">\(B\)</span>. The summation spans across the index
<span class="math inline">\(k\)</span> from 1 to <span
class="math inline">\(K\)</span>, where <span
class="math inline">\(K\)</span> corresponds to the number of columns in
matrix <span class="math inline">\(A\)</span> (which should equivalently
match the number of rows in matrix BB for accurate multiplication). This
equation forms the core operation underlying the GEMM benchmark, which
orchestrates the calculation of the matrix product between <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> to yield matrix <span
class="math inline">\(C\)</span>.</p>
<p>GEMM is found in image processing tasks that require matrix
operations. For example, convolutional neural networks (CNNs)
extensively use matrix multiplications for convolutional layers, and
GEMM’s efficiency and parallelism make it highly useful for accelerating
these operations. Additionally, transformations, filters, and image
manipulations often involve matrix operations, and therefore GEMM’s
optimised implementations can significantly enhance the performance of
image processing algorithms.</p>
<h3 id="performance-metrics">Performance Metrics</h3>
<p>This section focuses on evaluating implemented image processing
algorithms using two key metrics: execution time and power consumption.
The analysis provides insights into the strengths and limitations of the
image processing algorithms on a heterogeneous architecture.</p>
<h4 id="execution-time">Execution Time</h4>
<p>In evaluating the performance of image processing algorithms, precise
time measurements are essential to capture the subtle differences across
hardware platforms. For the CPU, the C++ standard library’s <span
class="math inline">\(high\_resolution\_clock\)</span> is employed,
offering a fine-grained temporal resolution suitable for capturing in
microseconds. This method involves marking the start and end times
surrounding the algorithm’s execution and computing the difference to
determine the elapsed time. On the GPU side, CUDA events were utilised
to measure the time taken for the algorithms to run. CUDA events are
specifically designed to capture start and end times in a GPU’s
environment, ensuring accurate timing measurements that account for the
asynchronous nature of GPU operations. Irrelevant processes are stopped
within the operating system to prevent interference during the timing
measurement. For the FPGA evaluations, the behavioural simulation timing
feature of the Vivado software is used. This tool provides a detailed
timing analysis, simulating how the algorithm would perform on the FPGA,
thereby offering insights into its expected real-world performance. The
implementations are written in C/C++/Verilog and uses the time function
built into Linux and system performance monitor to measure the runtime
of CPU/GPU/FPGA.</p>
<h4 id="power-consumption">Power Consumption</h4>
<p>Accurate power estimation is always challenging for software tools.
However, systematic steps are taken to minimise assumptions for better
accuracy. The approach used to measure the power consumption for the CPU
and GPU is obtained by using <em>HWMonitor</em> software. The power is
initially measured to determine the average base operating power. Then,
each algorithm is executed multiple times, and the power is measured
during algorithm runtime. The FPGA on-chip power consumption is measured
using the reports from the power analyser feature integrated into Vivado
Design Suite. The heterogeneous implementation power consumption is
calculated using both <em>HWMonitor</em> and Xilinx’s System Monitor IP.
Static power consumption, refers to the constant energy usage of a
device when it’s idle, whereas dynamic power consumption varies based on
the workload or activity levels, resulting in fluctuations in energy
usage</p>
<h3 id="measurement-environments">Measurement Environments</h3>
<p>While FPGA can provide an accurate execution time in the simulation
mode, the same is not true for the CPU/GPU accelerators, as there might
be other software (including part of the operating system) competing for
compute resources. To mitigate this, the execution time for each
bench-marked algorithm is measured as the average of 1,000 iterations on
CPU/GPU and closing all other non-core application processes before
execution. The Nvidia (CUDA) GPU also has an initialisation time often
associated with setting up the GPU context and memory allocations, can
be significant, especially for smaller tasks. The initialisation time is
recorded for both with and without.</p>
<p><strong>Software &amp; Hardware Environments:</strong>
<em>OpenCV</em> and <em>Pytorch</em> library is used to implement image
processing algorithms and CNNs on CPU and GPU platforms. The FPGA
implementation is written in Verilog, using Vivado Design Suite 2019.2.
Additionally, for comparison purposes, implementation was done with
high-level synthesis (HLS) code using Xilinx Vitis 2019.2.
Programmability and flexibility vary across architectures shown in
Table <a href="#tab:CombinedEnvironment" data-reference-type="ref"
data-reference="tab:CombinedEnvironment">[tab:CombinedEnvironment]</a>;
CPUs and GPUs are general-purpose, which makes them highly programmable
for a wide range of tasks, with languages like C++ being commonly used.
FPGAs are more inflexible since significant time is needed to change
implementation designs and are typically crafted in hardware descriptor
languages such as Verilog. The hardware setup consists of a desktop PC
running a Linux operating system, with a discrete GPU and FPGA connected
via a high throughput PCIe interface to reduce data latency.</p>
<h3 id="sec:measurementApproach">Measurement Approach</h3>
<p>The algorithms are implemented individually on each hardware and then
combined to create the combined pipeline. For a fair comparison,
open-sourced (OpenCV) and CNN libraries(Pytorch) were employed, which
are highly optimised for their respective architectures. This is with
exception of the Verilog implementations that were developed manually.
The parameter for each algorithms used float precision and <span
class="math inline">\(5\times5\)</span> kernel size. During the
benchmarking, for consistency, an uncompressed <span
class="math inline">\(8\)</span> bit <span class="math inline">\(1920
\times 1080\)</span> greyscale (Colour for <em>RGB2Gray</em> algorithm)
bitmap image for all experiments and a bayerRAW equivalent for
<em>Demoasiacing</em> algorithm.</p>
<p>We provide multiple performance indicators to compare between
architectures. For each algorithm, the runtime is measured on each
hardware to determine which accelerator executed the operation in the
least amount of time. The results from the runtimes are used to
calculate the estimated throughput using Eq. (<a href="#eq:flop"
data-reference-type="ref" data-reference="eq:flop">[eq:flop]</a>). The
clock cycles per operation (CPO) in Eq. (<a href="#eq:ClockComplete"
data-reference-type="ref"
data-reference="eq:ClockComplete">[eq:ClockComplete]</a>) gives insight
into the average number of cycles required to execute an instruction. To
have a fair comparison across the target hardware, the energy per
operation is normalised using Eq. (<a href="#eq:energyepo"
data-reference-type="ref"
data-reference="eq:energyepo">[eq:energyepo]</a>): <span
class="math display">\[\text{Throughput} = \frac{N}{t}
\label{eq:flop}\]</span></p>
<p><span class="math display">\[\text{CPO} = \frac{f \times t}{N}
\label{eq:ClockComplete}\]</span></p>
<p><span class="math display">\[\text{EPO} = \frac{P \times t}{N}
\label{eq:energyepo}\]</span></p>
<p>In these equations, <span class="math inline">\(N\)</span> denotes
the number of operations performed and <span
class="math inline">\(t\)</span> signifies the runtime of the
computational task in seconds. <span class="math inline">\(f\)</span>
represents the frequency of the processing unit in hertz, and <span
class="math inline">\(P\)</span> is power consumption in watts.</p>
<h2 id="sec:result">Experiments, Results &amp; Discussion</h2>
<p>This section presents the bench-marked results of each algorithm
described in <a href="#sec:benchmark" data-reference-type="ref"
data-reference="sec:benchmark">4.3</a> and an in-depth discussion. The
section is divided into two parts, which include the runtime, power
consumption, EPO and throughput results for individual ISP algorithms
and combined exemplar pipelines.</p>
<h3 id="individual-isp-algorithms">Individual ISP Algorithms</h3>
<figure id="fig:OtherAlgorithmsExecutionTime">

<figcaption>Execution times (milliseconds) for <em>individual
algorithms</em> found within imaging pipelines on each hardware
architecture.</figcaption>
</figure>
<p>Fig. <a href="#fig:OtherAlgorithmsExecutionTime"
data-reference-type="ref"
data-reference="fig:OtherAlgorithmsExecutionTime">4.5</a> &amp; Fig. <a
href="#fig:CHAP1OtherAlgorithmsPower" data-reference-type="ref"
data-reference="fig:CHAP1OtherAlgorithmsPower">4.6</a> plots the
execution time (in milliseconds) and power consumption (in Watts) of the
selected benchmarking image processing algorithms varying in complexity
across different hardware architectures: CPU, GPU, FPGA, and high-level
synthesis implementation on FPGA. The results reveal runtime variations
among the architectures for each algorithm. Overall, the CPU performs
competitively with the GPU, FPGA and HLS for lower complexity algorithms
cases such as <em>RGB2GRAY</em> algorithm, <em>Addition</em>, and
<em>Subtraction</em>. It’s evident that algorithms involving a small
number of operations, such as colour channel conversion, do not require
many computational cores to leverage parallelism or memory access
requirements. However, the CPU’s performance starts to decline as the
complexity of the algorithms increases, as seen in cases like
<em>Sobel</em>, <em>Gamma Correction</em>, <em>GEMM</em>, and
<em>FFT</em>, where the large array processing capabilities offered by
the GPU and FPGA become more prominent. On average, the CPU is <span
class="math inline">\(4.5\times\)</span> and <span
class="math inline">\(4.35\times\)</span> slower than the GPU and FPGA,
respectively.</p>
<figure id="fig:CHAP1OtherAlgorithmsPower">

<figcaption>Power Consumption (Watts) for <em>individual algorithms</em>
found within imaging pipelines on each hardware
architecture.</figcaption>
</figure>
<p>Across most algorithms, the GPU consistently demonstrates its
capability for calculations that require a great amount of multiply and
accumulate operations such as <em>GEMM</em> where its vast number of
cores are fully occupied. Although FPGAs also contain many processing
blocks, their quantity is typically far fewer than GPUs, thus having a
small increase in runtime. The results show that GPU implementations
outperform FPGAs for larger data/kernel sizes but underperform for
smaller sizes where the memory latency and kernel initialisation
overhead become significant.</p>
<p>Non-linear algorithms such as <em>Median</em>, <em>Erode</em> and
<em>Dilate</em> have a significant impact on all architectures due to
having unconventional operations which do not have specialised hard
blocks to compute them. In addition, branching conditions involve
irregular memory access patterns. The impact can be seen from the GPU
and FPGA results, which jump in runtime from linear to non-linear
filters where parallelisation is inhibited and the kernel is not
separable. The <em>Gamma Correction</em> is another non-linear algorithm
which operates on a pixel-wise basis, modifying pixel intensities based
on their original values and gamma factors. Division operations are
generally more complex and relatively slower compared to multiplication
and addition but can be pipelined in hardware. Therefore reducing the
overall runtime on all architectures and requiring more resources to
compute. The HLS implementation proved competitive in runtime with the
hand-written FPGA and GPU for many low-medium complexity algorithms in
which the compiler can leverage pre-written functions or libraries. On
the contrary, algorithms such as <em>Gamma Corr.</em> or
<em>Demosiacing</em>, which are implemented without using pre-optimised
libraries, required more compiler effort to generate HDL, resulting in
slightly slower execution times.</p>
<p>Related to power consumption, the CPU consumes the most energy in all
cases. As the algorithm complexity increases, more power is consumed.
The FPGA and HLS are 27% and 7.5% more energy efficient than the GPU in
nearly all algorithms, which reveals that direct hardware designs have
much less power overhead than the GPU, which needs to support other
processes such as host communication. Table <a
href="#tab:average_reduction_ratios" data-reference-type="ref"
data-reference="tab:average_reduction_ratios">[tab:average_reduction_ratios]</a>
presents average reduction ratios for each algorithm relative to CPU
energy consumption. The GPU exhibits a higher energy reduction ratio in
<em>White balance</em>, <em>Sobel</em>, <em>Gamma</em> and
<em>GEMM</em>, which reveals that the higher clocked GPU can execute the
algorithms faster while offsetting the higher operating power
consumption.</p>
<figure id="fig:CHAP1OtherAlgorithmsThroughput">

<figcaption>Throughput for <em>individual algorithms</em> found within
imaging pipelines on each hardware architecture (log scale)</figcaption>
</figure>
<figure id="fig:CHAP1OtherAlgorithmsEPO">

<figcaption> Energy per operation (EPO) for <em>individual
algorithms</em> found within imaging pipelines on each hardware
architecture (log scale)</figcaption>
</figure>
<p>The algorithm throughput and energy per operation in nanoJoules, are
shown in Fig. <a href="#fig:CHAP1OtherAlgorithmsThroughput"
data-reference-type="ref"
data-reference="fig:CHAP1OtherAlgorithmsThroughput">4.7</a> and Fig. <a
href="#fig:CHAP1OtherAlgorithmsEPO" data-reference-type="ref"
data-reference="fig:CHAP1OtherAlgorithmsEPO">4.8</a>. Using nJ, as
opposed to watts, offers a more granular and clearer measurement. The
trend remains, with CPU lagging in throughput and EPO compared to the
other architectures for all algorithms. Although in <em>RGB2GRAY</em>,
<em>Median</em> &amp; <em>FFT</em>, the CPU is closer to the other
accelerators in both metrics due to lower complexity, input size and
non-linearity of the algorithms, which don’t map well to highly parallel
hardware. The GPU consistently maintains its higher throughput
capabilities, as shown by the graphs and lower energy per operation on
larger data sized algorithms. The FPGA achieves closer results to the
GPU, but being clocked lower and having fewer processing cores results
in a slight performance decrease. The HLS tool exhibits comparable
performance, closely trailing the GPU and FPGA in most algorithms.
Although it experiences a slight performance lag which is attributed to
challenges in hardware translation, this setback is mitigated by
leveraging optimised pre-written functions used in <em>STREAM</em>. In
such algorithms, the HLS tool demonstrates comparable throughput
performance to hand-optimised FPGA implementation.</p>
<h3 id="combined-isp-pipelines">Combined ISP Pipelines</h3>
<figure id="fig:Execution">

<figcaption>Execution times (milliseconds) for combined image processing
pipelines on each hardware architecture. Some bars that don’t appear are
due to values being small</figcaption>
</figure>
<figure id="fig:Energy">

<figcaption>Power Consumption (Watts) for combined processing pipelines
on each hardware architecture.</figcaption>
</figure>
<p>The combined image processing pipeline algorithm for execution times
is reported in Fig. <a href="#fig:Execution" data-reference-type="ref"
data-reference="fig:Execution">4.9</a>. The runtime results indicate
nearly a <span class="math inline">\(3.46\times\)</span>, <span
class="math inline">\(2.92\times\)</span>, and <span
class="math inline">\(1.79\times\)</span> order of magnitude improvement
going from CPU to GPU, FPGA, and HLS, respectively. The GPU also has a
slightly marginal <span class="math inline">\(\sim0.56\times\)</span>
runtime improvement over the FPGA implementation and is closer to a
double order of magnitude improvement than the HLS. The memory transfer
results in the table show that the latency for each algorithm ranges
from <span class="math inline">\(20\sim70\)</span>ms for the CPU and
GPU. In contrast, the FPGA can take advantage of stream processing
pixels to minimise memory access for most algorithms.</p>
<p>In the execution time of <em>Edge Total</em> and <em>CNN Total</em>
pipelines, the improvement between accelerators is minimal in comparison
to the <em>SIFT Total</em>, which has substantial differences between
each platform. The <em>Gaussian Pyramid</em> stage within <em>SIFT</em>
has the largest contribution to overall <em>SIFT Total</em> execution
time. The result can be attributed to image filter algorithms with many
multiply-and-accumulate operations, which map well to the parallel
processing of GPU and FPGAs due to their high number of compute cores.
In contrast, the CPU suffers due to the lack of processing cores where
parallelism is needed, resulting in poorer execution time. In addition,
the power consumption results in Fig. <a href="#fig:Energy"
data-reference-type="ref" data-reference="fig:Energy">4.10</a> indicate
that the FPGA consumes <span class="math inline">\(1.4\sim 6\)</span>x
less power in the <em>Gaussian Pyramid</em> stage than the CPU and GPU,
with the HLS implementation being slightly less power efficient. The
architecture of FPGAs enables tight-knit designs without additional
power consumption by other support functions. Furthermore, the
efficiency is evidenced in the <em>Sobel</em> algorithm; the FPGA makes
use of the DSP blocks, which consumes less power, although the algorithm
contains more than double the numerical operations than <em>Box</em> or
<em>Gaussian</em>.</p>
<h3 id="energy-consumption-throughput-results">Energy Consumption &amp;
Throughput Results</h3>
<figure id="fig:CombinedThroughput">

<figcaption>Throughput of each algorithm on hardware platforms (log
scale) for combined processing pipelines.</figcaption>
</figure>
<figure id="fig:CombinedEPO">

<figcaption>Energy per operation (EPO) for each algorithm on hardware
platforms (log scale) for combined processing pipelines.</figcaption>
</figure>
<p>The plots in Fig. <a href="#fig:CombinedThroughput"
data-reference-type="ref"
data-reference="fig:CombinedThroughput">4.11</a> &amp; Fig. <a
href="#fig:CombinedEPO" data-reference-type="ref"
data-reference="fig:CombinedEPO">4.12</a> show the throughput and energy
consumed per operation. The throughput difference between each
accelerator for low complexity/arithmetic algorithms such as
<em>R2G</em> was consistent, with all three accelerators are comparable.
However, the gap widens between CPU and the other hardware in throughput
from <em>Gaussian</em> to <em>CNN Total</em>. Comparing GPU and FPGA
implementations, the FPGA outperforms in throughput for <em>Edge
Total</em>. The hand-written FPGA is able to stream algorithms more
effectively than the GPU without overhead CPU memory management latency.
Furthermore, the core initialisation and allocation of the GPU does not
offset the time it processes for the <em>Gaussian</em> and
<em>Resize</em> algorithms.</p>
<p>The GPU and both FPGAs consume <span
class="math inline">\(\sim2\)</span>x less energy per operation compared
to the CPU for <em>Gaussian Pyramid, Extrema, Orientation</em>
algorithms. This result is because many cores are at full occupancy
which start to compute more data in parallel thus increasing throughput.
The HLS implementation of <em>Orientation</em> and <em>Descriptor</em>
found in <em>SIFT</em> algorithm has worse energy consumption per
operation than the hand-written FPGA and GPU. The throughput loss in the
<em>descriptor</em> algorithm for GPU and FPGA is due to high data
dependency, which leads to sequential processing. In some algorithms,
the GPU consumes less energy per operation than the FPGA. The lower
power consumption is due to processing the algorithm faster on the GPU
than the FPGA to offset the high energy usage from the clock speed and
support functions. Table <a href="#tab:Result Summary"
data-reference-type="ref"
data-reference="tab:Result Summary">[tab:Result Summary]</a> summarises
the results of each calculation (Throughput, CPO, Energy Consumption per
Operation).</p>
<h3 id="sec:discussion">Discussions</h3>
<p>The results highlight the areas where there are clear performance
gaps in the implementations on each accelerator. For example, the HLS
may not be the best approach to implement all algorithms due to the
compiler not optimally translating custom C++ code to Verilog, resulting
in performance degradation compared to hand-written FPGA code.
Therefore, our benchmarking framework contains a consistent set of
metrics to assess various implementations and understand the trade-offs
between each target hardware. The results from the framework indicate
two generic conclusions: 1) FPGAs are better suited to meet power
budget, whereas GPUs can achieve faster execution time (as anticipated),
and 2) most optimised performance can be achieved through heterogeneous
computing, especially in real-time imaging.</p>
<p>For example, in implementing SIFT, the sub-algorithms <em>Gaussian
Pyramid</em> and <em>Descriptor Generation</em> are better suited to
GPUs due to faster execution time and throughput, whereas <em>Extrema
Detection</em> and <em>Orientation</em> are worthy of targeting FPGAs
due to their energy consumption profile. For the first two, GPU consumes
<span class="math inline">\(\sim\)</span>1 &amp; <span
class="math inline">\(\sim\)</span>8 nanoJoule more energy per
operation, respectively, but in trade for significant speedup. On the
contrary, the latter ones are closely comparable using the throughput
and execution time metrics on the GPU and FPGA. However, the power
consumed per operation for both algorithms is significantly lower for
the FPGA, and hence, the FPGA is better suited. Therefore, partitioning
SIFT to target a heterogeneous architecture would benefit from both
power and speed performance improvements. However, it is worth noting
that such partitioning will incur the cost of frequent memory transfer
between architectures.</p>
<p>In the case of the edge detection pipeline from <em>RGB2GRAY</em> to
<em>Sobel</em>, the GPU is <span class="math inline">\(\sim2\)</span>x
faster than the FPGA but at the cost of more energy consumption.
Therefore, it may be ideal to select the FPGA platform, especially
within an embedded system with low power constraints. Furthermore, the
low latency of FPGAs would achieve better execution time if the GPU
initialisation and memory transfer time are taken into account.
Therefore, when considering the deployment of an algorithm on a GPU,
it’s vital to ensure that the speedup gained from the GPU’s parallel
processing capabilities outweighs this initial transfer overhead. If the
algorithm doesn’t run sufficiently fast on the GPU to compensate for
this initialisation time, it might not be the optimal choice for
real-time or low-latency requirements. In such cases, relying on
low-latency architectures such as FPGA offers better overall
performance. This highlights the importance of a holistic evaluation of
execution times, factoring in initialisation and processing time, before
deciding on the accelerator. Additionally, GPUs require a CPU to
allocate tasks and manage memory which means additional idle power being
consumed.</p>
<p>In the CNN pipeline, the FPGA computes the <em>RGB2GRAY</em> and
<em>Resize</em> faster than the other architectures but is <span
class="math inline">\(1.45\times\)</span> slower in CNN inference
compared to GPU. However, when considering power consumption and image
transfer latency, it is better to pipeline all the operations on an
FPGA. The GPU may be better suited to training models or executing
larger CNNs that are too big to fit onto FPGA logic. The hand-written
FPGA is highly sensitive to implementation and optimisations but allows
more granular control over design, while GPUs benefit from a mature
ecosystem of compilers and tools. These compilers can automatically
optimise and implement core operations, often with high efficiency.</p>
<p>In terms of qualitative visual quality, images processed by CPU, GPU,
and FPGA all appear similar since the precision is kept the same for
each algorithm. However, for a more comprehensive assessment, deeper
analysis can be conducted using visual metrics algorithms
(<em>e.g.</em>, SSIM, RSME) or through human-based visual
experiments.</p>
<h2 id="sec:conclusion">Conclusions</h2>
<p>This chapter discusses the importance of understanding the properties
of image processing algorithms to determine which hardware accelerator
is suitable and if it can benefit from heterogeneous architecture,
especially for real-time vision applications. To facilitate such
insight, a benchmarking framework is proposed to observe the features of
image processing algorithms and provide a consistent set of metrics to
identify trade-offs in performance and energy efficiency of various
hardware accelerators, including CPUs, GPUs and FPGAs. We selected
commonly used low, medium and high-level image processing operations as
exemplars, dissected them in sub-algorithms, and benchmarked their
throughput and energy consumption profiles on each hardware. The results
indicate that partitioning algorithms based on their memory latency,
energy consumption and throughput profiles have the potential for
efficient deployment on heterogeneous hardware in achieving optimised
performance at a lower power.</p>
<p>The performance variations are influenced by factors such as
parallelism, memory access patterns, and the capability of each
architecture to map algorithmic operations efficiently. Algorithms that
contain large data size parallel operations and have regular memory
access patterns tend to perform well on GPU, while FPGA and HLS
architectures may perform better for smaller data sized operations.
However, both face challenges optimising for irregular memory access
patterns and complex algorithmic computations. The FPGA delivers great
performance relative to its size, clock and processing resources, but
the specialised nature of its architecture is highly sensitive to how
the design is implemented. Translating HLS code to hardware can
introduce overheads, potentially affecting performance. While HLS tools
expedite design cycles, they might not always match the optimisation of
manual hardware designs, leading to possible inefficiencies in resource
allocation and data paths.</p>
<div class="landscape">

</div>
<h1 id="chap:DSO">Domain-Specific Optimisations</h1>
<p><span id="sec1" data-label="sec1"></span> In recent years, real-time
vision systems on embedded hardware have become ubiquitous due to the
increased need for different applications such as autonomous driving,
edge computing, remote monitoring, etc. Field Programmable Gate Arrays
(FPGA) offer the speed and flexibility to architect tight-knit designs
that are power and resource-efficient. It has resulted in FPGAs becoming
integrated into many applications <span class="citation"
data-cites="bhowmik2018embedded"></span>. Often, these designs consist
of many low to high-level image processing algorithms that form a
pipeline. Increasingly, the race for faster processing encourages
hardware application developers to optimise the algorithms.</p>
<p>Traditionally, optimisations are domain agnostic and developed for
general purpose computing. The majority of these optimisations aim to
improve throughput and resource usage by increasing the number of
parallel operations <span class="citation"
data-cites="VouKalLy16"></span>, memory bandwidth <span class="citation"
data-cites="ChaDar14"></span> or operations per clock cycle <span
class="citation" data-cites="LeyDomGar14"></span>. On the contrary,
domain-specific optimisations are more specialised in a particular
domain and can potentially achieve larger gains in faster processing and
reducing power consumption. This chapter proposes domain-specific
optimisation techniques on FPGAs that exploit the inherent knowledge of
the image processing pipeline.</p>
<p>In demonstrating the proposition, a thorough analysis is presented of
well-known image processing algorithms, emerging CNN architectures
(MobileNet<span class="citation" data-cites="SanMarkHowAnd18"></span>
&amp; ResNet<span class="citation" data-cites="HeZhaXia16"></span>), and
Scale Invariant Feature Transform (SIFT) <span class="citation"
data-cites="lowe2004distinctive"></span>. The decision to include
MobileNet is influenced by its popular use within embedded systems, and
ResNet is included for its consistently higher accuracy rates compared
to other available architectures. Additionally, SIFT is chosen for being
the most popular feature extraction algorithm, owing to its performance
and accuracy. Algorithmic properties are exploited with the proposed
domain-specific optimisation strategies. The optimised design undergoes
evaluation and comparison with other general optimised hardware designs
regarding performance, energy consumption, and accuracy. The main
contributions of this chapter are:</p>
<p>Proposition of four domain-specific optimisation strategies for image
processing and analysing their impact on performance, power and
accuracy; and</p>
<p>Validation of the proposed optimisations on widely used
representative image processing algorithms and CNN architectures
(MobilenetV2 &amp; ResNet50) through profiling various components in
identifying the common features and properties that have the potential
for optimisations.</p>
<h2 id="sec:Domain-Specific Optimisations">Domain-Specific
Optimisations</h2>
<p>Image processing algorithms typically form a pipeline with a series
of processing blocks. Each processing block consists of a combination of
low, mid, intermediate and high-level imaging operations, starting from
colour conversion, filtering to histogram generation, features
extraction, object detection or tracking. Any approximation and
alteration to the individual processing block or the pipeline have an
impact on the final outcome, such as overall accuracy or runtime.
However, depending on the applications, such alterations are expected to
be acceptable as long as they are within a certain error range (e.g.,
<span class="math inline">\(\sim \pm 10\%\)</span>).</p>
<p>Many image processing algorithm operations share common functional
blocks and features. Such features are useful for forming
domain-specific optimisation strategies. Within the scope of this work,
image processing algorithms are profiled and analysed to enable
potential areas for optimisations. However, such optimisations impact
algorithmic accuracy and therefore, it is important to identify the
trade-off between performance, power, resource usage, and accuracy.</p>
<p>The hypothesis suggests that understanding of domain knowledge, e.g.,
processing pipeline, individual processing blocks, or algorithmic
performance, can be used for optimisations to gain significant
improvements in runtime and lower power consumption, especially in
FPGA-based resource-limited environments. Based on the common patterns
observed in a variety of image processing applications, this section
proposes four domain-specific optimisation (DSO) approaches: <em>1)
downsampling</em>, <em>2) datatype</em>, <em>3) separable filter</em>
and <em>4) convolution kernel size</em>. However, on the flip side,
optimisation often leads to lower accuracy in return for gains in speed
and lower energy consumption. The effectiveness of these optimisations
is compared against benchmark FPGA, GPU and CPU implementations, showing
the impact on accuracy. Within the scope of this thesis, four
optimisation strategies have been identified and are discussed
below:</p>
<h3 id="optimisation-i-down-sampling">Optimisation I: Down Sampling</h3>
<p>Down/subsampling optimisation reduces the data dimensionality while
largely preserving image structure and hence accelerates runtime by
lowering the number of computations across the pipeline. Sampling rate
conversion operations such as downsampling/subsampling are widely used
within many application pipelines (<em>e.g.</em>, low bit rate video
compression <span class="citation" data-cites="LinDon06"></span> or
pooling layers in Convolutional Neural Network (CNN) <span
class="citation" data-cites="lecun1998gradient"></span>) to reduce
computation, memory and transmission bandwidth. Image downsampling
reduces the spatial resolution while retaining as much information as
possible. Many image processing algorithms use this technique to
decrease the number of operations by removing every other row/column of
an image to speed up the execution time. However, the major drawback is
the loss of image accuracy due to removing pixels. <em>down sampling
optimisation</em> used for each selected algorithm is a bilinear
interpolation, and both runtime and accuracy are measured.</p>
<p>Bilinear downsampling is a technique that reduces the number of
pixels in an image by computing each output pixel as a weighted average
of its four nearest input pixels. The weights, represented by
interpolation factors <span class="math inline">\(\alpha_i\)</span> and
<span class="math inline">\(\beta_i\)</span>, are determined based on
the distances between the target output pixel <span
class="math inline">\((x, y)\)</span> and the neighbouring input pixels
<span class="math inline">\((x_i, y_i)\)</span> in both the horizontal
and vertical directions. These factors contribute to a smoothed,
downsampled image by interpolating colour values based on the
surrounding pixel information. Mathematically, the value of a
downsampled pixel <span class="math inline">\(D(x,y)\)</span> can be
calculated using the following equation: <span
class="math display">\[D(x,y) = \sum_{i=1}^{4} \alpha_i \cdot \beta_i
\cdot I(x_i, y_i)\]</span> Where <span
class="math inline">\(D(x,y)\)</span> represents the downsampled pixel
value at location <span class="math inline">\((x, y)\)</span> in the
downscaled image, and <span class="math inline">\(I(x_i, y_i)\)</span>
represents the intensity (colour value) of the neighbouring pixel <span
class="math inline">\((x_i, y_i)\)</span> in the original image.
Downsampling reduces the image size between octaves in the ’Gaussian
pyramid’ construction stage.</p>
<h3 id="optimisation-ii-datatype">Optimisation II: Datatype</h3>
<p>Bit width reduction through datatype conversion (<em>e.g.</em>,
floating-point (FP) to integer) significantly reduces the number of
arithmetic operations, resulting in optimised runtime at lower
algorithmic accuracy. Whilst quantising from FP to integer
representations is common in the software domain, one of the advantages
of reconfigurable hardware is the capability to reduce dimensionality to
arbitrary sizes (<em>e.g.</em>, 7, 6, 5, 4 bits) as a trade-off between
accuracy and power/performance.</p>
<p>Consider an image where each pixel has a floating-point value in the
range of <span class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>. A straightforward way to perform
quantisation is to map these values to a set of integers. One commonly
used formula for this conversion is:</p>
<p><span class="math display">\[Q(x) = \text{round}(x \times (2^k -
1))\]</span></p>
<p>Here, <span class="math inline">\(Q(x)\)</span> is the quantised
value, <span class="math inline">\(x\)</span> is the original
floating-point value, and <span class="math inline">\(k\)</span> is the
bit-depth (e.g., <span class="math inline">\(8\)</span> for an 8-bit
image). The function <span class="math inline">\(\text{round}\)</span>
rounds the value to the nearest integer. This equation multiplies the
floating-point value by <span class="math inline">\(2^k - 1\)</span>
(255 for an 8-bit image) and rounds it, converting the value into an
integer between <span class="math inline">\(0\)</span> and <span
class="math inline">\(2^k - 1\)</span>. This process significantly
reduces the data size and computational requirements, albeit with some
loss of information due to rounding. The converted integer values can
then be used in place of the floating-point values for further
processing tasks.</p>
<p>In image processing, most algorithms are inherently developed using
floating-point (FP) calculations. Although FP offers higher accuracy, it
comes at the expense of computational complexity and, therefore,
increased resource and energy consumption. A viable alternative is
fixed-point arithmetic, where a fixed location of the decimal point
separates integers from fractional numbers. Opting for fixed-point
representation can significantly improve computational speed, albeit at
the cost of some accuracy. Here, a <em>datatype conversion</em>
optimisation is proposed, wherein all operational stages are converted
from FP to integer arithmetic. This conversion allows for an evaluation
of the trade-off between performance and accuracy.</p>
<h3 id="optimisation-iii-iv-convolution">Optimisation III &amp; IV:
Convolution</h3>
<p>Convolution kernel size optimisation reduces computational
complexity, which is directly proportional to the squared size of the
filter kernel size, i.e., <span
class="math inline">\(\mathcal{O}(n^2)\)</span> or quadratic time
complexity. Convolution is a fundamental operation employed in most
image processing algorithms that modify the spatial frequency
characteristics of an image. Given a kernel and image size <span
class="math inline">\(n \times n\)</span> and <span
class="math inline">\(M \times N\)</span>, respectively, convolution
would require <span class="math inline">\(n^2\times M \times N\)</span>
multiplications and additions. For a given image, complexity is
dependent on the kernel size, leading to a complexity of <span
class="math inline">\(\mathcal{O}(n^2)\)</span>. Reducing kernel size
significantly lowers the number of computations; for example, replacing
a <span class="math inline">\(5 \times 5\)</span> kernel with a <span
class="math inline">\(3\times3\)</span> kernel would reduce the
computation by a factor of <span
class="math inline">\(\times2.7\)</span>. Therefore, this is proposed as
an ideal target for optimisation, although it may come at the cost of
accuracy.</p>
<p><span class="math display">\[\label{eq:Separable}
\begin{aligned}
\quad
\frac{1}{4}
\begin{bmatrix}
1 \\ 2 \\ 1
\end{bmatrix}
\quad
\times
\quad
\frac{1}{4}
\begin{bmatrix}
1 &amp; 2 &amp; 1
\end{bmatrix}
=
\frac{1}{16}
\begin{bmatrix}
1 &amp; 2 &amp; 1 \\
2 &amp; 4 &amp; 2 \\
1 &amp; 2 &amp; 1
\end{bmatrix}
\end{aligned}\]</span></p>
<p>Another convolution optimisation strategy is separable filters, which
is a type of linear filter that can be broken down into a series of 1D
filters shown in Eq.<a href="#eq:Separable" data-reference-type="ref"
data-reference="eq:Separable">[eq:Separable]</a>, making it
computationally efficient for image processing tasks. The separability
property stems from the ability to represent a 2D filter kernel as the
outer product of two 1D kernels. This means that instead of directly
convolving the image with a 2D kernel, one can first convolve it along
the rows with a 1D kernel and then convolve the result along the columns
with another 1D kernel. The formula for a separable filter can be
expressed as:</p>
<p><span class="math display">\[H(x, y) = F(x) \cdot G(y)\]</span></p>
<p>where <span class="math inline">\(H(x,y)\)</span> is the 2D filter
kernel, <span class="math inline">\(F(x)\)</span> is the 1D filter
kernel applied along the rows, and <span
class="math inline">\(G(y)\)</span> is the 1D filter kernel applied
along the columns. By separating the filtering process into 1D
convolutions, the number of operations required is significantly
reduced, leading to faster image filtering compared to non-separable
filters. Common examples of separable filters include Gaussian filters
and the Sobel operator for edge detection.</p>
<h2 id="sec:SIFT">Case Study Algorithms</h2>
<p>In this section, an overview of the representative algorithms
targeted for optimisation is presented, as discussed in Section <a
href="#sec:Domain-Specific Optimisations" data-reference-type="ref"
data-reference="sec:Domain-Specific Optimisations">5.1</a>.
Subsequently, the proposed optimisations will be applied to enhance
their performance.</p>
<h3 id="sift">SIFT</h3>
<figure id="fig:SIFTBlockDiagram">
<img src="Images/AlgorithmDiagram.png" />
<figcaption>SIFT Algorithmic Block Diagram.</figcaption>
</figure>
<p>SIFT <span class="citation" data-cites="lowe2004distinctive"></span>
is one of the widely used prototypical feature extraction algorithms. To
demonstrate the proposed optimisations, various versions of SIFT have
been implemented, consisting of two main and several sub-components as
shown in Fig. <a href="#fig:SIFTBlockDiagram" data-reference-type="ref"
data-reference="fig:SIFTBlockDiagram">5.1</a> and described below.</p>
<h4 class="unnumbered" id="scale-space-construction">Scale-Space
Construction</h4>
<figure id="fig:ScaleSpace">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;">(b)</td>
</tr>
</tbody>
</table>
<figcaption>a) Scale-Space Hardware Block Diagram b) Extrema Detection
in Local Space/Scale Neighbourhood </figcaption>
</figure>
<h5 id="gaussian-pyramid">Gaussian Pyramid</h5>
<p>The Gaussian pyramid <span
class="math inline">\(L(x,y,\sigma)\)</span> is constructed by taking in
an input image <span class="math inline">\(I(x,y)\)</span> and
convolving it at different scales with a Gaussian kernel <span
class="math inline">\(G(x,y,\sigma)\)</span>: <span
class="math display">\[\begin{aligned}
\label{eq:SIFT1}
    G(x,y,\sigma) &amp;= \frac{1}{2 \pi \sigma ^2} e^{- \frac{x^2 +
y^2}{2 \sigma ^2}}, \\
    L(x,y,\sigma)&amp;=G(x,y,\sigma) * I(x,y),
\end{aligned}\]</span> Where <span class="math inline">\(\sigma\)</span>
is the standard deviation of the Gaussian distribution. The input image
is then halved into a new layer (octave), which is a new set of Gaussian
blurred images. The number of octaves and scales can be changed
depending on the requirements of the application.</p>
<p>The implemented block design reads pixel data of input images into a
line buffer shown in Fig. <a href="#fig:ScaleSpace"
data-reference-type="ref" data-reference="fig:ScaleSpace">5.2</a>(a).
The operations in this stage are processed in parallel for maximum
throughput. This is due to significant matrix multiplication operations,
which greatly impact the runtime. This stage is the most computationally
intensive, making it an ideal candidate for optimisation.</p>
<p>The Difference of Gaussian <span
class="math inline">\({DOG}(x,y,\sigma)\)</span>, in Eq.<a
href="#eq:SIFT3" data-reference-type="ref"
data-reference="eq:SIFT3">[eq:SIFT3]</a> is obtained by subtracting the
blurred images between two adjacent scales, separated by the
multiplicative factor <span class="math inline">\(k\)</span>.</p>
<p><span class="math display">\[\label{eq:SIFT3}
    \textsl{DOG}(x,y,\sigma)=L(x,y,k\sigma)-L(x,y,\sigma).\]</span></p>
<p>The minima and maxima of the <span class="math inline">\(DOG\)</span>
are detected by comparing the pixels between scales shown in Fig. <a
href="#fig:ScaleSpace" data-reference-type="ref"
data-reference="fig:ScaleSpace">5.2</a>(b). This identifies points that
are best representations of a region of the image. The local extrema are
detected by comparing each pixel with its <span
class="math inline">\(26\)</span> neighbours in the scale space (<span
class="math inline">\(8\)</span> neighbour pixels within the same scale,
<span class="math inline">\(9\)</span> neighbours within the above/below
scales). Simultaneously, the candidate keypoints with low contrast or
located on an edge are removed.</p>
<h4 class="unnumbered" id="descriptor-generation">Descriptor
Generation</h4>
<figure id="fig:Descriptor Generation">
<img src="Images/keypoint.png" />
<figcaption>Magnitude &amp; Orientation Assignment and Keypoint
Descriptor Generation</figcaption>
</figure>
<h5 class="unnumbered" id="magnitude-orientation-assignment">Magnitude
&amp; Orientation Assignment</h5>
<p>Inside the SIFT descriptor process shown in Fig. <a
href="#fig:Descriptor Generation" data-reference-type="ref"
data-reference="fig:Descriptor Generation">5.3</a>, the keypoint’s
magnitude and orientation are computed for every pixel within a window
and then assigned to each feature based on the local image gradient.
Considering <span class="math inline">\(L\)</span> is the scale of
feature points, the gradient magnitude <span
class="math inline">\(m(x,y)\)</span> and the orientation <span
class="math inline">\(\theta (x,y)\)</span> are calculated as:</p>
<p><span class="math display">\[\begin{aligned}
    m(x,y) &amp;=\sqrt{L_{x}(x,y)+L_{y}(x,y)}, \\
    \theta (x,y) &amp;=tan^{-1}\left (
\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)} \right).
    \label{eq:SIFT5}
\end{aligned}\]</span> Once the gradient direction is obtained from the
result of pixels in the neighbourhood window, a <span
class="math inline">\(36\)</span> bin histogram is generated. The
magnitudes are Gaussian weighted and accumulated in each histogram bin.
During the implementation, <span class="math inline">\(m(x,y)\)</span>
and <span class="math inline">\(\theta (x,y)\)</span> are computed based
on the CORDIC algorithm <span class="citation"
data-cites="andraka1998survey"></span> in vector mode to map efficiently
on an FPGA.</p>
<h4 class="unnumbered" id="keypoint-descriptor">Keypoint Descriptor</h4>
<p>After calculating the gradient direction around the selected
keypoints, a feature descriptor is generated. First, a <span
class="math inline">\(16\times16\)</span> neighbourhood window is
constructed around a keypoint and then divided into sixteen <span
class="math inline">\(4\times4\)</span> blocks. An <span
class="math inline">\(8\)</span>-bin orientation histogram is computed
in each block. The generated descriptor vector consists of all histogram
values, resulting in a vector of <span class="math inline">\(16 \times 8
= 128\)</span> numbers. The <span
class="math inline">\(128\)</span>-dimensional feature vector is
normalised to make it robust from rotational and illumination
changes.</p>
<h4 class="unnumbered" id="SIFTHardwareDesc">SIFT Hardware
Implementation</h4>
<figure id="fig:SIFTBlock">
<img src="Images/SIFTBLOCK.png" />
<figcaption>High-level block diagram of the SIFT algorithm on
FPGA</figcaption>
</figure>
<p>The high-level hardware block diagram depicted in Fig. <a
href="#fig:SIFTBlock" data-reference-type="ref"
data-reference="fig:SIFTBlock">5.4</a> of SIFT illustrates the
individual modules that build up the complete algorithm.</p>
<p><strong>Scale-Space Construction:</strong></p>
<figure id="fig:GaussModule">
<img src="Images/ScaleSpaceModule.png" />
<figcaption>Gaussian Convolution Module Block Diagram.</figcaption>
</figure>
<p>To efficiently process the image data, the Gaussian convolution
module observed in Fig. <a href="#fig:GaussModule"
data-reference-type="ref" data-reference="fig:GaussModule">5.5</a> uses
line buffers to store and process pixel data. As pixel data streams into
the FPGA, it is stored in the buffers organised in rows corresponding to
image rows. These line buffers hold a portion of the image data needed
to compute the convolution operation. Using line buffers, the FPGA can
process multiple pixels simultaneously, reducing latency and increasing
throughput. Furthermore, pre-calculated coefficients defining the
approximated Gaussian weights are applied to the pixel values during
filtering and are stored in BRAM registers. The implementation uses
separable filters, the module first applies a one-dimensional Gaussian
filter in the horizontal direction followed by another in the vertical
direction.</p>
<p>In addition, handling boundary pixels is vital to preserve image
integrity. However, in this implementation focused on a <span
class="math inline">\(1920\times1080\)</span> image size, boundary
pixels are neglected to simplify hardware design.</p>
<figure id="fig:ExtremaHW">
<img src="Images/Extrema.png" />
<figcaption>Extrema Detection Module Block Diagram.</figcaption>
</figure>
<p>Subsequently, adjacent levels of the Gaussian pyramid are subtracted
from each other to obtain the DoG pyramid. This subtraction operation is
preformed in parallel between each scale and the three resulting DoG are
buffered. Two row buffers are used for every DoG and form a <span
class="math inline">\(3 \times 3\)</span> neighbourhood for extrema
detection. Fig. <a href="#fig:ExtremaHW" data-reference-type="ref"
data-reference="fig:ExtremaHW">5.6</a> illustrates the design of maxima
detector module where each pixel is then compared to its 26 neighbors,
and the minimum magnitude is computed to determine the local extremum.
Each DoG buffers output consists of three values that constitute one
column of a 3x3 neighbouring window. The DoG words are forwarded to a
comparator circuit which compares the middle pixel of DoG2 with its
neighbours, and an OR gate indicates if it’s an extremum. Note that the
first row is processed on the fly without requiring buffers, since DoG
operation is a single-pixel operation and doesn’t affect the boundaries.
The width of these buffers depends on the range of the DoG operation
results.</p>
<p><strong>CORDIC &amp; Prewitt Mask Module:</strong></p>
<figure id="fig:CORDIC">
<img src="Images/CORDIC.png" />
<figcaption>CORDIC Module Block Diagram. <span class="citation"
data-cites="AMD12"></span></figcaption>
</figure>
<p>In the proposed implementation, the first derivatives of G2, are
produced by applying Prewitt mask operator to generates the first-order
derivatives of the image with respect to both the x and y directions.
The magnitude is efficiently computed using the sum of absolute values
of <span class="math inline">\(G_x^2\)</span> and <span
class="math inline">\(G_y^2\)</span>. This approach replaces the square
root operation traditionally used in gradient magnitude calculations.
After computation, the result is stored as 8 bits, retaining only the
integer part of the magnitude for subsequent calculations. The gradient
orientation is computed traditionally by using large Look-Up Tables
(LUTs) for precomputed arctangents and hardware resources for division
operations. However, the implementation uses Xilinx IP CORDIC module,
which solves trigonometric equations iteratively and also computes a
broader range of equations, including the hyperbolic and square root.
The output orientation assignments are stored as a 6-bit integers.</p>
<p><strong>Histogram &amp; Normalisation Module:</strong></p>
<p>In the SIFT descriptor generation stage, each keypoint contributes to
histogram entries representing gradient orientations and magnitudes
within a local region. Keypoints may influence multiple orientation
bins, leading to limited parallelisation. To address this, the
descriptor computation utilises eight BRAMs, each dedicated to a
specific orientation bin. These arrays independently accumulates data
from keypoints associated with a particular orientation, enabling
parallel processing. Keypoint coordinates and orientation information
are used to distribute magnitude contributions across the arrays. The
non-data dependent nature of each array allows for pipelined
accumulation and simultaneous processing of multiple keypoints. After
processing all the keypoints, an adder tree sums histogram values stored
in the array.</p>
<figure id="fig:Descriptorgenblock">
<img src="Images/Descriptor Gen.png" />
<figcaption>Descriptor Normalisation Block Diagram</figcaption>
</figure>
<p>The unnormalised histogram data is streamed into the final module
shown in Fig. <a href="#fig:Descriptorgenblock"
data-reference-type="ref"
data-reference="fig:Descriptorgenblock">5.8</a> that performs
normalisation. The input data is converted into floating point
representation, to ensure accuracy and comparability with other hardware
architectures. Once, converted the data is stored into BRAM and L1-norm
of the histogram is calculated concurrently using DSPs. Each entry in
the histogram is subsequently divided by the computed L1-norm, followed
by a square root operation. The resulting normalised values are then
converted from floating-point to fixed-point representation (8 bit) to
minimise storage space. Furthermore, the outputs from each processing
element are accumulated into a unified output vector using a combination
of FIFO buffers and a multiplexer.</p>
<h3 id="digital-filters">Digital Filters</h3>
<figure id="fig:filter-kernels">

<figcaption>Example approximated <span
class="math inline">\(3\times3\)</span> image filter
kernels.</figcaption>
</figure>
<p>Digital filters are a tool in image processing to extract useful
information from noisy signals. They are commonly used for tasks such as
smoothing, edge detection, and feature extraction. Filters operate by
applying a kernel, or a small matrix of values, to each pixel of an
image. The kernel is convolved with the image, and the resulting output
value is placed in the corresponding pixel location of the output image
shown in the Eq. (<a href="#eq:kernel" data-reference-type="ref"
data-reference="eq:kernel">[eq:kernel]</a>). <span
class="math inline">\(I(x,y)\)</span> is the input image and <span
class="math inline">\(K(k_x,k_y)\)</span> is the kernel. The convolution
result <span class="math inline">\(O(x,y)\)</span> is calculated by:</p>
<p><span class="math display">\[\label{eq:kernel}
\begin{aligned}
O(x, y) &amp;= \sum_{k_x} \sum_{k_y} I(x - k_x, y - k_y) \cdot K(k_x,
k_y)
\end{aligned}\]</span></p>
<p>The indices <span class="math inline">\(k_x\)</span> and <span
class="math inline">\(k_y\)</span> correspond to the coordinates of the
kernel <span class="math inline">\(K\)</span>, <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> correspond to the coordinates of the
output image <span class="math inline">\(O\)</span>.</p>
<h3 id="sec:CNN">Convolutional Neural Network</h3>
<figure id="fig:CNN">
<img src="Images/CNN.png" />
<figcaption>Typical layers implemented within CNN
Architectures.</figcaption>
</figure>
<p>Convolutional Neural Networks are a class of deep neural networks
typically applied to images to recognise and classify particular
features. A CNN architecture typically consists of a combination of
convolution, pooling, and fully connected layers shown in Fig. <a
href="#fig:CNN" data-reference-type="ref"
data-reference="fig:CNN">5.10</a>.</p>
<p>The convolution layers extract features by applying a convolution
operation to the input image using a set of learnable filters (also
called kernels or weights) designed to detect specific features. The
output of the convolution operation is a feature map, which is then
passed through a non-linear activation function, such as ReLU, to
introduce non-linearity into the network. The convolutional layers can
be stacked to form a deeper architecture, where each layer is designed
to detect more complex features than the previous one. In addition, it
is the most computationally intensive layer because each output element
in the feature map is computed by repeatedly taking a dot product
between the filter and a local patch of the input, which results in a
large number of multiply-add operations.</p>
<p>The pooling layers are responsible for reducing the spatial size of
the feature maps while retaining important information. The most common
types of pooling are max pooling and average pooling. These layers
typically use a small window that moves across the feature map and
selects the maximum or average value within the window. This operation
effectively reduces the number of parameters in the network and helps to
reduce overfitting.</p>
<p>The fully connected layers make predictions based on the extracted
features. These layers take the output from the convolutional and
pooling layers and apply a linear transformation to the input, followed
by a non-linear activation function. The fully connected layer usually
has the same number of neurons as the number of classes in the dataset,
and the output of this layer is passed through a softmax activation
function to produce probability scores for each class. A CNN
architecture also includes normalisation layers such as batch
normalisation, dropout layers that are used to regularise the network
and reduce overfitting, and an output layer that produces the final
predictions.</p>
<h2 id="sec:result">Experimental Results and Discussion</h2>
<figure id="fig:FilterAlgorithms">
<img src="Images/FilterAlgorithms.png" />
<figcaption>Filter Algorithms Applied onto Input Image</figcaption>
</figure>
<p>We verify the proposed optimisations on ’SIFT’, ’Box’, ’Gaussian’ and
’Sobel’ (in Fig. <a href="#fig:FilterAlgorithms"
data-reference-type="ref"
data-reference="fig:FilterAlgorithms">5.11</a>) algorithms, as well as
MobileNetV2 and ResNet50 CNN architectures. This is achieved by creating
baseline benchmarks on four target hardware CPU, GPU and FPGA, followed
by the realisations of the optimisations individually and combined. The
CPU and GPU versions for Filter and SIFT algorithms are implemented
using <em>OpenCV</em><span class="citation"
data-cites="opencv_library"></span>. Pytorch library is used to
implement CNN architectures (ResNet50 &amp; MobileNetV2) and
optimisations. Additionally, both architectures are pre-trained on the
image-net classification dataset. The FPGA implementation for all
algorithms is developed using Verilog (SIFT/Filter) and HLS (CNN). All
baseline algorithms and CNN models use floating point 32 (FP32), and an
uncompressed grayscale <span class="math inline">\(8\)</span>-bit <span
class="math inline">\(1920\times1080\)</span> input image is used for
the SIFT algorithm, and each sub-operation is profiled. Details of the
target hardware/software environments and power measurement tools are
given in Table <a href="#tab:HWEnvironment" data-reference-type="ref"
data-reference="tab:HWEnvironment">[tab:HWEnvironment]</a>.</p>
<p><strong>Dataset.</strong> The input images used in the CNN and Filter
experiments are from LIU4K-v2 dataset <span class="citation"
data-cites="LiuliuYan19"></span>. The dataset contains 2000 high
resolution <span class="math inline">\(3840\times2160\)</span> images
with various backgrounds and objects.</p>
<h3 id="performance-metrics-1">Performance Metrics</h3>
<p>As part of the evaluation process, we measure three different
performance metrics, namely, <em>1) execution time</em>, <em>2) energy
consumption</em> and <em>3) accuracy</em>.</p>
<h4 id="execution-time-1">Execution time</h4>
<p>The execution time measured for the CPU and GPU platforms uses time
function libraries to count the smallest tick period. Each
algorithm/operation is run for 1000 iterations and averaged to minimise
competing resources or other processes directly affecting the
architecture, especially for the CPU architecture. The GPU has an
initialisation time which is taken into account and removed from the
results. The timing simulation integrated into Vivado design suite
software is used to measure the time for the FPGA platform. The
experiments exclude the time of both the image read and write from
external memory. We compute the frame per second (FPS) as the inverse of
the execution time: <span class="math display">\[\label{eq:FPS}
\text{FPS}= 1/\text{Execution Time}.\]</span></p>
<h4 id="power-consumption-1">Power Consumption</h4>
<p>Two common methods used for measuring power are software and
hardware-based. Accurately estimating power consumption is a challenge
using software-based methods, which have underlying assumptions in their
models and may not measure other components within the platform. In
addition, taking the instantaneous watt or theoretical TDP of a device
is not accurate since power consumption varies on the specific workload.
Therefore, we obtain the total energy consumed by measuring the power
over the duration of the algorithm executed. A script is developed to
start and stop the measurements during the execution of the algorithm
and extract the power values from the software.</p>
<p>With the use of a power analyser within the Vivado design suite and
the MaxPower-tool, the measurement of FPGA power consumption is divided
into two parts, <em>(1)</em> static power and <em>(2)</em> dynamic
power. Static power relates to the consumption of power when there is no
circuit activity and the system remains idle. Dynamic power is the power
consumed when the design is actively performing tasks. The power
consumption for the CPU and GPU is obtained using <em>HWMonitor</em> and
<em>Nvidia-smi</em> software. To have a fair comparison across the
target hardware for the SIFT algorithm, we normalise it as the energy
per operation (EPO): <span class="math display">\[\label{eq:energy1}
\text{Energy} = (\text{Power} * \text{Execution Time}).\]</span></p>
<p>Additionally, We calculate the energy consumption for the Filter and
CNN algorithms:</p>
<p><span class="math display">\[\label{eq:energy}
\text{EPO} = (\text{Power} * \text{Execution
Time})/\text{Operations}.\]</span></p>
<h4 id="accuracy">Accuracy</h4>
<p>With an expectation that the optimisations impact overall algorithmic
accuracy, we capture it by measuring the <em>Euclidean distance</em>
between the descriptors generated from the CPU (our comparison
benchmark) to the descriptor output produced by the FPGA. The Euclidean
distance <span class="math inline">\(d(x,y)\)</span> is calculated in
Eq. (<a href="#eq:Euc" data-reference-type="ref"
data-reference="eq:Euc">[eq:Euc]</a>) where <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> are vectors, and <span
class="math inline">\(K\)</span> is the number of keypoints generated.
This accuracy measurement is only used for the SIFT algorithm
implementation.</p>
<p><span class="math display">\[\label{eq:Euc}
d(x,y)=\sqrt{\sum_{i=1}^{K} (x_{i}-y_{i})^{2}}.\]</span></p>
<p>Subsequently, the accuracy for each Euclidean distance is calculated
using Eq. (<a href="#eq:Accu" data-reference-type="ref"
data-reference="eq:Accu">[eq:Accu]</a>): <span
class="math display">\[\label{eq:Accu}
\text{Accuracy} = 100 - \left( \left( \frac{\text{Euclidean
Distance}}{\text{Max Distance}} \right) \times 100\right)\]</span></p>
<p>The <em>Euclidean Distance</em> denotes the distance between the two
descriptor vectors being compared, and <em>Max Distance</em> represents
the maximum Euclidean distance found in the vector. The accuracy is
transformed to have 100% indicate identical descriptors, while 0%
indicates completely dissimilar descriptors.</p>
<p>We used root mean square error (RSME) to compare the input image to
the output images produced by each hardware accelerator to determine the
pixel accuracy. RMSE is defined as: <span class="math display">\[RMSE =
\sqrt{(\frac{1}{n})\sum_{i=1}^{n}(y_{i} - x_{i})^{2}}\]</span> Where the
difference between the pixel intensity values of output and input
(y<sub>i</sub>,x<sub>i</sub>) images. Divided by N, which is the total
number of pixels in the image.</p>
<p>The accuracy of the CNN architecture is measured by taking the number
of correct predictions divided by the total number of predictions:</p>
<p><span class="math display">\[\text{Accuracy} = \frac{\text{Number of
Correct Predictions}}{\text{Total Number of Predictions}} \times
100\]</span></p>
<p>A high accuracy indicates that the model is making accurate
predictions, while a low accuracy suggests room for improvement in the
model’s performance.</p>
<h3 id="results-and-discussions">Results and Discussions</h3>
<p>The results and discussions section contains the evaluation of
algorithms in three categories, feature extraction algorithms
(<em>SIFT</em>), filter algorithms (<em>Box, Gaussian, Sobel</em>) and
Convolution Neural Networks (<em>MobilenetV2, ResNet50</em>).</p>
<h4 id="sift-1">SIFT</h4>
<figure id="fig:ResAccGraph">

<figcaption>SIFT: FPS (Bars) and Accuracy (Dots) for each optimisation
on both configurations (octave, scale).</figcaption>
</figure>
<p>We obtain results for FPGA implementations of the SIFT algorithm,
considering various optimisations or combinations of them. Two sets of
results are captured for <em>octave, scale</em> of (2,4) and (4,5) as
they are regularly reported in the literature for SIFT implementation on
FPGA. The results are primarily obtained at a target frequency of 300
MHz for various components of SIFT and execution time and accuracy are
reported in Table <a href="#tab:Optimisation_Summary"
data-reference-type="ref"
data-reference="tab:Optimisation_Summary">[tab:Optimisation_Summary]</a>
along with FPS numbers in Fig. <a href="#fig:ResAccGraph"
data-reference-type="ref" data-reference="fig:ResAccGraph">5.12</a>.</p>
<p>In terms of individual optimisations on the base FPGA implementation,
<em>down sampling</em> and <em>integer</em> optimisations had the most
reduction of accuracy but in trade for a greater reduction of runtime.
On the other hand, <em><span class="math inline">\(3\times3\)</span>
kernel size</em> (down from default <span class="math inline">\(5\times
5\)</span>) had better accuracy results but with a small improvement on
the overall runtime. In the case of combined optimisations, both
<em>down sampling</em> and <em>integer</em> combinations greatly reduced
the execution times but at a cost of <span
class="math inline">\(8\sim10\%\)</span> accuracy loss. In the most
optimised case, (4,5) and (2,4) configurations achieved <span
class="math inline">\(17\)</span> and <span
class="math inline">\(50\)</span> fps, at an accuracy of <span
class="math inline">\(90.18\%\)</span> and <span
class="math inline">\(89.45\%\)</span>, respectively. The <span
class="math inline">\(10 \sim 11\%\)</span> loss in accuracy in both
configurations can be attributed to the loss of precision and pixel
information resulting in imperfection in feature detection.</p>
<p>The comparison with optimised CPU and GPU implementations is shown in
Table <a href="#tab:platoformsummary" data-reference-type="ref"
data-reference="tab:platoformsummary">[tab:platoformsummary]</a> which
includes total execution time and energy consumption per operation
(nJ/Op). Results indicate the optimised FPGA implementation achieved
comparable GPU runtime at 600 MHz but significantly outperformed them
when energy consumption statistics are taken into account. The GPU
results excluded the initialisation time, which would add greater
latency to the overall runtime. In addition, the power consumption of
the GPU is at <span class="math inline">\(12.47\)</span>nJ/Op, which
would make it a difficult choice for real-time embedded systems. On the
other hand, optimised FPGA implementations have better performance per
watt than the GPU and CPU. The comparison with the state-of-the-art FPGA
implementations is reported in Table <a href="#tab:state_of_art"
data-reference-type="ref"
data-reference="tab:state_of_art">[tab:state_of_art]</a>, and results
show major improvements in the runtime even with larger image size and
more or similar feature points (<span
class="math inline">\(\sim10000\)</span>). Finally, for completeness, we
report the resource and power usage statistics for optimised
configurations at 300 MHz in Table <a href="#tab:resourseusage"
data-reference-type="ref"
data-reference="tab:resourseusage">[tab:resourseusage]</a>.</p>
<h4 id="filter-implementations">Filter Implementations</h4>
<figure id="fig:FilterRuntime">

<figcaption>Filter: Runtime comparison for optimisations applied on each
architecture. </figcaption>
</figure>
<figure id="fig:FilterEnergy">

<figcaption>Filter: Energy consumption comparison for optimisations
applied on each architecture.</figcaption>
</figure>
<p>Fig. <a href="#fig:FilterEnergy" data-reference-type="ref"
data-reference="fig:FilterEnergy">5.14</a> &amp; Fig. <a
href="#fig:FilterRuntime" data-reference-type="ref"
data-reference="fig:FilterRuntime">5.13</a> plots the runtime and energy
consumption of three image processing filter algorithms (<em>Box</em>,
<em>Gaussian</em>, and <em>Sobel</em>) with various optimisations
strategies applied to the baseline algorithm. Comparing the baseline
performance, the CPU architecture suffers the most in execution time and
energy consumption which can be attributed to the lack of many compute
cores. In contrast, GPUs and FPGAs exploit data parallelism and
stream/pipeline processing to significantly reduce runtime.</p>
<p>Both Fig. <a href="#fig:FilterEnergy" data-reference-type="ref"
data-reference="fig:FilterEnergy">5.14</a> &amp; Fig. <a
href="#fig:FilterRuntime" data-reference-type="ref"
data-reference="fig:FilterRuntime">5.13</a> show that the performance of
both GPU and FPGA are comparable in both metrics studied. The GPU
demonstrated a marginally better computation speed compared to the FPGA,
with an average execution time improvement of <span
class="math inline">\(9.45\%\)</span> for <em>Box</em> and
<em>Gaussian</em> algorithms. On the other hand, the FPGA has a <span
class="math inline">\(5.88\%\)</span> improvement for <em>Separable
Filter</em> over GPU.</p>
<p>In the case for <em>Sobel</em>, the FPGA achieves a speedup of
approximately <span class="math inline">\(1.09\times\)</span> over the
GPU across all optimisation strategies. The smaller kernel size allows
the FPGA to use its DSP slices to efficiently compute the algorithm,
whilst the GPU operations do not fully occupy the compute resources
available which results in load imbalance and communication latency.
Relative to power consumption, the CPU experiences the most significant
impact in all cases by consuming <span
class="math inline">\(1.19\times\)</span> Joules on average. The higher
energy usage can be attributed to their higher clock, complex memory
hierarchy and lack of parallel capability. The GPU has been observed to
consume <span class="math inline">\(\sim1.36\times\)</span> more Joules
than the FPGA. The high energy cost can be derived from the base
support/unused logic components consuming static power. However, the
FPGA operates on the least energy consumed per clock due to its
custom-written nature. The energy consumption for <em>seperable</em>
optimisation reveals similar results between the GPU and FPGA. This is
attributed to the GPU able to compute the algorithm faster to offset the
higher clock speed energy cost.</p>
<p>All optimisations, e.g <em>Datatype</em>, <em>Kernel</em>,
<em>Downsampling</em>, and <em>Separable Filters</em> optimisations had
major improvements for each accelerator. Reducing the kernel size to
<em><span class="math inline">\(3\times3\)</span> kernel size</em> and
applying <em>Separable Filters</em> had the most impact due to lowering
the number of operations computed during the convolution operation. The
<em>Datatype</em> and <em>Downsampling</em> optimisations had around on
average <em><span class="math inline">\(12.24\sim28.16\%\)</span></em>
decrease in runtime for all algorithms. The optimisation runtime results
and accuracies of each filter algorithm are reported in Table <a
href="#tab:ImageProcessingAlgorithmOptimisationSummary"
data-reference-type="ref"
data-reference="tab:ImageProcessingAlgorithmOptimisationSummary">[tab:ImageProcessingAlgorithmOptimisationSummary]</a>.
In terms of image accuracy, downsampling has the most significant
difference compared to the original, which can be attributed to the rows
that are removed due to the algorithm.</p>
<h4 id="cnn-architecture">CNN Architecture</h4>
<figure id="fig:CNNExecutionTime">

<figcaption>CNN: The graph compares execution time and accuracy across
three optimisation strategies (<strong>Baseline</strong>,
<strong>Datatype</strong>, <strong>DownSampling</strong>) on CPU, GPU,
and FPGA for two neural network models (<em>MobileNetV2</em> and
<em>ResNet50</em>). </figcaption>
</figure>
<p>Fig. <a href="#fig:CNNExecutionTime" data-reference-type="ref"
data-reference="fig:CNNExecutionTime">5.15</a> displays the runtime
performances and classification accuracy of the baseline and optimised
CNN algorithms on each hardware architecture. The results show that the
CPU, GPU, and FPGA exhibit similar levels of performance, with the GPU
having an average improvement of <span
class="math inline">\(5.41\sim12\%\)</span> over the FPGA for the
<em>Downsampling</em> optimisation in <em>MobileNetV2</em> and the
baseline for <em>ResNet50</em>, respectively. The FPGA leads in the
<em>Datatype</em> optimisation over the GPU with a <span
class="math inline">\(6.25-11.1\%\)</span> reduction in time for both
CNNs. The <em>Datatype</em> optimisation involves quantisation of the
model’s weights from FP32 to 8-bit to reduce complexity. The FPGA
computes the quantised operations faster on both architectures due to
exploiting the DSP blocks and requiring no additional hardware logic for
floating-point arithmetic. However, the quantised model weights are
unable to represent the full range of values present in the input image,
resulting in a <span class="math inline">\(\sim10\%\)</span> accuracy
loss for all platforms. The <em>Downsampling</em> strategy has a slight
improvement in runtime with minimal impact on the accuracy, with a loss
around <span class="math inline">\(\sim5\%\)</span>.</p>
<figure id="fig:CNNEnergy">

<figcaption>CNN: Architecture Energy comparison of Model
<em>Datatype</em> &amp; Input Image <em>Downsampling</em> Optimisations
on ResNet50 and MobilenetV2.</figcaption>
</figure>
<p>In Fig. <a href="#fig:CNNEnergy" data-reference-type="ref"
data-reference="fig:CNNEnergy">5.16</a>, the energy consumption graph
shows that the CPU consumes on average, <span
class="math inline">\(3.14\times\)</span> more energy than the other
accelerators for both CNNs. In addition, the <em>ResNet50</em>
architecture has more layers than <em>MobileNetV2</em> and, therefore,
contains more operations, resulting in higher energy usage. In all
cases, the FPGA consumes the least amount of energy, <span
class="math inline">\(1.11\sim3.55\times\)</span> less than the CPU and
GPU, to compute the image classification. The results show the potential
of reducing the computation time of CNNs by further applying the
proposed optimisations in a layer by layer basis, but at the cost of
slight accuracy loss. The optimisation results of each CNN architecture
and accuracy are reported in Table <a href="#tab:CNNSummaryTable"
data-reference-type="ref"
data-reference="tab:CNNSummaryTable">[tab:CNNSummaryTable]</a>.</p>
<p>Consequently, larger images or complex networks with many layers and
larger filter sizes require more memory to store the weights and
activations. This leads to higher memory requirements, especially within
real-time embedded systems where space is limited. However, applying
optimisations can alleviate the computational load, but careful
consideration must be taken to understand the trade-offs between runtime
and accuracy depending on the application. The <em>Kernel</em>
optimisations could not be implemented on the chosen CNN architectures,
which would require heavily modifying the standard convolution operation
in both networks. This would completely change the network, thus
creating a new architecture.</p>
<h2 id="conclusion-future-direction">Conclusion &amp; Future
Direction</h2>
<p>This chapter proposes new optimisation techniques called <em>domain
specific optimisation</em> for real-time image processing on FPGAs.
Common image processing algorithms and their pipelines are considered in
proposing such optimisations, which include down/subsampling, datatype
conversation and convolution kernel size reduction. These were validated
on the popular image processing algorithms and convolution neural
network architectures. The optimisation results for CNN and Filter
algorithms vastly improved the computation time for all processing
architectures. The SIFT algorithm implementation results significantly
outperformed state-of-the-art SIFT implementations on FPGA and achieved
runtime at par with GPU performances but with lower power usage.
However, the optimisations on all algorithms come at the cost of <span
class="math inline">\(\sim5-20\%\)</span> accuracy loss. Overall,
<em>Downsampling</em> and <em>datatype</em> optimisation resulted in the
most significant reductions in execution time and energy
consumption.</p>
<p>The results demonstrate that applying domain-specific optimisations
to increase computational performance while minimising accuracy loss
demands in-depth and thoughtful consideration. Furthermore, it should be
noted that the optimisations selected in the experiment are
non-exhaustive, leaving room for further exploration.</p>
<p>One proposal for algorithms comprising multiple operation stages is
to use adaptive techniques instead of fixed integer downsampling
factors, bit-widths, and kernel sizes. These adaptive methods analyse
the data and dynamically adjust the level of optimisation based on input
characteristics. For instance, adjusting the bit-width and downsampling
factor according to the specific input data within each stage can yield
better results and strike a more suitable trade-off between performance
and accuracy. Several strategies can be employed in the CNN domain to
address the challenges. Quantisation-Aware Training (QAT) and
mixed-precision training enable the model to adapt to lower precision
representations during training, reducing accuracy loss during inference
with quantised weights. Additionally, selective downsampling and kernel
size reduction of CNN architectures help retain relevant information and
preserve accuracy. Channel pruning can further offset accuracy loss by
removing redundant or less critical channels. As a result, employing
these strategies and considering hardware constraints makes it possible
to strike an optimal balance between accuracy and performance, unlocking
the full potential of efficient applications.</p>
<p>On the other hand, the drawback of traditional libraries and
compilers is that they often struggle to keep pace with the rapid
development of deep learning (DL) models, leading to sub-optimal
utilisation of specialised accelerators. To address the limitation,
adopting optimisation-aware domain-specific languages, frameworks, and
compilers is a potential solution to cater to the unique characteristics
of domain algorithms (<em>e.g.</em>, machine learning or image
processing). These tool-chains would enable algorithms to be
automatically fine-tuned, alleviating the burden of manual
domain-specific optimisation.</p>
<h1 id="sec:HCNN">Image Processing Algorithms on Heterogeneous Platforms
</h1>
<p>Feature extraction algorithms and Convolutional Neural Networks (CNN)
are widely used in various problem domains, such as object detection,
image classification, and segmentation. Feature Extraction are typically
designed to identify and extract relevant patterns or features from the
input data. These algorithms are typically designed and implemented on
DSPs or GPUs, which offer a specialised architecture properties which
include thousands of general compute cores and coupled with a large
amount of high-bandwidth memory.</p>
<p>In the case of CNNs that contain millions of parameters, which in
turn require significant memory resources to store their weights,
implementing them on low-resource and energy constrained platforms is
limited. Heterogeneous platforms solves these constraints by utilising
various specialised processors, such as CPUs, GPUs, TPUs, and FPGAs, to
process specific operations. Leveraging the advantages of true
heterogeneous architectures, run-time and power efficient designs can be
realised by exploiting architectures with sufficient resource and
processing capacity.</p>
<p>However, partitioning algorithms remain an arduous task, particularly
wh-en distributing operations among various accelerators within
heterogeneous architectures. This process necessitates a delicate
balance, taking into account critical factors such as computational
power, memory bandwidth, and communication overhead. Furthermore
scheduling tasks presents its own set of challenges. Scheduling involves
determining the order in which tasks are executed on different
processing units, considering factors such as task dependencies,
resource availability, and load balancing. Therefore, a scheduler is
required for managing hardware resources efficiently, controlling
concurrency, balancing workloads, prioritising tasks while adapting to
dynamic conditions. Thus, the scheduler plays a critical role in
orchestrating task execution to minimise data transfers and optimise
overall system performance</p>
<p>The important contributions of this chapter is the development of a
heterogeneous hardware and adaption of algorithms on that hardware.
Starting with an extensive analysis of popular feature extraction
algorithms such as SIFT and two CNN architectures, namely
<em>ResNet18</em><span class="citation" data-cites="SanHowZhu18"></span>
and <em>MobilnetV2</em><span class="citation"
data-cites="KaiXSha16"></span>. The feasibility of implementing these
algorithms and networks onto heterogeneous systems is investigated by
identifying the optimal stage in each network/algorithm to be mapped
onto a specific accelerator. A comprehensive benchmarking analysis of
the CNNs and SIFT is conducted by performing image classification and
feature extraction on a wide range of platforms to discern the layers or
stages that exhibit the highest energy consumption, inference, and total
runtime. Two new heterogeneous platforms are constructed, one comprising
high-performance accelerators and the other an embedded system with
power-optimised processors. The algorithms and networks are implemented
on both platforms using a fine-grained partitioning strategy and
evaluated. Heterogeneous results are compared to the homogeneous
accelerator counterparts to determine the best-performing
architecture.</p>
<p>The main contributions of this chapter are as follows:</p>
<p>Efficient deployment of CNNs and SIFT, which are computationally
faster and consume less energy, is proposed.</p>
<p>Partitioning methods on heterogeneous architectures are introduced by
studying the features of CNNs and stages of SIFT to identify
characteristics used to determine a suitable accelerator.</p>
<p>Two heterogeneous platforms consisting of two configurations,
high-performance and a power-optimised embedded system, are
developed.</p>
<p>Development of a heterogeneous scheduler to allocate tasks onto the
suitable accelerator.</p>
<p>Benchmarking and evaluating runtime, energy, and inference metrics of
popular convolution neural networks and SIFT on a wide range of
processing architectures and heterogeneous systems.</p>
<h2 id="heterogeneous-architecture">Heterogeneous Architecture</h2>
<p>In order to implement CNNs efficiently on heterogeneous platforms, A
development flow is proposed, shown in Fig. <a href="#fig:Framework"
data-reference-type="ref" data-reference="fig:Framework">6.1</a>. The
framework identifies the properties of networks and further profiles in
accordance with their hardware suitability. Finally, optimise and
evaluate the partitioning decisions.</p>
<h3 id="CNNDevflow">CNN Development Flow:</h3>
<figure id="fig:Framework">
<img src="Images/Framework.png" />
<figcaption>Development flow of Implementing CNNs on Heterogeneous
Hardware</figcaption>
</figure>
<h4 id="network-feature-extraction-layer-profiling-analysis">Network
Feature Extraction &amp; Layer Profiling Analysis</h4>
<p>Analysing the network architecture is essential in understanding the
role of each layer and how they contribute to the overall performance of
the model. This is accomplished by running the CNN on various hardware
architectures and profiling the execution time and energy consumption of
each layer. Once the resource-intensive layers have been identified by
profiling, they can be deconstructed into the types of operations they
perform. This deconstruction allows for a more granular understanding of
the computational requirements.</p>
<h4 id="partitioning-optimisation">Partitioning &amp; Optimisation</h4>
<p>To efficiently map operations onto hardware, understanding the
instruction sets and memory models of different accelerators is
necessary. For example, GPUs excel at performing matrix multiplication
during high occupancy, while FPGAs are more power and runtime efficient
for smaller matrix sizes. CPUs, with their high clock frequency and
memory hierarchy, can be advantageous for sequential layers.
Optimisations such as quantisation, pruning, and compression can improve
performance, but the trade-offs must be carefully considered.</p>
<h4 id="performance-evaluation">Performance Evaluation</h4>
<p>To determine performance, partitioning strategies and hardware
choices are benchmarked using various metrics, such as energy
consumption, accuracy, inference, and throughput. Evaluating algorithms
not only serves as a comparison to other architecture but also
identifies areas for improvement.</p>
<p>The following sections, presents an overview of the representative
feature extraction and CNN algorithms targeted for partitioning and
implementation on heterogeneous platforms.</p>
<h2 id="scale-invariant-feature-transform">Scale-Invariant Feature
Transform</h2>
<p>The Scale-Invariant Feature Transform (SIFT) algorithm used to detect
and describe local features in images. The SIFT algorithm is designed to
be robust to changes in scale, rotation, and partial occlusion. It works
in several stages: First, it identifies key points in the image through
scale-space extrema detection. These keypoints are then localised more
accurately and assigned an orientation. Finally, a descriptor is
computed for each keypoint, capturing its local image gradient patterns.
These descriptors are used for matching keypoints across different
images, making SIFT useful for tasks like object recognition, image
stitching, and 3D reconstruction. The in-depth algorithm and its
operations are explored in the previous chapter, section <a
href="#sec:SIFT" data-reference-type="ref"
data-reference="sec:SIFT">5.2</a>.</p>
<h3 id="sift-algorithm-analysis">SIFT Algorithm Analysis</h3>
<p>There are several key stages in the SIFT algorithm that vary in
computational complexities and hardware implications. This section
discusses the complexity, memory footprint and impact of operations on
CPU/GPU/FPGA hardware. The full algorithmic description of SIFT is
described in Section <a href="#sec:SIFT" data-reference-type="ref"
data-reference="sec:SIFT">5.2</a>.</p>
<h4 id="gaussian-pyramid-construction">Gaussian Pyramid
Construction:</h4>
<p>The Gaussian stage of the SIFT algorithm poses a considerable
computational load on hardware, not only due to the intensive
convolution operations but also because of the memory requirements
involved. The process of generating multiple intermediate images, each
corresponding to a different scale, can lead to significant memory
consumption, particularly for high-resolution images. For a square image
with dimensions of N x N, the complexity of the convolution operation
grows quadratically with N, resulting in a substantial computational
load. This process is repeated for each of the K scales, further adding
to the overall computational demand. Moreover, the hardware would
require high memory bandwidth for accessing large filter kernels and
image matrices. In addition to the computational complexity, the memory
footprint of storing multiple Gaussian-filtered images can become a
bottleneck, especially when dealing with large images or a high number
of scales. Architectures with higher parallelisation and memory caches
are more suitable for this stage.</p>
<h4 id="extrema-detection">Extrema Detection:</h4>
<p>The computation required to determine these extrema involves a
pixel-by-pixel comparison, evaluating whether each pixel qualifies as an
extremum. While this comparison is conducted for every pixel in the
image. These are <span class="math inline">\(O(1)\)</span> operations
for each pixel, and given the nature of the operation, lower compute
resources are required. The extrema detection algorithm operates
independently on each scale level of the pyramid, comparing pixels
within a local neighbourhood to identify potential keypoints. Therefore,
this stage can be implemented in parallel which maps well to GPUs and
FPGAs.</p>
<h4 id="orientation-and-magnitude-assignment">Orientation and Magnitude
Assignment</h4>
<p>While square root and arc tangent operations are less computationally
intensive compared to convolutions, they still pose a significant
computational burden, especially when performed on a large number of
pixels. Hardware support for fixed-point or floating-point arithmetic
can significantly accelerate these calculations, as these specialised
units are optimised for handling complex mathematical operations.</p>
<h4 id="descriptor-generation-1">Descriptor Generation:</h4>
<p>In the histogram binning and normalization stage of SIFT, local image
gradients are quantised into orientation histograms and then normalised
to enhance the robustness of feature descriptors. Binning involves
multiplication and addition operations while normalisation involves
division which requires more resource logic on hardware. However, the
operation intensity is relatively lower than the previous stages which
makes it suitable for all architectures.</p>
<h4 class="unnumbered" id="experimental-design">Experimental Design</h4>
<p>The selected profiling times for each stage and on each hardware are
shown in Fig. <a href="#fig:SIFTAlgoProfiling" data-reference-type="ref"
data-reference="fig:SIFTAlgoProfiling">6.2</a>. The runtime profiles of
each SIFT stage were collected using a robust experimental methodology.
The input is a greyscale <span class="math inline">\(3840 \times
2160\)</span> resolution image. The CPU and GPU implementations
leveraged the OpenCV SIFT function, while the FPGA was developed using
Verilog. The CPU and GPU code is executed 1000 times, and its runtimes
are averaged. In the FPGA implementation, the resulting timing graphs
from the simulations are used to determine the time taken for each
stage. All architectures had 16-bit float precision for their respective
designs and algorithms.</p>
<figure id="fig:SIFTAlgoProfiling">

<figcaption>Operation Stage Run-time Profiling: SIFT.</figcaption>
</figure>
<h3 id="sift-profiling-partitioning-strategy">SIFT Profiling &amp;
Partitioning Strategy</h3>
<figure id="fig:Partitioning">
<img src="Images/SIFT Partition.png" />
<figcaption>SIFT Algorithm &amp; Partitioning Strategy.</figcaption>
</figure>
<p>The results reveal that the CPU is substantially slower in execution
time than GPU and FPGA by <span class="math inline">\(2\times\)</span>
on average. Even though the CPU has the highest clock speed, the lack of
many processing cores results in poor for-loop unrolling optimisations
for parallelisation. Comparing only GPU and FPGA, the overall
<em>Total</em> runtime has shown the GPU being <span
class="math inline">\(0.83 \times\)</span> faster. In the <em>Gaussian
Pyramid</em> and <em>Orientation &amp; Magnitude</em> stage, the GPU
outperforms the FPGA by <span class="math inline">\(2 \times\)</span>.
On the other hand, the FPGA outperforms the GPU in the <em>Extrema
Detect</em> stage by <span class="math inline">\(1.5 \times\)</span>.
The GPU and FPGA architectures are comparable in performance when
generating keypoint descriptors due to a lower amount of operations.
Overall, the lower GPU runtime in most stages is attributed to having a
significantly higher clock speed (<em>e.g.</em>, 1725MHz vs 300MHz) and
more processing cores than the FPGA to maximise throughput.</p>
<p>The partitioning strategy shown in Fig. <a href="#fig:Partitioning"
data-reference-type="ref" data-reference="fig:Partitioning">6.3</a>,
focuses on striking a balance between potential energy consumption and
the execution time of the heterogeneous platform.</p>
<p>The RGB to greyscale conversion is a computationally lightweight
image processing operation. It involves a linear combination of the red,
green, and blue colour channels with specific weightings to produce a
greyscale image. The decision to execute <code>rgb2gray</code> algorithm
on the CPU instead of the GPU or FPGA is due to minimising the overhead
associated with transferring the image data. Although GPUs and FPGAs can
perform the RGB to Gray conversion slightly faster due to their
throughput processing and pipelining capabilities, the time spent moving
the data to and from these platforms can negate the benefits, especially
for smaller image sizes where the conversion isn’t the bottleneck.</p>
<p>The "<code>Gaussian Pyramid</code>" executed on GPU is faster than
the CPU and FPGA since the vast number of cores and memory resources
available can utilise majority of the matrix multiplication operations.
To create these scale-space representations, the algorithm needs to
access the image data repeatedly for each scale level. The Gaussian
filters, used to perform blurring, have larger kernels (in terms of
memory requirements) as the scale level increases. Additionally, the
image data must be read from memory for each scale level, leading to
significant memory access. This heavy memory access is due to the
repetitive application of convolution operations with Gaussian filters
at multiple scales. The memory bandwidth and efficiency become critical
in this stage, especially when working with large images or implementing
the algorithm on hardware platforms. Therefore, GPUs can provide an
advantage in scenarios where larger memory bandwidth is needed over
FPGAs. The "<code>Extrema Detection</code>" is allocated to GPU to
reduce additional data transfer costs that would offset any performance
gain. The "<code>Orientation &amp; Magnitude</code>" operations are
better suited to the FPGA due to the customised pipelining offered,
which allows a higher number of gradient calculation operations per
clock cycle. In the final operation stage,
"<code>Descriptor Generation</code>", the FPGA offers comparable
performance to the GPU while consuming less energy per operation and
reducing additional data transfers.</p>
<h2 id="convolutional-neural-network">Convolutional Neural Network</h2>
<p>This section describes the architecture of two widely used CNNs,
<em>Resnet18</em> and <em>MobilenetV2</em>. Each CNN is profiled layer
by layer and a partitioning strategy is developed to execute on the
heterogeneous platform. The layer characteristics and profiling results
support the partitioning methods.</p>
<h3 id="convolution-neural-network-architecture">Convolution Neural
Network Architecture:</h3>
<figure id="fig:Rensnet18">
<img src="Images/Rensnet18.png" />
<figcaption>ResNet-18 Architecture &amp; Partitioning
Strategy.</figcaption>
</figure>
<p><strong>ResNet-18:</strong> is a deep convolutional neural network
architecture observed in <a href="#fig:Rensnet18"
data-reference-type="ref" data-reference="fig:Rensnet18">6.4</a>, that
employs several key techniques to achieve state-of-the-art performance
in various computer vision tasks. Its design is driven by the need to
train very deep neural networks while mitigating issues like vanishing
gradients. The key components and technical details of ResNet-18 are as
follows:</p>
<p><strong>Convolutional Layers:</strong> ResNet-18 comprises a total of
18 layers, which are organised into several stages. The first layer is a
<span class="math inline">\(7\times7\)</span> convolutional layer with a
stride of 2. This layer is followed by a max-pooling operation with a
<span class="math inline">\(3\times3\)</span> window and a stride of 2.
The large kernel size in the initial layer helps capture larger spatial
features.</p>
<p><strong>Batch Normalisation and ReLU Activation:</strong> After each
convolutional layer, batch normalisation is applied to stabilise and
accelerate training. This is followed by the Rectified Linear Unit
(ReLU) activation function, which introduces non-linearity into the
network. The combination of batch normalisation and ReLU helps in faster
convergence and regularisation.</p>
<p><strong>Residual Connections:</strong> One of the distinctive
features of ResNet-18 is its use of residual connections. These
connections introduce identity mappings, which allow the network to
learn the residual information between layers. Mathematically, the
output of a residual block is calculated as follows: <span
class="math display">\[F(x) = \mathcal{H}(x) + x\]</span> Where <span
class="math inline">\(x\)</span> is the input to the block, <span
class="math inline">\(\mathcal{H}(x)\)</span> represents the
transformation applied by the block, and <span
class="math inline">\(F(x)\)</span> is the output.</p>
<p><strong>Downsampling Blocks:</strong> Each stage in ResNet-18
contains multiple residual blocks. After a series of convolutional
layers within a stage, a downsampling block is applied. The downsampling
block typically involves a convolutional layer with a stride of 2, which
reduces the spatial size of the feature maps while increasing the number
of channels. This operation effectively reduces the computational burden
while preserving important information.</p>
<p><strong>Softmax Classification Layer:</strong> The final layer of
ResNet-18 is a softmax classification layer. It takes the feature map
produced by the preceding layers and computes a probability distribution
over output classes. The softmax function is applied to the features,
and the resulting probabilities indicate the likelihood of the input
belonging to different classes.</p>
<p><strong>Shortcut Connections:</strong> To prevent vanishing gradients
and facilitate the flow of information, shortcut connections are
introduced in residual blocks. These connections skip the first two
convolutions within a block and add the input directly to the output of
the third convolutional layer. This way, the gradient can flow backwards
through the skip connection, making it easier to train very deep
networks.</p>
<figure id="fig:MobileNetV2Architectures">
<img src="Images/MobilnetV2.png" />
<figcaption>MobileNetV2 Architecture &amp; Partitioning
Strategy.</figcaption>
</figure>
<p><strong>MobileNetV2:</strong> shown in <a
href="#fig:MobileNetV2Architectures" data-reference-type="ref"
data-reference="fig:MobileNetV2Architectures">6.5</a>, is an
embedded-optimised convolutional neural network architecture that uses a
range of techniques to achieve high accuracy with low computational
cost. Key details of MobileNetV2 include:</p>
<p><strong>Depthwise Separable Convolution:</strong> MobileNetV2 employs
a depthwise separable convolution technique. It divides a standard
convolution operation into two distinct steps: depthwise convolution and
pointwise convolution. Depthwise convolution first performs a separate
convolution for each input channel using a kernel of size <span
class="math inline">\((k, k)\)</span>, where <span
class="math inline">\(k\)</span> is the filter size. This reduces the
computational load by a significant margin.</p>
<p>The depthwise convolution operation is computed using Eq. (<a
href="#eq:depthwise" data-reference-type="ref"
data-reference="eq:depthwise">[eq:depthwise]</a>):</p>
<p><span class="math display">\[\label{eq:depthwise}
y = \text{depthwise\_conv}(x, W_{d})\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the output, <span
class="math inline">\(x\)</span> is the input feature map, and <span
class="math inline">\(W_{d}\)</span> are the depthwise convolution
weights.</p>
<p><strong>Pointwise Convolution:</strong> After the depthwise
convolution, pointwise convolution is applied using <span
class="math inline">\(1\times1\)</span> kernels. Pointwise convolution
combines the results of the depthwise convolution by performing a linear
combination of the channels. This step helps to capture complex
relationships between channels and is critical for maintaining model
accuracy.</p>
<p>The pointwise convolution operation shown in  Eq. (<a
href="#eq:Pointwise" data-reference-type="ref"
data-reference="eq:Pointwise">[eq:Pointwise]</a>):</p>
<p><span class="math display">\[\label{eq:Pointwise}
y = \text{pointwise\_conv}(x, W_{p})\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the output, <span
class="math inline">\(x\)</span> is the result of the depthwise
convolution, and <span class="math inline">\(W_{p}\)</span> are the
pointwise convolution weights.</p>
<p><strong>Reduction of Computational Cost and Parameters:</strong> The
combination of depthwise separable convolution reduces the computational
cost significantly, making MobileNetV2 suitable for resource-constrained
embedded devices. The reduction in the number of parameters and the
computational requirements is a crucial advantage.</p>
<p><strong>Linear Bottlenecks:</strong> MobileNetV2 also introduces
linear bottlenecks, which are inexpensive <span
class="math inline">\(1\times1\)</span> convolutions placed between a
ReLU activation function and a <span
class="math inline">\(3\times3\)</span> convolution. These linear
bottlenecks are designed to keep the computational cost low while
ensuring that the network maintains a high level of accuracy. The ReLU
activation helps introduce non-linearity, while the subsequent <span
class="math inline">\(3\times3\)</span> convolution captures more
complex features.</p>
<p>The linear bottleneck operation represented in  Eq. (<a
href="#eq:bottleneck" data-reference-type="ref"
data-reference="eq:bottleneck">[eq:bottleneck]</a>):</p>
<p><span class="math display">\[\label{eq:bottleneck}
y = \text{conv\_3x3}(\text{ReLU}(\text{conv\_1x1}(x, W_{l})),
W_{3x3})\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the output, <span
class="math inline">\(x\)</span> is the input, <span
class="math inline">\(W_{l}\)</span> are the linear bottleneck weights,
and <span class="math inline">\(W_{3x3}\)</span> are the weights for the
<span class="math inline">\(3\times3\)</span> convolution.</p>
<h3 id="cnn-profiling-partitioning-strategy">CNN Profiling &amp;
Partitioning Strategy:</h3>
<figure id="fig:Resnet18LayerRuntime">

<figcaption>ResNet18, Layer Run-time Profiling: First Convolution
(Conv1) Layer (L), Fully Connected (FC). Total represents the complete
CNN running including initialisation time.</figcaption>
</figure>
<p>In this section, both CNN architectures are analysed and partitioned
onto the appropriate accelerator based on their runtime profiles. The
CNN hardware comparison results are displayed in Figure Fig. <a
href="#fig:Resnet18LayerRuntime" data-reference-type="ref"
data-reference="fig:Resnet18LayerRuntime">6.6</a> &amp; Fig. <a
href="#fig:MobilenetLayerRuntime" data-reference-type="ref"
data-reference="fig:MobilenetLayerRuntime">6.7</a>.</p>
<h4 class="unnumbered" id="experimental-design-1">Experimental
Design</h4>
<p>The runtime profiles of each CNN architecture layer were collected
using a robust experimental design. Both MobileNetV2 and ResNet18
architectures used a <span class="math inline">\(3840 \times
2160\)</span> resolution image dataset. The CPU and GPU implementations
leveraged the Pytorch library and its CUDA configuration. A custom hook
function was defined to measure the runtime of each convolutional and
linear layer during forward pass execution. For every convolutional and
linear layer in the model, the hook function recorded the start and end
times, allowing calculation of the layer-wise runtime. Through 1000 code
execution iterations, the runtimes collected are averaged. In the FPGA
implementation, Xilinx deep learning processing unit IP and their
resulting timing graphs are used to determine the time taken by each
layer. All architectures had 8-bit precision for both models and
implementation.</p>
<h4 id="resnet18"><strong>Resnet18:</strong></h4>
<p>The <em>Resnet18</em> results in Fig. <a
href="#fig:Resnet18LayerRuntime" data-reference-type="ref"
data-reference="fig:Resnet18LayerRuntime">6.6</a> show the fastest
hardware for executing the model is the GPU, with the total execution
time of <span class="math inline">\(0.18\)</span>s, while the slowest is
the CPU with <span class="math inline">\(0.29\)</span>s. The FPGA’s
total execution time is between the two with <span
class="math inline">\(0.19\)</span>s.</p>
<p>The <code>conv1</code> layer is computationally intensive for all
platforms as it applies 64 filters of size <span
class="math inline">\(7\times7\)</span> to a large input image with
multiple colour channels. This results in a large number of
multiply-accumulate (MAC) operations. The conv1 layer also performs
padding and activation functions, which adds to the overall
computational cost. However, the execution time for Conv1 is
significantly faster on the GPU, which can parallelise the computations
across multiple cores. In layers <span class="math inline">\(L1\sim
L2\)</span>, the GPU is <span class="math inline">\(1.36\times\)</span>
and <span class="math inline">\(1.10\times\)</span> faster than the
FPGA. Therefore, the GPU is the best candidate to allocate Conv1, L1 and
L2 for execution.</p>
<p>The <span class="math inline">\(L3\sim L4\)</span> and Fully
Connected (FC) layers take relatively less time to execute. The size of
feature maps decreases as they progress through the layers due to
downsampling operations like pooling and strides. The <span
class="math inline">\(L3\sim L4\)</span> convolutional and average pool
layers can be executed on the FPGA since fewer MAC operations are
occurring for the GPU to be fully utilised while taking advantage of
power efficient architecture.</p>
<figure id="fig:MobilenetLayerRuntime">

<figcaption>MobileNetV2 Layer Run-time Profiling: Bottleneck Layer (BN).
Total represents the complete CNN running including initialisation
time.</figcaption>
</figure>
<h4 id="mobilenetv2"><strong>MobilenetV2:</strong></h4>
<p>The Fig. <a href="#fig:MobilenetLayerRuntime"
data-reference-type="ref"
data-reference="fig:MobilenetLayerRuntime">6.7</a> results show that the
total execution time for the CNN on the CPU was <span
class="math inline">\(0.241\)</span>s, while on the GPU and the FPGA, it
was <span class="math inline">\(0.23\)</span>s and <span
class="math inline">\(0.20\)</span>s, respectively. The bottleneck layer
with the longest execution time for all three devices was BN1, with a
time of <span class="math inline">\(0.02202\)</span>ms on the CPU, <span
class="math inline">\(0.015\)</span>ms on the 3070 GPU, and <span
class="math inline">\(0.0034\)</span>ms on the FPGA.</p>
<p>The runtime for each bottleneck layer decreases as it moves from
<code>Bottleneck 1</code> to <code>Bottleneck 7</code> due to reduced
input channels and the amount of computation required to process the
data in each layer. Thus, the later bottleneck layers take less time to
execute than the earlier ones. The first five bottleneck layers are
suitable for execution on the FPGA, as it shows that it performs <span
class="math inline">\(\sim4\times\)</span> faster than the GPU on
average. The reason behind the faster execution on FPGA can attributed
to multiple factors below:</p>
<p>Direct, custom and optimised routing between logic allows efficient
data-flow transfer and locality.</p>
<p>Separable filters and feature maps have reduced memory footprint
which can be efficiently managed.</p>
<p>Efficient use of pipelining for convolutional operations and reduced
data dependency (<em>e.g.</em>, ResNet18 residual connections).</p>
<p>The remaining <code>Bottleneck 5 </code><span
class="math inline">\(\sim 7\)</span> layers are suitable for execution
on the GPU because of a slight performance advantage and shorter
initialisation transfer time back to the host. The <code>Softmax</code>
and <code>fully connected</code> layers are also computed on the GPU
since the performance is comparable to the FPGA and reduces data
transfer overhead. Both layers are required to transform features into a
suitable format, and it assigns a probability score for
classification.</p>
<h2 id="experimental-setup">Experimental Setup</h2>
<p>This section introduces both heterogeneous implementations and their
corresponding tools and software used to target those architectures. In
addition, a detailed break of the scheduler used to move data between
all accelerators while keeping tasks synchronised. Both power and
execution time are discussed in detail which are used to evaluate both
platforms.The proposed partitioning is tested using two developed
heterogeneous platforms containing high-low power components, as shown
in Table <a href="#tab:HWEnvironment" data-reference-type="ref"
data-reference="tab:HWEnvironment">[tab:HWEnvironment]</a>, and
described below:</p>
<figure id="fig:Clamp">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;">(b)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<figcaption>(a) Heterogeneous High-Power System, (b) Low-Power Embedded
System</figcaption>
</figure>
<p><strong>Low-Power System:</strong> The constructed system consists of
a custom carrier board which is equipped with several key components,
including an Artix-7 (XC7A200T) FPGA, a Jetson Xavier NX, and an ARM
CPU. To provide additional storage space, the Linux image is flashed
onto the SD card rather than the 16Gb eMMC. Communication between the
FPGA and the Xavier NX is achieved through a PCIe gen2 4-lane interface,
which is connected via an M.2 key-M connector.</p>
<p><strong>High-Power System:</strong> The system consists of CPU (AMD
5900x), GPU (GTX 3070) and FPGA (Xilinx ZCU106), integrated into a
desktop with 32GB 3200Mhz DDR4 Memory. Both devices are interfaced via
PCIe Gen3 and the communication to the host CPU uses direct memory
access (DMA), allowing the movement of data between host memory and
subsystems. The GPU and FPGA drivers are used to program the DMA engine
and DMA/bridge subsystem IP. Idle CPU is frequency scaled to reduce
power consumption.</p>
<p><strong>Dataset.</strong> The test images used in the experiments are
from LIU4K-v2 dataset <span class="citation"
data-cites="LiuliuYan19"></span>, which is a high resolution data-set
that includes 2000 <span class="math inline">\(3840\times2160\)</span>
images. The images contain a variety of backgrounds and objects.</p>
<h3 class="unnumbered"
id="heterogeneous-scheduler-architecture">Heterogeneous Scheduler
Architecture</h3>
<figure id="fig:SchedulerArch">
<img src="Images/SchedulerDetail.png" />
<figcaption>Scheduler Architecture for Heterogeneous Platform:
Allocating tasks to processors depending on the partitioning
strategy.</figcaption>
</figure>
<p>A heterogeneous scheduler architecture in Fig. <a
href="#fig:SchedulerArch" data-reference-type="ref"
data-reference="fig:SchedulerArch">6.9</a> is developed, which is
responsible for distributing and managing tasks or workloads across
different types of processing units or resources. The scheduler is
written in C/C++ to manage memory transfers and pass the feature map and
operation stage data from the CPU and into the GPU or FPGA.</p>
<p>The scheduler uses a <em>First-Come, First-Served</em> (FCFS)
algorithm due to its relatively simple construction and minimal runtime
overhead. The operation stages in imaging algorithms are executed
sequentially. Therefore, tasks are partitioned in order based on their
dependency on previous task data, which makes it suitable for this type
of scheduling algorithm. The pre-partitioned ordered tasks are fetched
from the queue and decoded to prepare for execution. As tasks are
dequeued, they are placed in the task ready queue, a staging area where
tasks await execution. The task ready queue ensures that tasks are
readily available for the execution stage. Each task contains a
predefined pragma which tells the scheduler which architecture to
execute the operation on. Additionally, a task status register is used
to keep track of the current state and progress of each task. This
register provides real-time information about the task’s status, whether
it is waiting, executing, or completed. The task status register is
essential for maintaining task synchronisation and ensuring that tasks
progress through the execution pipeline smoothly. It allows the
scheduler to monitor and manage the execution of tasks and make informed
decisions based on the tasks’ statuses, ensuring optimal resource
utilisation and order of execution.</p>
<div class="algorithm">
<div class="algorithmic">
<p><span class="math inline">\(fpga\_output \gets \text{None}\)</span>
<span class="math inline">\(gpu\_output \gets \text{None}\)</span> <span
class="math inline">\(task\_queue \gets \emptyset\)</span></p>
<p><span class="math inline">\(task \gets \text{tasks}[i]\)</span> <span
class="math inline">\(task\_queue \gets task\_queue \cup
\{task\}\)</span></p>
<p><span class="math inline">\(task \gets
\text{Dequeue}(task\_queue)\)</span></p>
<p><span class="math inline">\(fpga\_output \gets
\text{ExecuteOnFPGA}(task)\)</span> <span
class="math inline">\(gpu\_output \gets
\text{ExecuteOnGPU}(task)\)</span></p>
<p><span class="math inline">\(final\_output \gets
\text{TransferData}(fpga\_output, &quot;FPGA&quot;,
&quot;CPU&quot;)\)</span> <span class="math inline">\(final\_output
\gets \text{TransferData}(gpu\_output, &quot;GPU&quot;,
&quot;CPU&quot;)\)</span></p>
<p><span class="math inline">\(final\_output \gets
\text{PostProcess}(final\_output)\)</span> <span
class="math inline">\(\text{DisplayResult}(final\_output)\)</span></p>
</div>
</div>
<p>The pseudocode presented in Algorithm <a
href="#Alg:HeterogeneousScheduler" data-reference-type="ref"
data-reference="Alg:HeterogeneousScheduler">[Alg:HeterogeneousScheduler]</a>
outlines the process of the Heterogeneous Scheduler. This algorithm
iterates over the tasks in the workload and employs an FCFS queue to
execute tasks in the order they were received. The algorithm initialises
two functions, <code>ExecuteOnFPGA()</code> and
<code>ExecuteOnGPU()</code>, which are used to execute the task on a
certain device based on a partitioning strategy. The FCFS queue ensures
that tasks are executed in the order of arrival, maintaining fairness
and accuracy in task execution. Once all tasks have been executed, the
algorithm transfers the output data from the FPGA or GPU to the CPU,
depending on which device the output is stored on. This transfer
facilitates the consolidation of results for further processing. Lastly,
the algorithm post-processes the output to generate the final result of
the workload.</p>
<h3 id="cpu-gpu-fpga-data-communication">CPU-GPU-FPGA Data
Communication</h3>
<figure id="fig:Scheduler">
<img src="Images/Scheduler.png" />
<figcaption>RDMA Direct Memory Access Data-transfer process steps for
communication between FPGA-GPU.</figcaption>
</figure>
<p>The data transfer process controlled by the scheduler follows a
series of steps described below:</p>
<p>Allocate Buffer: Allocate memory buffers on both the GPU and FPGA to
hold the data to be transferred.</p>
<p>Register Buffer: Register the GPU buffer with the FPGA using PCIe
Base Address Register mapping or GPUDirect Remote Direct Memory Access
to enable direct access.</p>
<p>Pin Buffer: Pin the GPU buffer to prevent it from being swapped out
of physical memory, ensuring consistent and efficient access by the
FPGA/Host.</p>
<p>Request Copy: Initiate the data transfer from the GPU buffer to the
FPGA buffer using a Direct Memory Access controller.</p>
<p>Program DMA Copy: Configure the DMA engine’s source and destination
addresses, transfer size, and control parameters to transfer data
autonomously.</p>
<p>Handle DMA Completion: Monitor the DMA engine’s status flags or
interrupts to detect transfer completion.</p>
<p>Process Data on FPGA/GPU: Access the transferred data from the
destination buffer.</p>
<p>In the case of FPGA, the scheduler uses the drivers to initialise the
DMA to allocate buffer pointers and then pass the pointer to the write
function. After receiving the input data and its size, the driver
creates a descriptor and initialises the DMA process by providing the
descriptor’s start address. The driver writes a control register to
start the DMA transfer, which reads the descriptor and fetches the
feature map data to be processed on the FPGA.</p>
<p>On the GPU side, the CPU host code allocates device pointers using
CUDA functions like <code>cudaMalloc</code> to specify the locations in
the GPU’s memory where the data will be placed. Then, the CPU host code
invokes CUDA API functions such as <code>cudaMemcpy</code> to request
the data transfer. The GPU driver, which manages GPU resources, sets up
the transfer, allocates GPU memory, and configures the data transfer
channels. It ensures that the FPGA’s memory is correctly mapped to the
GPU’s address space to enable efficient transfer. Subsequently, the GPU
driver issues commands to the GPU to initiate the data transfer. The
actual transfer is executed by the GPU hardware using Direct Memory
Access (DMA). Once completed, the GPU returns a status to the driver.
The CPU host code can then access and process the data in the GPU’s
memory. Synchronisation mechanisms, like CUDA events or
<code>cudaStreamSynchronize</code>, may be employed to ensure that the
GPU doesn’t process the data prematurely.</p>
<p>The systems exploit GPUDirect RDMA shown in Fig. <a
href="#fig:Scheduler" data-reference-type="ref"
data-reference="fig:Scheduler">6.10</a> to facilitate low-latency
communication without involving the host CPU by retrieving the bus
address of buffers in GPU memory. Traditionally, BAR windows are mapped
to the CPU’s address space using memory-mapped I/O (MMIO) addresses.
However, current operating systems lack mechanisms for sharing MMIO
regions between drivers. Therefore, the NVIDIA kernel driver provides
functions to handle address translations and mappings. This means that
data can be moved directly between the GPU and the host without the need
for intermediate buffers or copies in CPU memory. This approach
significantly improves data transfer efficiency, particularly for large
images or data, as it eliminates unnecessary data movement and reduces
memory overhead.</p>
<h3 id="execution-time-2">Execution time</h3>
<p>The evaluation of the overall system performance considers both
latency and compute factors, reporting performance metrics for total
time, inference, and other significant layers while using floating point
16 precision. Other devices, such as i9-11900KF (5.30GHz), are also
benchmarked for additional insight. The run-time is measured using the
host platform’s built-in time libraries. The network performance is
estimated by executing and averaging the results of 100 images. The
frame per second (FPS) metric is computed using Eq. <a href="#eq:FPS"
data-reference-type="ref" data-reference="eq:FPS">[eq:FPS]</a>:</p>
<p><span class="math display">\[\label{eq:FPS}
\text{FPS}= 1/\text{Execution Time}.\]</span></p>
<h3 id="power-consumption-2">Power Consumption</h3>
<figure id="fig:Clamp">
<table>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;">(b)</td>
</tr>
</tbody>
</table>
<figcaption>(a) Power Measurement using Current Clamp, (b) Connected to
a Data Logger at 4 Kilo Samples Per Second.</figcaption>
</figure>
<p>Two common methods used for measuring power are software and hardware
based. Accurate power estimation is always challenging for software
tools because they have to assume various factors in their models.
Additionally, Taking the instantaneous power or TDP of a device is not
accurate since power consumption varies on the specific workload.
Therefore, measuring power over the time it takes for the algorithm to
execute improves accuracy as opposed to using just fixed Wattage. The
hardware measurement approach uses a current clamp meter shown in <a
href="#fig:Clamp" data-reference-type="ref"
data-reference="fig:Clamp">6.11</a>, which outputs a voltage for every
Amp measured. The <em>Otii Arc Pro</em><span class="citation"
data-cites="qoitech_2023"></span> data-logger captures the time series
data from the current clamp and generates a graph showing the current
consumption over time. A script is developed to start and stop the
measurements during the algorithm’s execution. The mean current is
averaged and multiplied by the input voltage to determine the energy
consumed in Joules (J).</p>
<p>The energy consumption is obtained using Eq. (<a href="#eq:Energy"
data-reference-type="ref" data-reference="eq:Energy">[eq:Energy]</a>)
where <em>E</em> is energy, <em>P</em> represents power and <em>t</em>
time.</p>
<p><span class="math display">\[\label{eq:Energy}
E = P \times t\]</span></p>
<h2 id="experimental-results">Experimental Results</h2>
<p>In this section, results of both CNN and SIFT algorithms implemented
on a heterogeneous platform are observed and discussed in-depth.</p>
<h3 id="heterogeneous-sift-results">Heterogeneous SIFT Results</h3>
<p>In achieving that, a custom pipeline was created by targeting various
algorithm components on different hardware based on their suitability
obtained from the benchmarking framework. This includes the latency of
transferring image data between memory and the accelerators. The
heterogeneous architecture empowers the ability to pick and execute
operations within the image processing algorithms on each architecture
to meet the speed and power target. However, within the scope of this
work, only an initial configuration of the SIFT algorithm is reported,
which establishes preliminary steps toward future work on finding the
most optimal configuration for the algorithms.</p>
<h4 id="heterogeneous-sift-runtime-energy-consumption">Heterogeneous
SIFT Runtime &amp; Energy Consumption</h4>
<p>Table <a href="#tab:heterogenoussummary" data-reference-type="ref"
data-reference="tab:heterogenoussummary">[tab:heterogenoussummary]</a>
shows the execution time of the SIFT algorithm on a heterogeneous
platform. The table includes memory transfer latency between the host
and devices, an aspect frequently overlooked in similar analyses. The
results reveal that the heterogeneous platform (Excl. Memory Transfer)
outperforms all discrete architectures, CPU, GPU and FPGA by <span
class="math inline">\(103\times\)</span>, <span
class="math inline">\(1.21\times\)</span> and <span
class="math inline">\(1.43\times\)</span>, respectively. However, taking
data transfer into account, the heterogeneous architecture increases in
execution time due to host task scheduling. On the other hand, As
accelerators are fabricated on the same silicon die, memory latency
would significantly be reduced.</p>
<figure id="fig:SIFTPower">

<figcaption>SIFT Power Consumption, Baseline Homogeneous and
Heterogeneous Implementation Comparison.</figcaption>
</figure>
<p>The energy consumption results in Fig. <a href="#fig:SIFTPower"
data-reference-type="ref" data-reference="fig:SIFTPower">6.12</a> reveal
that the CPU consumes the most energy for all operation stages in
<em>SIFT</em> and <code>RGB2Gray</code> while the FPGA used the least.
The <code>Gaussian Pyramid</code> stage stands out as the most energy
intensive due to the substantial number of operations it requires. In
contrast, the low resource requirements of <code>RGB2Gray</code> and
<code>Descriptor Generation</code> stages reflected lower energy
usage.</p>
<p>The heterogeneous architecture, which combines CPU, GPU and FPGA
resources, strikes a balance between power consumption and execution
time. The "<em>Total</em>" power consumption is notably lower than the
CPU but between both GPU and FPGA since the static power of other
accelerators is taken into account.</p>
<h2 id="heterogeneous-cnn-results">Heterogeneous CNN Results</h2>
<p>The results in Fig. <a href="#fig:Resnet18PowerRuntime"
data-reference-type="ref"
data-reference="fig:Resnet18PowerRuntime">6.14</a> &amp; Fig. <a
href="#fig:MobilenetPowerRuntime" data-reference-type="ref"
data-reference="fig:MobilenetPowerRuntime">6.15</a> show the total
run-time and energy consumption of Resnet18 and MobilenetV2 on each
architecture and heterogeneous platform while Fig. <a
href="#fig:InferenceFPS" data-reference-type="ref"
data-reference="fig:InferenceFPS">6.13</a> shows the inference in
<em>Frames per Second</em>. The tables <a
href="#tab:Mobilenet-V2 Result Summary" data-reference-type="ref"
data-reference="tab:Mobilenet-V2 Result Summary">[tab:Mobilenet-V2
Result Summary]</a> &amp; <a href="#tab:ResNet-18 Result Summary"
data-reference-type="ref"
data-reference="tab:ResNet-18 Result Summary">[tab:ResNet-18 Result
Summary]</a>, summarises the results for the <em>Total Execution
Time</em>, <em>Inference</em>, <em>Convolution</em>, <em>Fully
Connected</em>, <em>Total Energy</em>, <em>CPU Energy</em>, <em>Device
Energy</em> &amp; <em>Datalogger</em></p>
<h3 id="inference">Inference</h3>
<figure id="fig:InferenceFPS">

<figcaption>Frames per Second (FPS) for Inference on CPU:(I9-9900K,
5900X) GPU:(GTX 3070, Xavier NX) FPGA:(Artix-7, ZCU106), High-Power
(HP), Low-Power (LP). (+) Denotes components in HP Platform, (-) Denotes
Components in LP Platform.</figcaption>
</figure>
<p>According to Fig. <a href="#fig:InferenceFPS"
data-reference-type="ref" data-reference="fig:InferenceFPS">6.13</a>,
<em>Resnet18</em> CNN had the highest FPS value at <span
class="math inline">\(270\)</span> in contrast to <em>MobileNetV2</em>
<span class="math inline">\(243\)</span> FPS on high and low power
heterogeneous architecture. This difference in FPS can be attributed to
the network depths and parameters, with <em>ResNet-18</em> having <span
class="math inline">\(18\)</span> layers and <em>MobileNetV2</em> having
<span class="math inline">\(53\)</span> layers, leading to differences
in computational complexity. Considering individual hardware only, the
’3070’ GPU achieved the highest FPS on <em>Resenet18</em> and the
’ZCU106’ FPGA for <em>MobileNetv2</em>. On the other hand, the Artix-7
has the lowest FPS in both architectures due to limited resources and
clock speed. In the case of both heterogeneous systems, <em>HP</em>
&amp; <em>LP</em> architectures achieve higher FPS than their individual
counterparts.</p>
<h3 id="total-execution-time">Total Execution Time</h3>
<figure id="fig:Resnet18PowerRuntime">

<figcaption>ResNet18 Energy Consumption &amp; Total Runtime Comparison;
CPU:(I9, 5900X), GPU:(3070, Xavier NX), FPGA:(Artix-7, ZCU106),
High-Power (HP), Low-Power (LP).</figcaption>
</figure>
<figure id="fig:MobilenetPowerRuntime">

<figcaption>MobileNetV2 Energy Consumption &amp; Total Runtime
Comparison; CPU:(I9, 5900X), GPU:(3070, Xavier NX), FPGA:(Artix-7,
ZCU106), High-Power (HP), Low-Power (LP).</figcaption>
</figure>
<p>Regarding Fig. <a href="#fig:Resnet18PowerRuntime"
data-reference-type="ref"
data-reference="fig:Resnet18PowerRuntime">6.14</a> for Resnet18, it can
be observed that the Artix-7 exhibits the highest total execution time,
taking approximately <span class="math inline">\(1.1\)</span> seconds to
complete the task. Conversely, the ’GPU: 3070’ has the lowest real
execution time, both completing the task at approximately <span
class="math inline">\(0.18\)</span>s. As for MobileNetV2 in <a
href="#fig:MobilenetPowerRuntime" data-reference-type="ref"
data-reference="fig:MobilenetPowerRuntime">6.15</a>, the ’FPGA: Artix-7’
platform also leads with the highest execution time at <span
class="math inline">\(1.4\)</span>s, while the ZCU102 classifies the
image in <span class="math inline">\(0.19\)</span>s and GPU at <span
class="math inline">\(0.23\)</span>s. It is noteworthy to mention that
the higher runtimes observed for the GPUs may be attributed to the
communication and transfer of data from the CPU and lower core
utilisation.</p>
<p>Total Execution time speedups of high (HP) and Low (LP) power systems
are compared against their fastest discrete components within each
system. The ’HP’ system demonstrated a speedup of <span
class="math inline">\(1.05\times\)</span> over the ’GPU:3070’ for
<em>Resnet18</em> and <span class="math inline">\(1.05\times\)</span>
for<em>MobileNetv2</em>. In the case for ’LP’ system, it exhibited a
speedup of <span class="math inline">\(1.21\times\)</span> over the
’GPU: Xavier NX’ for <em>Resnet18</em> and <span
class="math inline">\(1.06\times\)</span> for <em>MobileNetv2</em>. The
<code>Convolution</code> layer results show that the most time is spent
performing convolution operations. However, taking in account
data/memory transfer latency, both heterogeneous architectures
implementations have interconnect (PCIe) and distance bottlenecks. This
bottleneck reduces the FPS of HP &amp; LP systems by <span
class="math inline">\(10 \sim 25\)</span> which in turn allows the
’GPU:3070’ to marginally edge out on the HP system. The disparity
between the <code>Total Wallclock</code> and <code>Inference</code>
runtimes are due to the overhead and initialisation time which include
model/weight loading and data preprocessing. In addition, the
<code>Fully Connected</code> layer revealed that all architecture had
comparable performance due to the layer’s simple MAC operations.</p>
<h3 id="energy-consumption">Energy Consumption</h3>
<p>Concerning energy consumption, the discrete ’5900 &amp; I9’ CPUs
consume the most energy in both CNN architectures, around <span
class="math inline">\(20\sim26\)</span> Joules. The least amount of
energy consumed is from both FPGA architectures, ’FPGA: Artix’ and
’FPGA: ZCU106’, which used less than <span
class="math inline">\(15\)</span> Joules for both networks. Taking CPU
idle energy usage into account results in GPUs having comparable energy
usage statistics with both CPUs which is linked to higher CPU-GPU data
transfer and initialisation cost. However, HP and LP systems consume
<span class="math inline">\(1.02\times\)</span> and <span
class="math inline">\(1.03\times\)</span> less energy, respectively,
compared to the single ZCU106 and Artix architectures for
<em>Resnet18</em>. As for <em>MobileNetV2</em>, there is a <span
class="math inline">\(1.06\times\)</span> and <span
class="math inline">\(1.07\times\)</span> reduction in energy
consumption for the ’HP’ and ’LP’ systems, respectively. The idle
accelerators within heterogeneous systems had their clocks lowered to
save on static energy consumption. However, a small increase in idle
energy usage was observed during execution. If idle energy is taken into
account, then the energy consumption results of both HP &amp; LP systems
would be greater than discrete FPGA but lower than GPU.</p>
<h2 id="conclusion-2">Conclusion</h2>
<p>In this chapter, partitioning strategies are introduced to map the
layers of two widely used convolutional neural networks, namely,
<code>Resnet18</code> and <code>Mobilnetv2</code>, along with a feature
extraction algorithm (<code>SIFT</code>), onto a heterogeneous
architecture. Two new CPU-GPU-FPGA systems, one designed for high
performance and the other for low-power consumption, are proposed. The
experiments demonstrate that when layer/per-operation partitioning
methods are applied, both high-power and low-power systems outperform
homogeneous accelerators in terms of energy efficiency and execution
time. Furthermore, the results suggest that partitioning networks based
on their layer profiles holds the potential for efficient deployment on
heterogeneous architectures, offering a viable alternative to
GPU/FPGA-only applications.</p>
<h1 id="chap:concl">Discussion, Conclusions and Future Work</h1>
<p>The aim of this thesis is to present domain-specific optimisation
techniques for image processing algorithms on heterogeneous hardware. In
section <a href="#sec:Discussionc" data-reference-type="ref"
data-reference="sec:Discussionc">7.1</a>, the research problems are
identified and discussed. Furthermore, in section <a href="#sec:con_con"
data-reference-type="ref" data-reference="sec:con_con">7.2</a>, the
contributions to addressing the problems are presented. Lastly, in
section <a href="#sec:con_ftr" data-reference-type="ref"
data-reference="sec:con_ftr">7.3</a>, future research directions
extending the work are suggested.</p>
<h2 id="sec:Discussionc">Discussion</h2>
<p>The thesis focuses on achieving two main research aims, "Which is the
best method of partitioning and implementing algorithms on heterogeneous
hardware" and "Identifying domain-specific optimisations and
understanding the performance and accuracy trade-offs".</p>
<p>In the case of implementing algorithms on heterogeneous platforms,
the primary challenge is navigating the route to hardware. Designers
often face a complex terrain of diverse hardware architectures, each
with unique constraints and optimisation opportunities. This problem can
lead to a time consuming and error-prone process of manually configuring
and optimising algorithms for specific accelerators. Moreover, the need
for standardised tools and interfaces across platforms further
exacerbates the difficulty of seamless integration. Designers must
grapple with the intricacies of synchronisation and resource allocation,
which can be particularly daunting in complex, real-time image
processing applications. These challenges underscore the need for a more
streamlined and systematic approach to ensure efficient deployment of
algorithms on heterogeneous platforms.</p>
<p>The other challenge for heterogeneous systems is efficiently managing
data transfers between various processing units. Data movement between
processors introduces latency and consumes substantial computational
resources and memory bandwidth. In image processing, operations usually
form a pipeline often subject to data dependencies, making it difficult
to optimise the scheduling of tasks. Therefore, inefficient data
transfers can lead to a significant performance bottleneck.</p>
<p>Optimisation is an essential step towards extracting the best
performance out of systems. Traditional optimisations are not
domain-aware and, therefore, cannot exploit the unique properties of
specific problem domains to improve performance. Additionally,
understanding the trade-offs between domain-specific optimisations and
energy consumption or accuracy has not been fully considered.</p>
<p>Finally, implementing deep-learning algorithms such as CNNs or
feature extraction algorithms on heterogeneous architectures
necessitates the development of fine-grained partitioning strategies.
Applying these strategies requires a thorough understanding of hardware
architectures and profiling. In addition, developed metrics should be
used to effectively evaluate the performance of heterogeneous
implementations based on the type of algorithm deployed. Addressing
these challenges is critical to unlocking the full potential of
heterogeneous architectures.</p>
<h2 id="sec:con_con">Conclusions</h2>
<p>To achieve the first objective of efficient deployment of algorithms
on heterogeneous platforms, the characteristics of image processing
algorithms were decomposed into fundamental operations. A benchmarking
framework is presented in Chapter <a href="#Harbour"
data-reference-type="ref" data-reference="Harbour">4</a> to understand
the features of algorithms found in the image-signal pipeline and to
determine their suitability for specific accelerators in a heterogeneous
environment. This modular framework, termed the Heterogeneous
Architecture Benchmarking Framework on Unified Resources (HArBoUR),
provides an in-depth analysis and set of metrics for imaging algorithms,
which in turn enables the identification of the most efficient
processing unit. To support the proposed framework, low and high
complexity image processing pipelines are evaluated on each architecture
using various tools and libraries. This gives a comprehensive insight
into their design choices and optimisations. Different evaluation
metrics are proposed such as throughput, energy per operation and clock
cycles per operation.</p>
<p>The following chapter <a href="#chap:DSO" data-reference-type="ref"
data-reference="chap:DSO">5</a>, explores domain-specific optimisation
techniques within image processing. Several optimisations were proposed
and validated on CNNs, feature extraction and filter algorithms. The
results for CNN and filter algorithms had significantly reduced
computation times on all processing architectures. In the case of the
optimised SIFT algorithm implementation, it had outperformed the
state-of-the-art on FPGAs. Additionally, it achieved runtime at par with
GPU performances while consuming less power. However, these
optimisations come at the expense of reduced accuracy, highlighting the
need for thoughtful consideration when aiming to enhance performance
through domain-specific optimisations.</p>
<p>In the concluding Chapter <a href="#sec:HCNN"
data-reference-type="ref" data-reference="sec:HCNN">6</a>, the
development of two low and high-power heterogeneous systems using
commercial off-the-shelf hardware is discussed. Moreover, two
convolutional networks and a feature extraction algorithm are profiled
and analysed to identify performance hotspots and assess their hardware
compatibility. The algorithms are then partitioned onto the most
efficient hardware using a fine-granular strategy, involving the
separation of CNNs layer by layer and operations within the feature
extraction algorithm. The implemented heterogeneous algorithms are
evaluated against their discrete hardware counterparts, resulting in
notable speedups in performance and reduced energy consumption.</p>
<h2 id="sec:con_ftr">Limitations &amp; Future work</h2>
<p>In this section, the limitations and potential future directions of
this research are discussed below:</p>
<h3 id="heterogeneous-benchmark-framework">Heterogeneous Benchmark
Framework</h3>
<p>The heterogeneous benchmarking framework proposed in Section <a
href="#Harbour" data-reference-type="ref" data-reference="Harbour">4</a>
can be extended by including additional performance metrics that
consider communication latency and scheduling of algorithms to determine
the true performance. Further developing a tool-chain to support
designers by highlighting key areas of code that can be accelerated by a
particular processor and automatically partitioning algorithms without
requiring additional designer input. This automation not only saves time
but also ensures that the resulting code is fine-tuned on the target
hardware.</p>
<h3 id="domain-specific-optimisations-1">Domain-Specific
Optimisations</h3>
<p>The methods described in Section <a
href="#sec:Domain-Specific Optimisations" data-reference-type="ref"
data-reference="sec:Domain-Specific Optimisations">5.1</a> mainly centre
on applying optimisations uniformly across the entire algorithm,
resulting in the same optimisation being applied to every operation
stage within the algorithms. This coarse-grained approach may
potentially impact accuracy while having no significant impact on the
overall runtime. Therefore, adopting a fine-grained approach by applying
optimisation strategies to specific parts of an algorithm. An example of
a granular approach involves applying optimisations to individual layers
of a CNN or each stage of the SIFT algorithm, where each operation is
fine-tuned independently. Additionally, the development of a
domain-specific compiler capable of dynamically adapting and optimising
algorithms based on runtime conditions, accuracy requirements, energy
considerations, and data patterns can further enhance the efficiency and
effectiveness of domain-specific optimisations on a heterogeneous
platform.</p>
<h3 id="heterogeneous-implementations">Heterogeneous
Implementations</h3>
<p>In section <a href="#sec:HCNN" data-reference-type="ref"
data-reference="sec:HCNN">6</a>, future directions of this chapter
involve improving the hardware, scheduler and measurement accuracy.
Initially, The heterogeneous scheduler on the high performance system
transfers the output of one operation or layer onto the pinned memory of
the GPU or buffer. The transfer is indirect since it has to go through
the CPU, but can be shortened through direct memory transfer between
accelerators. The scheduling algorithm can be improved by dynamically
scheduling workloads for image processing if requirements change.</p>
<p>To address the challenges with data transfer latency can be separated
into two categories, Hardware and Software listed below:</p>
<p>Hardware: Using a faster interface between accelerators than PCIe or
integrating the cores onto a single compute chip to reduce the data
transfer distance.</p>
<p>Hardware: Utilising in-memory processing which integrates computation
within memory modules. This design reduces data movement overhead and
latency by processing data where it’s stored rather than shuttling it
between memory and processors.</p>
<p>Software: Latency-aware compilers predict anticipated data usage by
different processors and proactively optimise data placement to improve
data locality.</p>
<h3 id="domain-specific-language">Domain-Specific Language</h3>
<p>All the previously mentioned future research directions can be
unified within the framework of an image processing domain-specific
language targeting image processing. The language would allow users to
streamline the development of customised image pipelines by mapping
algorithms together using a data-flow model. The result of abstracting
away from hardware using a high-level signal flow diagram would simplify
the route to hardware while removing the burden of partitioning and
manual tuning from the designer.</p>
</body>
</html>
